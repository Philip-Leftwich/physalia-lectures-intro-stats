---
title: "5023B"
subtitle: "<small>Data Science for Biologists</small>"
author: "Dr Philip Leftwich"
format:
  LUstyle-revealjs:
    self-contained: true
    auto-stretch: false
    footer: "{{< fa envelope >}} [p.leftwich@uea.ac.uk](mailto: p.leftwich@uea.ac.uk) {{< fa globe >}} [philip.leftwich.github.io](https://philip.leftwich.github.io/) {{< fa brands linkedin >}} [philip-leftwich](https://www.linkedin.com/in/philip-leftwich-117052155/)"
    
    always_allow_html: yes
---

# Welcome! {background-color="#D9DBDB"}

```{r}
#| include: false
#| message: false
#| warning: false

library(arm)
library(car)
library(DHARMa)
library(emmeans)
library(equatiomatic)
library(fitdistrplus)
library(gtsummary)
library(lmtest)
library(MASS)
library(MuMIn)
library(performance)
library(pscl)
library(sjPlot)


```

::: columns
::: {.column .right}


:::

::: {.column}

![](images/UEA.jpg){fig-align="center" fig-alt="UEA logo" width=70%}

:::
:::


## About me

::: columns
::: {.column .right}

Associate Professor in Data Science and Genetics at the [University of East Anglia](https://www.uea.ac.uk/).

<br>

Academic background in Behavioural Ecology, Genetics, and Insect Pest Control.

<br>

Teach Genetics, Programming, and Statistics

:::

::: {.column}

![](images/UEA.jpg){fig-align="center" fig-alt="UEA logo" width=70%}

:::
:::

## About me

::: columns
::: {.column .right}


Norwich - "A Fine City!"

![](images/norwich.jpeg){fig-align="center" fig-alt="Norwich cathedral" width=90%}

:::

::: {.column}

![](images/norwich_map_position_in_uk_000001.png){fig-align="center" fig-alt="Norwich on a map" width=70%}

:::
:::

# Introduce yourselves {background-color="#D9DBDB"}


## Outline of the course

- Learning R and data wrangling

- Checking data quality and producing insights

- Statistics with linear models

- Generalized Linear Models

- Mixed modelling



## What to expect during this workshop

These workshop will run for *6 hours* each.

We will have a 40 min break halfway through and some shorter breaks

But take breaks when you need to!

* Combines slides, live coding examples, and exercises for you to participate in.

* Ask questions in the chat throughout!

## What to expect during this workshop

::: columns
::: {.column}

<br>

I hope you end up with more questions than answers after this workshop!

:::

::: {.column .center-text}

<br>

![](images/great-question.gif){fig-align="center" fig-alt="Schitts Creek questions gif" width=60%}

<small>Source: <a href="https://giphy.com/gifs/schittscreek-64afibPa7ySzhFAf00">giphy.com</a></small>

:::
:::





## Workshop Resources

<br><br>

- Slides available [here](https://philip-leftwich.github.io/physalia-lectures-intro-stats/#/title-slide)

- Coursebook available [here](https://ueabio.github.io/physalia-intro-stats-2023/index.html)

- Posit Cloud workspace available [here]


# An Introduction to R {background-color="#D9DBDB"}

## What is R?


* R is a full programming language

* R is a calculator

* R simulates & generates data

* R reads, processes and manipulates data

* R analyses data

* R makes plots, graphics, reports and presentations

## Why use R?

- Specialized in data analysis and statistical computing

- Large repository of packages (CRAN)

- Active community and extensive documentation

- Excellent for reproducible research 

## Basic R Syntax

```{r, echo = T}

5 + 10

```

```{r, echo = T}

x <- 5 + 10
x

y <- 20
```


## Basic operations

```{r, echo = T}
sum <- x + y
diff <- x - y
prod <- x * y
quot <- x / y

```

## Data types

```{r, echo = T}
x

y <- "apple"

z <- TRUE

str(x)
str(y)
str(z)

```

## Data Structures

- Vectors

```{r, echo = T}

vec <- c(1, 2, 3, 4, 5)
vec
```

- Data Frames

```{r, echo = T}

df <- data.frame(name=c("Alice", "Bob"), age=c(25, 30))
df
```

- Lists

```{r, echo = T}

lst <- list(name="Alice", age=25, scores=c(90, 85, 88))
lst
```


## Accessing data structures

```{r, echo = T}
df

```

```{r, echo = T}
df$name
```

```{r, echo = T}
df[1,]

df[,1]
```

## R terms

```{r, echo = FALSE, out.width="70%"}
knitr::include_graphics("images/terms.png")
```

## Functions

Functions are bits of code that complete specific tasks

```
select(.data, columns)
```

```{r, echo = T}

dplyr::select(.data = df, name)

```


```{r, echo = T}

dplyr::select(df, name)

```


## Pipes

Pipes let us string multiple functions together by passing the output from one line of code into the next line

```{r, echo = T}
df %>% 
dplyr::select(name) %>% 
  dplyr::arrange(dplyr::desc(name))

```


## What is RStudio/Posit?

```{r, echo = FALSE, out.width="70%"}
knitr::include_graphics("images/engine.png")
```

## What is RStudio/Posit


```{r, echo = FALSE, out.width="70%"}
knitr::include_graphics("images/environment.jpg")
```

## Navigating RStudio

Layout:

- Source Pane: Writing and editing scripts

- Console Pane: Executing R commands

- Environment/History Pane: Viewing and managing variables and command history

- Files/Plots/Packages/Help Pane: Managing files, viewing plots, accessing packages, and getting help

## Scripts

- Scripts: Write reusable code in .R files

```{r, echo = T}

# This is a comment

print("Hello, R!")


```

- Run code by executing lines or selections

- Automate running scripts

## Using Packages

R packages are collections of code and data that extend or improve functionality

```{r, echo = T, eval = F}
install.packages("ggplot2")
```

Once installed, packages must be loaded into the working environment to function

```{r, echo = T, eval = F}
library(ggplot2)

```


```{r, echo = T, eval = F}

ggplot(data, aes(x=variable1, y=variable2)) + geom_point()

```


## R is for Open Reproducible Research

::: columns
::: {.column}


* Reproducible

* Robust

* Transparent

* Reusable

* Shareable research materials

:::

::: {.column}

```{r, echo = FALSE, out.width="100%", fig.alt = "Is data and stats reporting enough?"}
knitr::include_graphics("images/reproducible-data-analysis-02.png")
```

:::

:::


## Main features of R


- Comprehensive Packages: Thousands of packages available through CRAN, Bioconductor, and GitHub to extend R’s capabilities.

- Data Manipulation: Powerful libraries like `dplyr` and `tidyr` for data wrangling.

- Statistical Analysis: Built-in functions for a wide range of statistical tests and models.

- Visualization: Excellent plotting libraries such as `ggplot2` for creating stunning visualizations.

## Main Features of RStudio

User-Friendly Interface: Four-pane layout (script, console, environment, files) for easy navigation.

Integrated Package Management: Simplifies the installation and management of R packages.

Version Control: Built-in support for Git to manage code versions and collaboration.

Projects: Organize workspaces efficiently using RStudio Projects.



## RStudio Projects?

::::{.columns}

:::{.column}

- Organization: Keeps related files (scripts, data, outputs) in one place.

- Reproducibility: Facilitates reproducible research by maintaining a consistent environment.

- Isolation: Projects can have their own libraries and settings, reducing conflicts between different projects.

:::

:::{.column}

```{r, echo = FALSE, out.width="80%", fig.alt = "R project organisation"}
knitr::include_graphics("images/Project.png")
```

:::

::::

## Creating a Project in RStudio

- Start a New Project: Go to File > New Project.

- Choose a Type: Select whether to create a new directory, use an existing one, or version control.

- Maintain Structure: Follow a structured directory format (e.g., /data, /scripts, /results).

- Within Project options - turn off options to save history and generate/import .RData files


## Workflow

```{r, echo = FALSE, out.width="60%", fig.alt = "Allison Horst"}
knitr::include_graphics("images/annotated.png")
```


# Questions? {background-color="#D9DBDB"}


- We have three introductory sections of coursework

Chapters 1 &2 are basic navigation and R operations

Chapter 3 is setting up a fresh project and loading data

```{r}
#| label: ex-getting-started
countdown::countdown(
  minutes = 40,
  color_border = "#00AEEF",
  color_text = "#00AEEF",
  color_running_text = "white",
  color_running_background = "#00AEEF",
  color_finished_text = "#00AEEF",
  color_finished_background = "white",
  top = 0,
  margin = "0.8em",
  font_size = "2em"
)
```

# Data wrangling {background-color="#D9DBDB"}


## Tidy data

- Tidy data is a standardized way of organizing data values within a dataset.
- Each variable forms a column.
- Each observation forms a row.
- Each type of observational unit forms a table.

## Why is Tidy Data Important?
- Makes data easier to manipulate, analyze, and visualize.
- Simplifies data cleaning and preparation tasks.
- Enhances reproducibility and collaboration.

## Example of Tidy Data


| Name   | Age | Height |
|--------|-----|--------|
| John   | 23  | 180    |
| Alice  | 25  | 165    |
| Bob    | 22  | 175    |

## Example of Non-Tidy Data

| Name   | John | Alice | Bob   |
|--------|------|-------|-------|
| Age    | 23   | 25    | 22    |
| Height | 180  | 165   | 175   |

## Converting Non-Tidy Data to Tidy Data

Identify variables and observations.

Restructure data so that each variable forms a column and each observation forms a row.

## Example

::: columns
::: {.column}



| Variable | John | Alice | Bob |
|----------|------|-------|-----|
| Age      | 23   | 25    | 22  |
| Height   | 180  | 165   | 175 |

:::

:::{.column}

| Name   | Age | Height |
|--------|-----|--------|
| John   | 23  | 180    |
| Alice  | 25  | 165    |
| Bob    | 22  | 175    |

:::

:::

## Another example

| Subject | Treatment_A | Treatment_B |
|---------|-------------|-------------|
| John    | 80          | 85          |
| Alice   | 90          | 95          |
| Bob     | 85          | 80          |


## Tidy data for treatments

| Subject | Treatment | Score |
|---------|-----------|-------|
| John    | A         | 80    |
| John    | B         | 85    |
| Alice   | A         | 90    |
| Alice   | B         | 95    |
| Bob     | A         | 85    |
| Bob     | B         | 80    |


## Tidy data is long

::: columns
::: {.column}

```{r, eval = T, echo = F}
library(tibble)
library(tidyr)
data <- tibble(
  Subject = c("John", "Alice", "Bob"),
  Treatment_A = c(80, 90, 85),
  Treatment_B = c(85, 95, 80)
)

```



```{r}

  data 


```

:::

:::{.column}

```{r}
data %>%
  pivot_longer(cols = starts_with("Treatment"),
               names_to = "Treatment",
               values_to = "Score")
```

:::

:::

## Benefits of tidy data

- Messy data can be messy in lots of different ways

- Tidy data is always consistent

- Our work as an analyst is easier if we can use consistent tools to work with our data

## What is the Tidyverse?

::::{.columns}

:::{.column}

- The **tidyverse** is a collection of R packages designed for data science.

- Developed by **Hadley Wickham**, it provides powerful tools for data wrangling and visualization.

- they help make data *tidy* and work with manipulating and cleaning *tidy* data to generate insights

:::

:::{.column}

- Core packages include:

  - **dplyr**: Data manipulation
  - **tidyr**: Data tidying
  - **readr**: Data import
  - **purrr**: Functional programming
  - **ggplot2**: Data visualization
  - **tibble**: Modern data frames

:::

::::

## Loading the Tidyverse
- Load the tidyverse with:
  
```{r, echo = T, eval = T, message = T, warning = T}
  library(tidyverse)
```

## What is Data Wrangling?

Data wrangling involves: 

- Cleaning 

- Checking

- Transforming

Raw data into a usable format.

This process is essential for effective analysis and visualization.

## Keeping Raw Data Raw

By keeping raw data intact:

- **Integrity**: You preserve the original dataset for reference.

- **Reproducibility**: Enables others to verify your work and replicate analyses.

- **Transparency**: Allows tracking of changes made during the wrangling process.

[Data Organization in Spreadsheets](https://www.tandfonline.com/doi/full/10.1080/00031305.2017.1375989)

## Documenting Data Manipulations

When we have a script we are maintaining a history of data checks and manipulations:

- Helps in understanding decisions made during analysis.

- Supports data integrity by enabling audits and reviews.

## What is dplyr?

**dplyr** is a key package in the tidyverse focused on data manipulation.

It provides six essential functions, known as the **"Wickham Six"**, for intuitive data wrangling.

## The Wickham Six Functions

| Function   | Description                                      |
|------------|--------------------------------------------------|
| `select()` | Include or exclude specific columns.            |
| `filter()` | Include or exclude specific rows.               |
| `mutate()` | Create new columns or modify existing ones.     |
| `arrange()`| Change the order of rows.                       |
| `group_by()`| Organize data into groups for analysis.       |
| `summarise()`| Create summary statistics for groups.        |

## Introducing the Palmer Penguins Dataset

The **palmerpenguins** dataset includes data on penguin species, bill length, flipper length, and more.

It’s a great resource for practicing data wrangling in R.

To get started, load the dataset:

```{r, eval = F, echo = T}
# IMPORT DATA ----
penguins <- read_csv ("data/penguins_raw.csv")

head(penguins) # check the data has loaded, prints first 10 rows of dataframe
#__________________________----
```

```{r, echo = F}

library(palmerpenguins)

penguins

```

## Using select()

Purpose: Choose specific columns from a data frame.

Example:

```{r, echo = T}
penguins %>% 
  select(species, bill_length_mm, flipper_length_mm)

```

## Using filter()

Purpose: Filter rows based on conditions.

Example:


```{r, echo = T}
penguins %>% filter(bill_length_mm > 40)

```

## Using mutate()


Purpose: Add or modify columns.

Example:


```{r, echo = T}
 penguins %>% mutate(bill_length_cm = bill_length_mm / 10)
```

## Using arrange()

Purpose: Sort rows by specific columns.

Example:


```{r, echo = T}

penguins %>% arrange(desc(flipper_length_mm))

```


## Using group_by()

Purpose: Group data for summary operations.

Example:


```{r, echo = T}
penguins %>% group_by(species)
```

## Using summarise()

Purpose: Create summary statistics for grouped data.

Example:


```{r, echo = T}
penguins %>% 
  group_by%>% 
  summarise(avg_bill_length = mean(bill_length_mm, na.rm = TRUE))
```

## Example Workflow with Palmer Penguins


Wrangle data while preserving the raw dataset:


```{r, echo = T}

penguins_cleaned <- penguins %>%
  filter(!is.na(bill_length_mm)) %>%
  mutate(bill_length_cm = bill_length_mm / 10) %>%
  arrange(species)

penguins_cleaned

```

## Documenting Your Work

Always comment your code:


```{r, echo = T}
# Filtering out missing values and converting bill length to cm
penguins_cleaned <- penguins %>%
  filter(!is.na(bill_length_mm)) %>%
  mutate(bill_length_cm = bill_length_mm / 10) %>%
  arrange(species)
```


## Recap and Next Steps

```{r}
#| label: ex-data-wrangling
countdown::countdown(
  minutes = 40,
  color_border = "#00AEEF",
  color_text = "#00AEEF",
  color_running_text = "white",
  color_running_background = "#00AEEF",
  color_finished_text = "#00AEEF",
  color_finished_background = "white",
  top = 0,
  margin = "0.8em",
  font_size = "2em"
)
```

We introduced the tidyverse and focused on dplyr for data wrangling using the palmer penguins dataset.


Emphasized the importance of keeping raw data raw and documenting manipulations for transparency.

# Questions and Discussion   {background-color="#D9DBDB"}


# Introduction to ggplot  {background-color="#D9DBDB"}

## Why do we need to visualise data?

::::{.columns}

:::{.column}

```{r, echo = FALSE, out.width = "60%"}
library(datasauRus)
  datasaurus_dozen %>% 
    group_by(dataset) %>% 
    summarize(
      mean_x    = mean(x),
      std_dev_x = sd(x),
    ) %>% 
    gt::gt()
```

:::

:::{.column}

```{r, echo = FALSE, out.width = "100%", warning = FALSE}

datasaurus_dozen %>% 
    group_by(dataset) %>% 
    summarize(
      mean_x  = mean(x),
      std_dev_x = sd(x),
    ) %>% 
  ggplot(aes(x = dataset,
         y = mean_x,
         colour = dataset,
         fill = dataset)) +
geom_errorbar(aes(ymin = mean_x-std_dev_x, 
              ymax = mean_x+std_dev_x),
              width = .8)+
  geom_col(width = .8, size = .8, colour = "black") +
  scale_y_continuous(limits = c(0,75), expand = expansion(mult = c(0, .1)))+
   theme_classic()+
   theme(legend.position = "none")


```

:::

::::

##

```{r, echo = FALSE, out.width="100%", fig.alt = "data points make the shape of a dinosaur", fig.cap = "When we visualise the data we can see trends or patterns we might otherwise miss"}
  ggplot(datasaurus_dozen, aes(x = x, y = y, colour = dataset))+
    geom_point()+
    theme_void()+
    theme(legend.position = "none")+
    facet_wrap(~dataset, ncol = 3)

```


Originally created by Alberto Cairo in [Download the Datasaurus: Never trust summary statistics alone; always visualize your data](http://www.thefunctionalart.com/2016/08/download-datasaurus-never-trust-summary.html)



## The problem with dynamite plots

```{r, echo = FALSE, out.width="90%", fig.alt = "A multitude of different patterns appear when visualising the data", fig.cap = "These datasets all have the same mean and standard deviation"}
knitr::include_graphics("images/dynamite-plots.png")
```

Weissgerber TL, Milic NM, Winham SJ, Garovic VD (2015) [Beyond Bar and Line Graphs: Time for a New Data Presentation Paradigm. PLoS Biol 13(4): e1002128.](https://doi.org/10.1371/journal.pbio.1002128) 



## Exploring data


```{r, echo = FALSE, out.width="100%"}
library(palmerpenguins)
penguins %>% 
  ggplot(aes(y = species, x = flipper_length_mm))+
  geom_boxplot()+
  theme_classic(base_size = 18)

```

##

```{r, include = FALSE}
library(patchwork)
```

```{r, include = FALSE}
plot_a <- penguins %>% ggplot(aes(y = species, x = flipper_length_mm))+
  geom_boxplot(outlier.shape  =NA)+
  geom_jitter(height = 0.2,
              alpha = 0.6)+
  theme_classic(base_size = 18)

```

```{r, include = FALSE}
plot_b <- penguins %>% ggplot(aes(y = species, x = flipper_length_mm))+
  ggridges::geom_density_ridges(aes())+ 
  geom_point(
    shape = "|",
    size = 3,
    position = position_nudge( y = -0.1)
    )+
    theme_classic(base_size = 18)

```

```{r, echo = FALSE, out.width="100%", warning = FALSE}
plot_a/
  plot_b

```

## Visualisation according to statisticians


```{r, echo = FALSE, out.width="85%", fig.alt = "Visualization According to Statisticians: An Interview Study on the Role of Visualization for Inferential Statistics: https://arxiv.org/pdf/2309.12684.pdf"}

knitr::include_graphics("images/things_statisticians_say.png")
```


## A **grammar** of graphics

* `ggplot2` is an application of the **grammar of graphics** for R  

:::{.fragment}

* A default dataset and set of mappings from variables to aesthetics  
* One or more layers of geometric objects    
* One scale for each aesthetic mapping used  
* A coordinate system  
* The facet specification  

:::



## A **grammar** of graphics, from [**ggplot2 as a creativity engine**](https://johnburnmurdoch.github.io/slides/r-ggplot/#/)  

::::{.columns}

:::{.column}


```{r, include = FALSE}
library(patchwork)
library(ggimage)

fruitfly <- readRDS(here::here("data", "fruitfly.rds"))

flyls2 <- lm(longevity ~ type + thorax + sleep, data = fruitfly)

  model_data <- emmeans::emmeans(flyls2, specs = ~ type + thorax,
                at=list(thorax=seq(.64,.96, by =.04))) %>% 
  as_tibble()
  
  colours <- c("cyan", "darkorange", "purple")
  
  dros_img <- here::here("docs", "images", "dros.jpg")
```

Easy enough to [*rapidly prototype*](https://johnburnmurdoch.github.io/slides/r-ggplot/#/14) graphics at the "speed of thought"  

```{r, warning = FALSE, echo = FALSE}

fruitfly %>% 
  ggplot()+
  aes(x = thorax,
      y = longevity,
      colour = type)+
  geom_point()

```

:::

:::{.column}

Powerful enough for [*final "publication"*](https://johnburnmurdoch.github.io/slides/r-ggplot/#/34)  

```{r, warning = FALSE, echo = FALSE}
# density plot of thorax length by treatment
marginal1 <- fruitfly %>% 
  ggplot()+
  geom_density(aes(x = thorax, fill = type),
               alpha = 0.5)+
  scale_fill_manual(values = colours)+
  theme_void()+
  theme(legend.position = "none")

# density plot of longevity by treatment
marginal2 <- fruitfly %>% 
  ggplot()+
  geom_density(aes(x = longevity, fill = type),
               alpha = 0.5)+
  scale_fill_manual(values = colours)+
  theme_void()+
  coord_flip()


# use the final model to produce model predictions set to the new constant sleep dataframe
model_plot <- model_data %>%  
  ggplot(aes(x=thorax, y = emmean, colour = type, fill = type))+
  geom_ribbon(aes(ymin=lower.CL, ymax=upper.CL), alpha = 0.2)+
  geom_line(linetype = "dashed", show.legend = FALSE)+
  geom_point(data = fruitfly, aes(x = thorax, y = longevity),
             show.legend = FALSE)+
  scale_colour_manual(values = colours)+
  scale_fill_manual(values = colours)+
  labs(y = "Lifespan in days",
       x = "Thorax length (mm)",
       fill = "Type of female exposure")+
  guides(colour = "none")+
  theme_classic()+
  theme(legend.position = "none")+
  geom_image( x = .7, y = 80, aes(image = dros_img),
              size = .2, by="height",
              inherit.aes = FALSE)

layout <- "
AAA#
BBBC
BBBC
BBBC"


marginal1+model_plot+marginal2 +plot_layout(design = layout)

```


:::

::::




##


::::{.columns}

:::{.column width="40%"}


```{r, eval = FALSE, echo = T}
ggplot(data = penguins, 
       aes(x = bill_depth_mm,#<<
           y = body_mass_g))#<<


```

:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}
theme_set(theme_gray(base_size = 18))

penguins <- penguins |> 
  mutate(species = fct_relevel(species, "Chinstrap", "Gentoo", "Adelie")) 

ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g))


```

:::

::::

##

::::{.columns}

:::{.column width="40%"}

```{r, eval = FALSE, echo = T}
ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g))+
         geom_point()#<<


```

:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}


ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g))+
         geom_point()


```

:::

::::

##

::::{.columns}

:::{.column width="40%"}


```{r, eval = FALSE, echo = T}
ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g))+
         geom_point(colour = "red")#<<


```

:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}

ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g))+
         geom_point(colour = "red")


```

:::

::::

##

::::{.columns}

:::{.column width="40%"}


```{r, eval = FALSE, echo = T}
ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g))+
         geom_point(aes(#<<
           colour = species))#<<


```

:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}

ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g))+
       geom_point(aes(colour = species))


```

:::

::::

##

::::{.columns}

:::{.column width="40%"}


```{r, eval = FALSE, echo = T}
ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g,
           colour = species))+#<<
         geom_point()+
  geom_smooth(method = "lm", #<<
              se = FALSE)#<<


```

:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}

ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g,
           colour = species))+#<<
         geom_point()+
  geom_smooth(method = "lm", se = FALSE)#<<


```

:::

::::

##

::::{.columns}

:::{.column width="40%"}


```{r, eval = FALSE, echo = T}
ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g,
           colour = species))+
         geom_point()+
  geom_smooth(method = "lm", 
              se = FALSE)+
  labs(x = "Body mass (g)",#<<
       y = "Flipper length (mm)")#<<


```

:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}
ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g,
           colour = species))+
         geom_point()+
  geom_smooth(method = "lm", 
              se = FALSE)+
  labs(x = "Body mass (g)",#<<
       y = "Flipper length (mm)")#<<
  


```

:::

::::

##

::::{.columns}

:::{.column width="40%"}


```{r, eval = FALSE, echo = T}
ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g,
           colour = species))+
         geom_point()+
  geom_smooth(method = "lm", 
              se = FALSE)+
  labs(x = "Body mass (g)",
       y = "Flipper length (mm)")+
  scale_color_manual(
    values = c("darkolivegreen4", #<<
               "darkorchid3", #<<
               "goldenrod1"))#<<

```

:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}

ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g,
           colour = species))+
         geom_point()+
  geom_smooth(method = "lm", se = FALSE)+
  labs(x = "Body mass (g)",
       y = "Flipper length (mm)")+
  scale_color_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))#<<


```

:::

::::

##

::::{.columns}

:::{.column width="40%"}



```{r, eval = FALSE, echo = T}
ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g,
           colour = species))+
         geom_point()+
  geom_smooth(method = "lm", 
              se = FALSE)+
  labs(x = "Body mass (g)",
       y = "Flipper length (mm)")+
  scale_color_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic()#<<

```

:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}

ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g,
           colour = species))+
         geom_point()+
  geom_smooth(method = "lm", 
              se = FALSE)+
  labs(x = "Body mass (g)",
       y = "Flipper length (mm)")+
  scale_color_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic(base_size = 18)


```

:::

::::



## Know your ABC's



### **A**ccurate



### **B**eautiful



### **C**lear


## Principles for clear data visualisation

:::{.incremental}

- Maximally distinguished

- Accessible data

- Appropriate axes

- Measures of variability

- Provide finescale data

- Non-overlapping data

:::


## Maximally distinguished

```{r, echo = FALSE, fig.alt = " Shape vs colours"}

knitr::include_graphics("images/shape_v_colour.png")
```


## Maximally distinguished


```{r, echo = FALSE, fig.alt = " Order of accessibility"}

knitr::include_graphics("images/list.png")
```




## Check palettes

```{r}

library(colorBlindness)

colorBlindness::cvdPlot() 

```


## Colour palettes

::::{.columns}

:::{.column width="40%"}

```{r, eval = FALSE, echo = TRUE}

library(viridis)

ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g,
           colour = species))+
         geom_point()+
  geom_smooth(method = "lm", 
              se = FALSE)+
  labs(x = "Body mass (g)",
       y = "Flipper length (mm)") +
  scale_colour_viridis(discrete = T) +
  theme_classic(base_size = 18)


```

:::


:::{.column width="60%"}

```{r}

library(viridis)

ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g,
           colour = species))+
         geom_point()+
  geom_smooth(method = "lm", 
              se = FALSE)+
  labs(x = "Body mass (g)",
       y = "Flipper length (mm)") +
  scale_colour_viridis(discrete = T) +
  theme_classic(base_size = 18)

```

:::

::::

## Jitter

::::{.columns}

:::{.column width="40%"}

```{r, eval = FALSE, echo = T}
ggplot(data = penguins, 
       aes(x = species,
           y = body_mass_g,
           colour = species))+
         geom_point()+#<<
  labs(x = "Species",
       y = "Body mass (g)")+
  scale_color_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic()+
  theme(legend.position = "none")

```


:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}
ggplot(data = penguins, 
       aes(x = species,
           y = body_mass_g,
           colour = species))+
        geom_point()+
  labs(x = "Species",
       y = "Body mass (g)")+
  scale_color_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic(base_size = 18)+
  theme(legend.position = "none")


```

:::

::::



## Jitter

::::{.columns}

:::{.column width="40%"}


```{r, eval = FALSE, echo = T}
ggplot(data = penguins, 
       aes(x = species,
           y = body_mass_g,
           colour = species))+
         geom_jitter(#<<
           width = 0.2)+#<<
  labs(x = "Species",
       y = "Body mass (g)")+
  scale_color_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic()+
  theme(legend.position = "none")

```
Also see [`ggbeeswarm`](https://github.com/eclarke/ggbeeswarm)

:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}

ggplot(data = penguins, 
       aes(x = species,
           y = body_mass_g,
           colour = species))+
        geom_jitter(width = 0.2)+
  labs(x = "Species",
       y = "Body mass (g)")+
  scale_color_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic(base_size = 18)+
  theme(legend.position = "none")


```

:::

::::

## Beeswarm

::::{.columns}

:::{.column width="40%"}


```{r, eval = FALSE, echo = T}

library(ggbeeswarm)

ggplot(data = penguins, 
       aes(x = species,
           y = body_mass_g,
           colour = species))+
         geom_beeswarm()+#<<
  labs(x = "Species",
       y = "Body mass (g)")+
  scale_color_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic()+
  theme(legend.position = "none")

```


:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}
library(ggbeeswarm)

ggplot(data = penguins, 
       aes(x = species,
           y = body_mass_g,
           colour = species))+
        geom_beeswarm()+#<<
  labs(x = "Species",
       y = "Body mass (g)")+
  scale_color_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic(base_size = 18)+
  theme(legend.position = "none")


```

:::

::::



## Stacked bars

::::{.columns}

:::{.column width="40%"}


```{r, eval = FALSE, echo = T}
penguins %>%     
  group_by(species) %>% #<<
    summarise(n=n()) %>% #<<
ggplot(aes(x = " ",
           y = n,
           fill = species))+
        geom_col()+ #<<
  labs(x = " ",
       y = "Count")+
  scale_fill_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic()

```


:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}

penguins %>%     
  group_by(species) %>% 
    summarise(n=n()) %>% 
ggplot(aes(x = " ",
           y = n,
           fill = species))+
        geom_col()+
  labs(x = " ",
       y = "Count")+
  scale_fill_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic(base_size = 18)


```

:::

::::



## Dodged plots

::::{.columns}

:::{.column width="40%"}

```{r, eval = FALSE, echo = T}
penguins %>%     
  group_by(species) %>% 
    summarise(n=n()) %>% 
ggplot(aes(x = species, 
           y = n,
           fill = species))+
        geom_col()+
  labs(x = "Species",
       y = "Count")+
  scale_fill_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic()+
  theme(legend.position = "none")
  

```


:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}

penguins %>%     
  group_by(species) %>% 
    summarise(n=n()) %>% 
ggplot(aes(x = species, #<<
           y = n,
           fill = species))+
        geom_col()+
  labs(x = "Species",
       y = "Count")+
  scale_fill_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic(base_size = 18)+
  theme(legend.position = "none")


```

:::

::::




## Labels

::::{.columns}

:::{.column width="40%"}


```{r, echo = FALSE}
plot <- penguins %>%     
  group_by(species) %>% 
    summarise(n=n()) %>% 
ggplot(aes(x = species, #<<
           y = n,
           fill = species))+
        geom_col()+
  labs(x = "Species",#<<
       y = "Count")+
  scale_fill_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic(base_size = 18)+
  theme(legend.position = "none")#<<
```



```{r, eval = FALSE, echo = T}

plot + 
  annotate("text",
           x = 1:3,
           y = c(72, 128, 156),
           label = c(68, 124, 152))
  

```

:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}
plot + 
  annotate("text",
           x = 1:3,
           y = c(72, 128, 156),
           label = c(68, 124, 152))

```

:::

::::



## Labels

::::{.columns}

:::{.column width="40%"}

```{r, eval = FALSE, echo = T}

plot + 
 geom_label(aes(label = n),
            fill = "white",
            nudge_y = 1,
            colour = "black",
            fontface = "bold")
  

```


:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}

plot + 
 geom_label(aes(label = n),
            fill = "white",
            nudge_y = 1,
            colour = "black",
            fontface = "bold")


```

:::

::::

## Axes

```{r, include =  FALSE}

set.seed(123)
df <- data.frame(
  Category = rep(c("Group_A", "Group_B"), each = 100),
  Value = c(rgamma(100, shape = 2, rate = 0.2),  # Larger values
            rgamma(100, shape = 2, rate = 2))   # Smaller values
)


```



::::{.columns}

:::{.column}

```{r}

ggplot(df, aes(x = Category, y = Value)) +
    geom_beeswarm() +
     labs(
         x = "Category",
         y = "Value")

```

:::

:::{.column}

```{r}
library(scales)

ggplot(df, aes(x = Category, y = Value)) +
    geom_beeswarm() +
    scale_y_log10(labels = label_log()) +
    labs(title = "Example: Two Categories with Log-Scaled Y-axis",
         x = "Category",
         y = "Value (log scale)")

```

:::

::::

## Facets

::::{.columns}

:::{.column width="40%"}


```{r, eval = FALSE, echo = T}

ggplot(penguins,
       aes(x = body_mass_g,
           fill = species))+
        geom_density(
       alpha = 0.4)+
  labs(y = "Density")+
  scale_fill_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic()+
  theme(legend.position = "none")+
  facet_wrap(~species)#<<


```



:::

:::{.column}


```{r, eval = T}

ggplot(penguins,
       aes(x = body_mass_g,
           fill = species))+
        geom_density(
       alpha = 0.4)+
  labs(y = "Density")+
  scale_fill_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic(base_size = 18)+
  theme(legend.position = "none")+
  facet_wrap(~species)

  

```


:::

::::

---

## Highlights

::::{.columns}

:::{.column width="40%"}


```{r, eval = FALSE, echo = T}

library(gghighlight)

ggplot(penguins,
       aes(x = body_mass_g,
           fill = species))+
        geom_density(
       alpha = 0.4)+
  gghighlight()+#<<
  labs(y = "Density")+
  scale_fill_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic()+
  theme(legend.position = "none")+
  facet_wrap(~species)
  

```

:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}

library(gghighlight)

ggplot(penguins,
       aes(x = body_mass_g,
           fill = species))+
        geom_density(
       alpha = 0.4)+
  gghighlight()+#<<
  labs(y = "Density")+
  scale_fill_manual(
    values = c("darkolivegreen4", 
               "darkorchid3", 
               "goldenrod1"))+
  theme_classic(base_size = 18)+
  theme(legend.position = "none")+
  facet_wrap(~species)


```

:::

::::


## Multiple plots


::::{.columns}

:::{.column width="40%"}

```{r, eval = FALSE, echo = T}


# density plot of thorax length by treatment
marginal1 <- fruitfly %>% 
  ggplot()+
  geom_density(aes(x = thorax, fill = type),
               alpha = 0.5)+
  scale_fill_manual(values = colours)+
  theme_void()+
  theme(legend.position = "none")

marginal1

```

:::

:::{.column width = "60%"}

```{r, echo = FALSE}




# density plot of thorax length by treatment
 fruitfly %>% 
  ggplot()+
  geom_density(aes(x = thorax, fill = type),
               alpha = 0.5)+
  scale_fill_manual(values = colours)

```

:::

::::

## Multiple plots


::::{.columns}

:::{.column width="40%"}

```{r, eval = FALSE, echo = T}

model_plot <- model_data %>%  
  ggplot(aes(x=thorax, y = emmean, colour = type, fill = type))+
  geom_ribbon(aes(ymin=lower.CL, ymax=upper.CL), alpha = 0.2)+
  geom_line(linetype = "dashed", show.legend = FALSE)+
  geom_point(data = fruitfly, aes(x = thorax, y = longevity),
             show.legend = FALSE)+
  scale_colour_manual(values = colours)+
  scale_fill_manual(values = colours)+
  labs(y = "Lifespan in days",
       x = "Thorax length (mm)",
       fill = "Type of female exposure")+
  guides(colour = "none")+
  theme_classic()+
  theme(legend.position = "none")+
  geom_image( x = .7, y = 80, aes(image = dros_img),
              size = .2, by="height",
              inherit.aes = FALSE)

model_plot

```

:::

:::{.column width = "60%"}


```{r}

model_plot <- model_data %>%  
  ggplot(aes(x=thorax, y = emmean, colour = type, fill = type))+
  geom_ribbon(aes(ymin=lower.CL, ymax=upper.CL), alpha = 0.2)+
  geom_line(linetype = "dashed", show.legend = FALSE)+
  geom_point(data = fruitfly, aes(x = thorax, y = longevity),
             show.legend = FALSE)+
  scale_colour_manual(values = colours)+
  scale_fill_manual(values = colours)+
  labs(y = "Lifespan in days",
       x = "Thorax length (mm)",
       fill = "Type of female exposure")+
  guides(colour = "none")+
  theme_classic()+
  theme(legend.position = "none")+
  geom_image( x = .7, y = 80, aes(image = dros_img),
              size = .2, by="height",
              inherit.aes = FALSE)

model_plot

```

:::

::::

## Multiple plots


::::{.columns}

:::{.column width="40%"}


```{r, eval = FALSE, echo = T}

library(patchwork)

layout <- 
"AAA#
BBBC
BBBC
BBBC"


marginal1+model_plot+marginal2 + plot_layout(design = layout)

```

:::

:::{.column width = "60%"}


```{r}

library(patchwork)

layout <- 
"AAA#
BBBC
BBBC
BBBC"


marginal1+model_plot+marginal2 + plot_layout(design = layout)

```


:::

::::



## Legend positions

::::{.columns}

:::{.column width="40%"}


```{r, echo = FALSE}

plot <- ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g,
           colour = species))+
         geom_point()+
  geom_smooth(method = "lm", 
              se = FALSE)+
  labs(x = "Body mass (g)",
       y = "Flipper length (mm)")+
  scale_color_manual(
    values = c("darkolivegreen4", #<<
               "darkorchid3", #<<
               "goldenrod1"))+
  theme_classic(base_size = 18)#<<

```



```{r, eval = FALSE, echo = T}

plot +
  theme(legend.position = c(0.7,  #<<
                            0.8))  #<<

```

:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}

plot +
  theme(legend.position = c(0.7, 0.8)) #<<


```

:::

::::

## Legend positions

::::{.columns}

:::{.column width="40%"}


```{r, echo = FALSE}

plot <- ggplot(data = penguins, 
       aes(x = bill_depth_mm,
           y = body_mass_g,
           colour = species))+
         geom_point()+
  geom_smooth(method = "lm", 
              se = FALSE)+
  labs(x = "Body mass (g)",
       y = "Flipper length (mm)")+
  scale_color_manual(
    values = c("darkolivegreen4", #<<
               "darkorchid3", #<<
               "goldenrod1"))+
  theme_classic(base_size = 18)#<<

```



```{r, eval = FALSE, echo = T}

plot +
  theme(legend.position = "top") #<<
```

:::

:::{.column width="60%"}

```{r, echo = FALSE, fig.width = 10}

plot +
  theme(legend.position = "top") #<<


```

:::

::::


## ggforce

```{r, warning = FALSE, message = FALSE, fig.width = 12}

penguins |> 
    ggplot(
        aes(x = bill_length_mm,
            y= body_mass_g,
            colour = species)) +
    geom_point(aes(fill = species), shape = 21, colour = "white") +
    geom_smooth(method = "lm", se = FALSE,linetype = "dashed", alpha = .4)+
ggforce::geom_mark_ellipse(aes(
    label = species,
    filter = species == 'Adelie'),
    con.colour  = "#526A83",
    con.cap = 0,
    con.arrow = arrow(ends = "last",
                      length = unit(0.5, "cm")),
    show.legend = FALSE) +
    gghighlight::gghighlight(species == "Adelie")+
  scale_colour_manual(    values = c("darkolivegreen4", #<<
               "darkorchid3", #<<
               "goldenrod1"))+
  scale_fill_manual(    values = c("darkolivegreen4", #<<
               "darkorchid3", #<<
               "goldenrod1"))+
    theme_classic(base_size = 18)#<<

```

## geomtextpaths

```{r, fig.width = 12}
library(geomtextpath)

penguins |> 
    ggplot(aes(x = bill_length_mm, 
               colour = species,
               label = species))+
  geom_textdensity( hjust = 0.35, vjust = .1)+ 
  scale_colour_manual(    values = c("darkolivegreen4", #<<
               "darkorchid3", #<<
               "goldenrod1"))+
    theme_classic(base_size = 18)+
  theme(legend.position = "none")

```

## ggtext

```{r, warning = FALSE, message = FALSE, fig.width= 12}
library(ggtext)


penguins |> 
  mutate(species = fct_relevel(species, "Chinstrap", "Gentoo", "Adelie")) |> 
  group_by(species) |> 
    summarise(n=n()) |> 
ggplot(aes(x = species,
           y = n,
           fill = species))+
        geom_col()+
  geom_label(aes(label = n),
            fill = "white",
            nudge_y = 1,
            colour = "black",
            fontface = "bold")+
  labs(x = "",
       y = "Count",
       title = paste(
         'There are almost half the observations on <br> <span style = "color:#556b2f">Chinstrap</span> penguins,  as there are <br> on <span style = "color:#daa520">Adelie</span> and <span style ="color:#9932CC">Gentoo</span> penguins'
       ))+
  scale_fill_manual(
    # when reordering levels - be careful about keeping colours consistent!!! May need manually sorting
      values = c("darkolivegreen4", #<<
               "darkorchid3", #<<
               "goldenrod1"))+
  coord_flip()+
  scale_y_continuous(limits = c(0, 200))+
    theme_classic(base_size = 18)+
  theme(legend.position = "none",
        axis.text.y = element_text(),
      plot.title = element_markdown())

```


## Keep learning

[R Cheat Sheets](https://www.rstudio.com/resources/cheatsheets/)

[Fundamentals of Data Visualisation](https://clauswilke.com/dataviz/)

[Beautiful plotting in R](https://www.cedricscherer.com/2019/08/05/a-ggplot2-tutorial-for-beautiful-plotting-in-r/)

[The ggplot2 book](https://ggplot2-book.org/)

[The ggplot extensions library](https://exts.ggplot2.tidyverse.org/)

## Exercise: getting to grips with ggplot

```{r}
#| label: ex-ggplot
countdown::countdown(
  minutes = 40,
  color_border = "#00AEEF",
  color_text = "#00AEEF",
  color_running_text = "white",
  color_running_background = "#00AEEF",
  color_finished_text = "#00AEEF",
  color_finished_background = "white",
  top = 0,
  margin = "0.8em",
  font_size = "2em"
)
```

# Understanding Data Quality  {background-color="#D9DBDB"}

## Importance of data quality

## Missing  data

The first issue we will cover is missing data. There is a whole host of reasons that your data could have missing values.

## Missing data {.smaller}

This can be broken down into three broad categories:

:::{.incremental}

- **MCAR (Missing Completely at Random)**	The probability of missing data is independent of any observed or unobserved data.	

- Leaf samples lost randomly due to a labeling error in a plant growth study.

- **MAR (Missing at Random)	** The probability of missing data is related to some observed data but not to the missing data itself.	

- Blood pressure readings missing more frequently for older patients in a drug trial.

- **MNAR (Missing Not at Random)**	The probability of missing data is related to the value of the missing data itself.	

- Heavier birds in a wildlife study are harder to capture and weigh, leading to missing weight data.

:::

## Missing data

Lots of ways to gather information on missing data:

```{r, echo = T}

summary(penguins)

```

And ways to remove it:

```{r, echo = T, eval = F}

drop_na(penguins)

drop_na(penguins, -delta_15n, -delta_13c, -comments)

```

## Mean imputation

- Preserves power

- Mean imputation can introduce bias if data is not **missing completely at random**.

- Reduces variability in the dataset.

- For MAR - we can use multiple imputation methods - see [mice package](https://www.rdocumentation.org/packages/mice/versions/3.17.0/topics/mice).

- MNAR very specialist

```{r, echo = T, eval = F}
penguins %>% 
  group_by(species, sex) %>% 
  mutate(body_mass_g = replace_na(body_mass_g, mean(body_mass_g, na.rm = T))) %>% 
  ungroup()

```

## Duplications

Duplications can skew results and reduce reliability of our data insights

```{r, eval = T, echo = T}
# check for duplicate rows in the data
penguins %>% 
  duplicated() %>% # produces a list of TRUE/FALSE statements for duplicated or not
  sum() # sums all the TRUE statements
```

## Data types and consistency

Example: Data is treated as a factor when it should be numerical 

Ensuring correct data types is essential for performing accurate analyses

```{r}

str(penguins)

```

## Implausible values {.smaller}

Values that fall outside of a possible range for a given variable.

- **Categorical**: "Male", "Female", "Mle"

```{r}
penguins %>% 
  distinct(species)

```

- **Continuous**: Negative values for an age, or a date given in the future

```{r}
summary(penguins)

```

## Outliers

::::{.columns}

:::{.column}

Observations that fall outside of a tolerated range from other observations

- > 3* Standard Deviation from the mean

- > 1.5 * Interquartile Range

Important to identify, but crucially these are *real* values

:::

:::{.column}

```{r, echo = T}
penguins %>% ggplot(aes(x = species, y = body_mass_g)) + geom_boxplot() +coord_flip()
```

:::

::::

## Histograms

::::{.columns}

:::{.column}

```{r, fig.width = 7}
library(ggridges)
penguins %>% drop_na(sex) %>% 
ggplot(aes(x = body_mass_g, y = species)) + 
  ggridges::stat_binline(aes(fill = sex),
                alpha = 0.8)

```
:::

:::{.column}
```{r, fig.width = 7}

library(ggridges)
penguins %>% drop_na(sex) %>% 
ggplot(aes(x = body_mass_g, y = species)) + 
  ggridges::stat_binline(aes(fill = sex),
                alpha = 0.8,
                bins = 10)

```
:::

:::{.column}

```{r}

library(ggridges)
penguins %>% drop_na(sex) %>% 
ggplot(aes(x = body_mass_g, y = species)) + 
  ggridges::stat_binline(aes(fill = sex),
                alpha = 0.8,
                bins = 50)

```
:::

::::

## Distributions

How values are spread across a range:

- Normal distribution

- Skewed distribution

- Uniform distribution

Hard to tell even when using a histogram

## QQ plots

::::{.columns}

:::{.column}

If data is normally distributed, then if we plot the [*quantiles*](https://www.youtube.com/watch?v=okjYjClSjOg) vs. theoretical normal quantiles (with same *n*), then we find a linear relationship

:::

:::{.column}


```{r, echo = FALSE, out.width="90%", fig.alt = "QQ plot examples"}
knitr::include_graphics("images/qq_example.png")
```

:::

::::

## Normal distribution

```{r}
# Generate right-skewed data
data_normal <- rnorm(1000, mean =0, sd =1)

# Create histogram and QQ plot
par(mfrow = c(1, 2))
hist(data_normal, main = "Normal distribution", xlab = "Value", col = "lightgreen", border = "black")
qqnorm(data_normal)
qqline(data_normal, col = "red")

```

## Outliers

```{r}
# Generate right-skewed data
data_normal <- rnorm(500, mean =0, sd =1)
data_extra <- rnorm(20, mean = 3, sd = 1)

data_normal <- c(data_normal, data_extra)

# Create histogram and QQ plot
par(mfrow = c(1, 2))
hist(data_normal, main = "Outliers", xlab = "Value", col = "lightgreen", border = "black")
qqnorm(data_normal)
qqline(data_normal, col = "red")

```

## Right-skewed

```{r}
# Generate right-skewed data
data_right_skewed <- rexp(1000)

# Create histogram and QQ plot
par(mfrow = c(1, 2))
hist(data_right_skewed, main = "Right Skewed", xlab = "Value", col = "lightgreen", border = "black")
qqnorm(data_right_skewed)
qqline(data_right_skewed, col = "red")


```

## Left-skewed

```{r}
# Generate left-skewed data
data_left_skewed <- -rexp(1000)

# Create histogram and QQ plot
par(mfrow = c(1, 2))
hist(data_left_skewed, main = "Left Skewed", xlab = "Value", col = "lightcoral", border = "black")
qqnorm(data_left_skewed)
qqline(data_left_skewed, col = "red")


```

## Bimodal

```{r}
# Generate bimodal data
data_bimodal <- c(rnorm(500, mean = -2), rnorm(500, mean = 2))

# Create histogram and QQ plot
par(mfrow = c(1, 2))
hist(data_bimodal, main = " Bimodal", xlab = "Value", col = "lightyellow", border = "black")
qqnorm(data_bimodal)
qqline(data_bimodal, col = "red")



```

## Heavy tailed

```{r}
# Generate heavy-tailed data
data_heavy_tailed <- rt(1000, df = 5)  # T-distribution with low degrees of freedom

# Create histogram and QQ plot
par(mfrow = c(1, 2))
hist(data_heavy_tailed, main = "Heavy-tailed", xlab = "Value", col = "lightblue", border = "black")
qqnorm(data_heavy_tailed)
qqline(data_heavy_tailed, col = "red")


```

## Light tailed

```{r}
# Load necessary library
library(ggplot2)

# Generate light-tailed data with high kurtosis using Beta distribution
set.seed(123)
data_beta <- rbeta(1000, shape1 = 2, shape2 = 2) * 2 - 1  # Scale to [-1, 1]

# Create histogram and QQ plot
par(mfrow = c(1, 2))

# Histogram
hist(data_beta, main = "Light tailed", 
     xlab = "Value", col = "lightblue", border = "black")

# QQ Plot
qqnorm(data_beta)
qqline(data_beta, col = "red")

```

## Uniform

```{r}
# Load necessary library
library(ggplot2)

# Generate light-tailed data with high kurtosis using Beta distribution
set.seed(123)
data_uni <- runif(1000, min = 0, max = 10) # Scale to [-1, 1]

# Create histogram and QQ plot
par(mfrow = c(1, 2))

# Histogram
hist(data_uni, main = "Uniform", 
     xlab = "Value", col = "lightblue", border = "black")

# QQ Plot
qqnorm(data_uni)
qqline(data_uni, col = "red")

```

## Skimr - generate quick overviews of data {.smaller}



```{r, echo = T}

skimr::skim(penguins)

```



## Exercise practice data checking

```{r}
#| label: ex-data-quality
countdown::countdown(
  minutes = 30,
  color_border = "#00AEEF",
  color_text = "#00AEEF",
  color_running_text = "white",
  color_running_background = "#00AEEF",
  color_finished_text = "#00AEEF",
  color_finished_background = "white",
  top = 0,
  margin = "0.8em",
  font_size = "2em"
)
```

- We need to have strategies for removing or correcting errors in the data.

- R scripts give us a record of changes without affecting the integrity of the raw data

- Having a clear series of checks saves time in the long run


# Descriptive Statistics  {background-color="#D9DBDB"}

## Building Statistical Models


::::{.columns}

:::{.column}

A model is a representation of what we think is going on in the real world. It can be a good fit, or a poor fit. 


A well fitted model could be used to make *predictions* about what might happen in the real world. 


A poorly fitted model could also make *predictions* but they might be disastrously wrong.


If we want our inferences to be **accurate** the model must represent the data collected.

:::

:::{.column}

```{r, echo = FALSE, fig.alt = " Model bridges - Andy Field Discovering Statistics"}

knitr::include_graphics("images/bridge.png")
```
:::

::::


## Populations

- The total “pool” you are trying to explore/describe

- You define what it is

- Usually you’re not going to be able to study the entire population, because: time, money, access, resources, support, etc. 

- So instead, we can usually only take a...



## Sample

- Drawn randomly from the population...

- ...to collect observations for variable(s) of interest...

- ...to try to say something meaningful about the population.



## Central tendency & spread

Often we will start with

**Central tendency** - a central or typical value

**Data Spread** - how observations are dispersed

Generally classed as **Descriptive Statistics**

## What is Descriptive Statistics?

- Descriptive statistics summarise and organise data in a clear, understandable way.

- They help us see patterns and trends without diving into deeper analytical methods.

## Central tendency

The **central tendency** of a series of observations is a measure of the “middle value”



The three most commonly reported measures of central tendency are the sample **mean, median, and mode**.


| Mean        | Median      | Mode       |
| ----------- | ----------- |----------- |
| The average value     | The middle value      |The most frequent value      |
| Sum of the total divided by *n*   | The middle value (if *n* is odd). The average of the two central values (if *n* is even)      |The most frequent value      |
| Most common reported measure, affected by outliers | Less influenced by outliers, improves as *n* increases | Less common




## Mean

One of the simplest statistical models in biology is the **mean**

::::{.columns}

:::{.column}

| Lecturer     | Friends |
| ----------- | ----------- |
| Mark      | 5       |
| Tony   | 3     |
| Becky | 3    |
| Ellen   | 2      |
| Phil   | 1     |
| **Mean **  | **2.6**      |
| **Median **  | **3**      |
| **Mode **  | **3**      |


:::

:::{.column}


Calculating the mean:

$$ \bar{x} = \frac{\sum_{i=1}^{n} x_i}{n} $$
$$\frac{5 + 3 + 3 + 2 + 1}{5} = 2.6$$

Sum all the values and divide by n of values

:::

::::



## The mean

One of the simplest statistical models in biology is the **mean**

::::{.columns}

:::{.column}


| Lecturer     | Friends |
| ----------- | ----------- |
| Mark      | 5       |
| Tony   | 3     |
| Becky | 3    |
| Ellen   | 2      |
| Phil   | 1     |
| **Mean **  | **2.6**      |
| **Median **  | **3**      |
| **Mode **  | **3**      |


:::

:::{.column}

We already *know* this is a hypothetical value as you can't have 2.6 friends (I think?)

Now with any model we have to know how well it fits/ how accurate it is

:::

::::



## Symmetrical

If data is symmetrically distributed, the **mean and median** will be close, especially as *n* increases. 

This is also know as a **normal distribution**


```{r, echo = FALSE, out.width = "60%"}
# Load required packages
library(ggplot2)

# Set seed for reproducibility
set.seed(123)

# Generate random sample from a normal distribution
sample_size <- 1000
mu <- 0  # mean
sigma <- 1  # standard deviation
sample <- rnorm(sample_size, mean = mu, sd = sigma)

# Create a data frame with the sample data
df <- data.frame(x = sample)

# Create a histogram plot using ggplot2
ggplot(df, aes(x = x)) +
  geom_histogram(binwidth = 0.2, fill = "lightblue", color = "black") +
  labs(x = "Value", y = "Frequency", title = "Distribution Histogram") +
  theme_classic()


```


## Variance

The average of the squared differences from the mean.


$$s{^2}_{sample} = \frac{\sum(x - \bar{x})^2}{N -1}$$
Sample variance is a robust measure of data spread, a higher variance means more spread.

## Calculating variance

::::{.columns}

:::{.column}

```{r, echo = FALSE, out.width="100%", fig.alt = "Symmetrical sides"}
knitr::include_graphics("images/normal-distribution.jpg")
```

:::

:::{.column}

```

   value residuals squared residuals
 1 12.7      2.88         8.27 
 2 14.2      4.32        18.7  
 3 11.3      1.41         1.99 
 4  7.43    -2.44         5.93 
 5  8.27    -1.60         2.57 
 6 12.7      2.81         7.90 
 7  5.34    -4.53        20.5  
 8 13.9      4.00        16.0  

```

```

  sum of residuals sum of squares  mean
1       -0.0577        359        9.87

```

:::

::::


## N-1? {.smaller}

```{r, echo = FALSE, out.width="30%", fig.alt = "Sampling"}
knitr::include_graphics("images/pop_sam.png")
```

For a *population* the variance $S_p^2$ is exactly the **mean** squared distance of the values from the population mean

$$
s{^2}_{pop} = \frac{\sum(x - \bar{x})^2}{N}
$$



But this is a *biased* estimate for the population variance 

- A biased sample variance will *underestimate* population variance

- n-1 (if you take a large enough sample size, will correct for this)

[More here](https://www.jamelsaadaoui.com/unbiased-estimator-for-population-variance-clearly-explained/#:~:text=The%20expected%20value%20of%20the%20sample%20variance%20is%20equal%20to,definition%20of%20an%20unbiased%20estimator.)



## Standard Deviation

- Square root of **sample variance**

- A measure of dispersion of the sample

- Smaller SD = more values closer to mean, larger SD = greater data spread from mean

* *variance*:

$$
\sigma = \sqrt{\sum(x - \overline x)^2\over n - 1}
$$


## Standard deviation - our example

Lecturer     | Friends | Diff | Squared diff |
  ------------ | ------- | --- | ------ |
  Mark         | 5       | 2.4  | 5.76    |
  Tony         | 3       | 0.4  | 0.16    |
  Becky        | 3       | 0.4  | 0.16    |
  Ellen        | 2       | -0.6  | 0.36    |
  Phil         | 1       | -1.6  | 2.56    |   
|  **Mean **  | **2.6**      |
| **variance** | **2.2** |
| **SD **  | **1.4**      |


## Standard Deviation

Small $s$ = data points are clustered near the mean

Large $s$ = data points are widely dispersed around the mean


```{r, echo = FALSE, message = FALSE, warning = FALSE, out.width = "60%"}

library(patchwork)

`SD = 1` <- rnorm(n = 1000, mean = 0, sd = 1)
`SD = 2` <- rnorm(n = 1000, mean = 0, sd = 2)
`SD = 3` <- rnorm(n = 1000, mean = 0, sd = 3)

tibble(`SD = 1`, `SD = 2`, `SD = 3`) %>% 
pivot_longer(cols = everything(), names_to = "Standard Deviation", values_to = "values") %>% 
  ggplot(aes(x = values, fill = `Standard Deviation`))+
  geom_histogram()+
  facet_wrap(~ `Standard Deviation`)+
  theme_classic()+
  theme(legend.position = "none")+
  labs(x = " ",
       y = "Frequency")


```


## Why the Normal Distribution matters

Shape: Symmetrical, bell-shaped curve

- Rule of Thumb: For normally distributed data:

    ~68% within 1 SD

    ~95% within 2 SDs

    ~99.7% within 3 SDs

Relevance: Underpins many statistical tests and probability calculations (e.g., Z-scores)

## Why the Normal Distribution matters

If we assume a normal distribution (or close enough), we can calculate the probability of observing any given value using just the mean and standard deviation. 

$$
f(x) = \frac{1}{\sqrt{2\pi} \, \sigma}
       \exp\!\Biggl(-\frac{(x - \mu)^2}{2\,\sigma^2}\Biggr)
$$

This has applications in hypothesis testing and building confidence intervals

## Visualising a Distribution

::::{.columns}

:::{.column}

**Histograms** plot frequency/density of observations within bins

```{r, echo = FALSE, message = FALSE, out.width="80%"}
tibble(`SD = 1`, `SD = 2`, `SD = 3`) %>% 
pivot_longer(cols = everything(), names_to = "Standard Deviation", values_to = "values") %>% 
  filter(`Standard Deviation` == "SD = 2") %>% 
  ggplot(aes(x = values), fill = "grey")+
  geom_histogram()+
  theme_minimal()+
  theme(legend.position = "none")+
  labs(x = bquote(bar(x)),
       y = " ")
```

:::

:::{.column}

**Quantile-Quantile plots** plot quantiles of a dataset vs. quantiles of a *theoretical* (usually normal) distribution

```{r, echo = FALSE, warning = F, message  = F, out.width="80%"}

tibble(`SD = 1`,`SD = 2`, `SD = 3`) %>% 
pivot_longer(cols = everything(), names_to = "Standard Deviation", values_to = "values") %>% 
  filter(`Standard Deviation` == "SD = 2") %>% 
  ggplot(aes(sample = values))+
  geom_qq()+
  geom_qq_line()+
  theme(legend.position = "none")+
  labs(x = " ",
       y = " ")
```

:::

::::


## Why is data distribution important?

Understanding the shape of our data informs the summary statistics we can use

```{r, echo = FALSE, fig.alt = "Frequency distribution with central tendencies", out.width = "60%"}
# Set seed for reproducibility
set.seed(123)

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}


# Generate random sample from a skewed distribution
sample_size <- 1000
skewness <- 0.6  # skewness parameter
sample1 <- rnorm(sample_size)
sample1 <- exp(sample * skewness)

# Create a data frame with the sample data
df1 <- data.frame(x = sample1)

# Calculate mean and median
mean_val <- mean(sample1)
median_val <- median(sample1)
mode_val <- Mode(sample1)
# Create a histogram plot using ggplot2
ggplot(df1, aes(x = x)) +
    geom_histogram(binwidth = 0.2, fill = "lightblue", color = "black") +
    geom_vline(xintercept = mean_val, linetype = "dashed", color = "red", size = 1) +
    geom_vline(xintercept = median_val, linetype = "dashed", color = "blue", size = 1) +
    geom_vline(xintercept = mode_val, linetype = "dashed", color = "black", size = 1) +
    labs(x = "Value", y = "Frequency") +
    annotate("text", x = mean_val, y = 80, label = "Mean", color = "red", vjust = -1, hjust = -0.2) +
    annotate("text", x = median_val, y = 140, label = "Median", color = "blue", vjust = -1, hjust = -0.2)+annotate("text", x = mode_val, y = 160, label = "Mode", color = "black", vjust = -1, hjust = -0.2)+
    theme_classic()
```



## Asymmetrical

Depending on our question, if the data is not symmetrical this could really matter...

```{r, echo = FALSE, out.width = "60%"}

mean_val2 <- mean(sample)

ggplot(df1, aes(x = x)) +
    geom_histogram(binwidth = 0.2, fill = "lightpink", color = "black", alpha = 0.6) +
    geom_histogram(data = df, binwidth = 0.2, fill = "lightpink", color = "black") +
    geom_vline(xintercept = mean_val, linetype = "dashed", color = "red", size = 1) +
    labs(x = "Value", y = "Frequency") +
    annotate("text", x = mean_val, y = 80, label = "Mean 2", color = "red", vjust = -1, hjust = -0.2) +  
  geom_histogram(data = df, aes(x=x), binwidth = 0.2, fill = "lightblue", color = "black", alpha =0.6)+
  geom_vline(xintercept = mean_val2, linetype = "dashed", color = "blue", size = 1)+
  annotate("text", x = mean_val2, y = 80, label = "Mean 1", color = "blue", vjust = -1, hjust = 1.2) +
    theme_classic()


```

## When data are not normal

- Median: Middle value of sorted data—resistant to skew/outliers

- Range: Max − Min (simple but sensitive to outliers)

- Interquartile Range (IQR): More robust (Q3 – Q1)

Why Use These?:

- Mean/SD can be misleading in highly skewed distributions

- Median & IQR often better represent central tendency & spread

## Median and Range

Going back to our friends data: 

::::{.columns}

:::{.column}


| Lecturer     | Friends |
| ----------- | ----------- |
| Mark      | 5       |
| Tony   | 3     |
| Becky | 3    |
| Ellen   | 2      |
| Phil   | 1     |
| **Median **  | **3**      |
| **Range **  | **4**      |

:::

:::{.column}


- The range is affected by extreme values

- The interquartile range (IQR)  looks at the middle 50% of scores

- The first **quartile** is the median of the lower 50% of the data: 1.5

- The second **quartile** is the median: 3

- The third **quartile** is the median of the upper 50% of the data: 5

:::

::::


## IQR

* Box bounded by 25th and 75th percentile (first and third quartile). This is called the interquartile range (IQR)

* Line in box is usually the median

* Whiskers extend to last OBSERVATION within 1 step (usually 1.5*IQR) from end of the box

* Any observations beyond whisker are plotted as individual points

::::{.columns}

:::{.column}


```{r, echo = FALSE, out.width="80%", fig.alt = "Boxplot"}
knitr::include_graphics("images/boxplot.png")
```

:::

:::{.column}

```{r, echo = FALSE, out.width="50%", fig.alt = "Box and whiskers"}
knitr::include_graphics("images/cat.jpg")
```

:::

::::

## What is Correlation?

A statistical measure that quantifies the degree to which two variables move together.

Correlation Coefficient Range: −1 to +1

- +1: Perfect positive relationship

- -1: Perfect negative relationship

- 0: No linear relationship


## Pearson's correlation

Measures the **linear** relationship between two variables

Assumes the data is approximately normally distributed

Few (if any) outliers

## Spearman's correlation

- Less sensitive to outliers

- Works with rank ordered data, no requirement for normality

# Understanding Bias  {background-color="#D9DBDB"}

##  Multicollinearity


- **Multicollinearity** occurs when two or more predictor variables in a regression model are highly correlated, making it difficult to determine their individual effect on the response variable.

**Impact:**
- Inflated standard errors, leading to unreliable coefficient estimates.
- Complicated interpretation of model results.

**Action:**
- Check for multicollinearity using Variance Inflation Factor (VIF) and correlation matrices.
- Consider removing or combining correlated variables to simplify the model.

**Example:**
- In a model predicting house prices, having both "square footage" and "number of rooms" may lead to multicollinearity.

## Multicollinearity

```{r, echo = T, warning = F, message = F}
penguins %>% 
  GGally::ggpairs(columns = 2:6, ggplot2::aes(colour = species))

```

## Omitted Variable Bias


**Definition:**
- **Omitted Variable Bias** occurs when a relevant variable that influences the dependent variable is left out of the model, leading to biased estimates of the included variables.

**Impact:**
- Misleading conclusions about the relationships among variables.
- Reduced model accuracy and reliability.

**Action:**
- Conduct thorough literature reviews to identify all relevant variables.
- Use domain knowledge to guide variable selection and inclusion.

**Example:**
- If studying the effect of education on income without including "work experience," the model may incorrectly attribute income differences solely to education.

## Sample Bias

This type of bias occurs when there’s not a representative sample of a group/groups in the dataset, thus skewing results and performance


```{r, message = F, warning = F}

island_species_summary <- penguins %>% 
  group_by(island, species) %>% 
  summarise(n=n()) %>% 
  ungroup() %>% # needed to remove group calculations
  mutate(freq=n/sum(n)) # 

penguins %>% 
  ggplot(aes(x=island, fill=species))+
  geom_bar(position=position_dodge2(preserve="single"))+ 
  #keeps bars to appropriate widths
    labs(x="Island",
       y = "Number of observations")+
  geom_text(data=island_species_summary, # use the data from the summarise object
            aes(x=island,
                y= n+10, # offset text to be slightly to the right of bar
                group=species, # need species group to separate text
                label=scales::percent(freq) # automatically add %
                ),
            position=position_dodge2(width=0.8))+ # set width of dodge
  scale_fill_manual(values=c("cyan",
                            "darkorange",
                            "purple"
                            ))+
  coord_flip()+
  theme_minimal()+
  theme(legend.position="bottom") # put legend at the bottom of the graph

```

## Survivorship Bias

```{r, echo = FALSE, out.width="90%", fig.alt = "WW2 planes returning from battle with bullet holes"}
knitr::include_graphics("images/survivor.png")
```

## Confirmation Bias


**Definition:**
- **Confirmation Bias** is the tendency to search for, interpret, and remember information that confirms pre-existing beliefs or hypotheses, rather than seeking out contradictory evidence.

**Impact:**
- Skewed analysis outcomes and reduced objectivity in decision-making.
- Important insights or alternative explanations may be overlooked.

**Action:**
- Encourage a culture of critical thinking and actively seek out opposing viewpoints.
- Use blind analysis techniques where applicable.

**Example:**
- Analysts may only report findings that support a preferred model while ignoring results that suggest alternative explanations.


## Discussion


- **How can we implement strategies to recognize and mitigate these biases in our data analysis processes?**

**Considerations:**

- Share examples from your experiences where these biases impacted outcomes.

- Discuss methods or tools you use to identify and address bias in your work.

## Exercise - Data Insights

```{r}
#| label: ex-data-insights
countdown::countdown(
  minutes = 30,
  color_border = "#00AEEF",
  color_text = "#00AEEF",
  color_running_text = "white",
  color_running_background = "#00AEEF",
  color_finished_text = "#00AEEF",
  color_finished_background = "white",
  top = 0,
  margin = "0.8em",
  font_size = "2em"
)
```

# Inferential Statistics  {background-color="#D9DBDB"}

## Inferential statistics

::::{.columns}

:::{.column}

### Descriptive

- Summarises the data in a meaningful way

- Measures of central tendency & measures of variability

:::

:::{.column}

- Analyses a sample of data to infer about a larger population

- Includes hypothesis testing and building confidence intervals

:::

::::


## Understanding Standard Deviation

Standard deviation is a measure of the spread of data points around the mean.

$$
s = \sqrt{\sum(x - \overline x)^2\over n - 1}
$$
A low standard deviation indicates that data points are close to the mean, while a high standard deviation indicates more spread out data.

## Standard deviation predicts data

The standard deviation tells you how far each score lies from the mean in your datset

```{r, fig.width = 12}
library(patchwork)

`SD = 1` <- rnorm(n = 1000, mean = 0, sd = 1)
`SD = 2` <- rnorm(n = 1000, mean = 0, sd = 2)
`SD = 3` <- rnorm(n = 1000, mean = 0, sd = 3)

tibble(`SD = 1`, `SD = 2`, `SD = 3`) %>% 
pivot_longer(cols = everything(), names_to = "Standard Deviation", values_to = "values") %>% 
  ggplot(aes(x = values, fill = `Standard Deviation`))+
  geom_histogram()+
  facet_wrap(~ `Standard Deviation`)+
  theme_classic()+
  theme(legend.position = "none")+
  labs(x = " ",
       y = "Frequency")

```

## Introduction to Standard Error

Standard error measures the accuracy of a sample mean as an estimate of the population mean.

$$
SE = {s\over \sqrt n}
$$


```{r, echo = FALSE, out.width="100%", fig.alt = "Data sampling"}

knitr::include_graphics("images/standard_error.png")

```

## Standard Error

### Standard deviation vs. standard error: 

- Standard deviation measures variability **within** a sample

- Standard error measures variability **between** sample means.

## Are two distributions the same or different?

```{r, fig.width = 12}

plot_two_normals <- function(mean1 = 0, sd1 = 1, mean2 = 0.5, sd2 = 1) {
  x <- seq(-5, 5, by = 0.1)
  y1 <- dnorm(x, mean = mean1, sd = sd1)
  y2 <- dnorm(x, mean = mean2, sd = sd2)
  plot(x, y1, type = "l", col = "red", xlab = "X", ylab = "Density", main = "Two Normal Distributions")
  lines(x, y2, col = "blue", lty = "dashed")
  legend("topright", c("Population 1", "Population 2"), lty = c("solid", "dashed"), col = c("red", "blue"))
}

plot_two_normals()

```

## Standard Error vs. Standard Error of the Difference

::::{.columns}

:::{.column}

Standard error of the difference measures the accuracy of the difference between two sample means.


$Mean~difference = \overline x_1 - \overline x_2$

$SED = \sqrt{s_1^2\over n_1}+{s_2^2\over n_2}$

Standard Error of the difference is calculated from two $s$ so will always be larger than a single population estimate

:::

:::{.column}

```{r, fig.width = 7}
plot_mean_diff <- function(mean1 = 0, sd1 = 1, mean2 = 0.5, sd2 = 1, sample_size = 20) {
    library(graphics)
    sd <- sqrt(sd1^2/sample_size + sd2^2/sample_size)
    x <- seq(-5, 5, by = 0.1)
    mean_diff <- rnorm(10000, mean = mean2 - mean1, sd = sd)
    y <- dnorm(x, mean = mean2 - mean1, sd = sd)
    plot(x, y, type = "l", col = "black", xlab = "Difference in Means", ylab = "Density", main = "Mean Difference Distribution")
    abline(v = 0, col = "red", lty = 2)
    xmin <- mean2 - mean1 - 1.96 * sd
    xmax <- mean2 - mean1 + 1.96 * sd
    ymin <- 0
    ymax <- max(y)
    rect(xmin, ymin, xmax, ymax, col = "grey", density = 20, angle = 45)
    legend("topright", legend = "95% \n Confidence Interval", fill = "grey")
}


plot_mean_diff(mean1 = 0, sd1 = 1, mean2 = 0.5, sd2 = 1, sample_size = 20)

```

:::

::::

## The Normal Distribution

Also known as the Gaussian distribution, its a bell shaped probability distribution

- Symmetrical around the mean

- Mean, mode, median are equal

- The shape is determined by two parameters: the mean ($\mu$) and standard deviation ($s$)

## The Z Distribution

The Z distribution is specific type of normal distribution with a mean of 0 and a standard deviation of 1. 

- Z scores represent the number of standard deviations a data point is from the mean

$z = \frac{X - \mu}{s}$

- Gives us standardized scores to compare normal distributions

## Confidence Intervals Explained

::::{.columns}

:::{.column}

Can be constructed by YOU:

Do you want to know the range within which you will capture the mean...

:::{.incremental}

* 66% of the time = 1 * S.E.



* 95% = 1.96 * S.E. 



* 99% = 2.58 * S.E. 

:::

The Confidence level (C) is the inverse of the significance level.

$$
\alpha = 1 - C
$$

:::

:::{.column}

```{r, fig.height = 9}

# Load required libraries
library(ggplot2)

# Define mean and standard deviation
mean <- 0
sd <- 1

# Define the limits for the x-axis
x_limits <- c(-4, 4)

# Create a sequence of x values
x <- seq(x_limits[1], x_limits[2], length.out = 1000)

# Calculate the y values for the normal distribution
y <- dnorm(x, mean, sd)

# Create a data frame
data <- data.frame(x, y)

# Define the z-scores for SE, 95% CI, and 99% CI
se_limit <- c(-1, 1) * sd
ci_95_limit <- qnorm(c(0.025, 0.975), mean, sd)
ci_99_limit <- qnorm(c(0.005, 0.995), mean, sd)

# Plot the normal distribution
ggplot(data, aes(x = x, y = y)) +
  geom_line(size = 1) +
  
  # Standard error shading
  geom_area(data = subset(data, x >= se_limit[1] & x <= se_limit[2]),
            aes(x = x, y = y), fill = "blue", alpha = 0.3) +
  
  # 95% CI shading
  geom_area(data = subset(data, x >= ci_95_limit[1] & x <= ci_95_limit[2]),
            aes(x = x, y = y), fill = "green", alpha = 0.2) +
  
  # 99% CI shading
  geom_area(data = subset(data, x >= ci_99_limit[1] & x <= ci_99_limit[2]),
            aes(x = x, y = y), fill = "red", alpha = 0.1) +
  
  # Add vertical lines for limits
  geom_vline(xintercept = se_limit, linetype = "dashed", color = "blue") +
  geom_vline(xintercept = ci_95_limit, linetype = "dashed", color = "green") +
  geom_vline(xintercept = ci_99_limit, linetype = "dashed", color = "red") +
  
  # Add text labels
  annotate("text", x = mean(se_limit), y = max(y) * 0.9, label = "SE", color = "blue", vjust = -1) +
  annotate("text", x = mean(ci_95_limit), y = max(y) * 0.8, label = "95% CI", color = "green", vjust = -1) +
  annotate("text", x = mean(ci_99_limit), y = max(y) * 0.7, label = "99% CI", color = "red", vjust = -1) +
  
  # Customize plot
  labs(title = "Normal Distribution with Standard Error and Confidence Intervals",
       x = "x", y = "Density") +
  theme_minimal(base_size = 18)


```

:::

::::


## The T Distribution

Under realistic scenarios we only ever have an *estimate* of the standard deviation. 

- At large enough sample sizes this doesn't matter, but *how* large? 

- The t-distribution is a correction for small sample size and unknown population variance with a normally distributed population

```{r, fig.width = 12}

x <- seq(-5, 5, by = 0.1)
y1 <- dt(x, df = 1)
y2 <- dt(x, df = 3)
y3 <- dt(x, df = 8)
y4 <- dt(x, df = 30)
y5 <- dnorm(x)
plot(x, y1, type = "l", col = "red", 
     xlab = "x", 
     ylab = "Density", 
     main = "T Distributions and Normal Distribution",
     ylim = c(0,0.4),
     xlim = c(-5, 5))
lines(x, y2, col = "blue")
lines(x, y3, col = "green")
lines(x, y4, col = "purple")
lines(x, y5, col = "black", lty = 2)
legend("topright", legend = c("df = 1", "df = 3", "df = 8", "df = 30", "Normal"), col = c("red", "blue", "green", "purple", "black"), lty = c(1, 1, 1, 1, 2))


```

##

the t-distribution is closely related to a normal distribution, but influenced by sample size *n* and has **fatter tails**

Calculate Confidence intervals based on *t-distribution*

${95\%~CI} = {\overline x \pm t*SE}$


```{r, out.width = "60%"}

knitr::include_graphics("images/z_vs_t.png")

```

*Calculating t based on sample size WILL affect confidence intervals*

## Understanding P-Values

- **Definition of p-value**: (probability of observing the data given that the null hypothesis is true)

- **Interpretation of p-values**: (low p-value indicates strong evidence against the null hypothesis)

- Common thresholds (e.g., p < 0.05)

## Relationship between p-values and Confidence Intervals

::::{.columns}

:::{.column}

- p-values and confidence intervals are both derived from the same underlying theory

- a confidence interval that does **not** include the null hypothesis (e.g. zero difference) has a corresponding p-value

- For example a 95% confidence interval that **does not** include zero is the same as p < 0.05

:::

:::{.column}

```{r, fig.width = 10}
plot_mean_diff(mean1 = 0, sd1 = 1, mean2 = 0.5, sd2 = 1, sample_size = 20)
```

:::

::::

## Using t-values

::::{.columns}

:::{.column}

Observed *t* is the product of the mean difference divided by the Standard error of the difference

${t=}{mean~difference\over~SE}$ 

${-2.437=}{-2.617\over1.074}$

${95\%~CI} = {\overline x \pm t_{critical}*SE}$

${95\%~CI} = {-2.617 \pm 2.048*1.07}$

${95\%CI;[-4.81:-0.417]}$

${=-2.617\pm2.19}$

:::

:::{.column}


p = 0.05 when observed t > than critical t:

| Df    | Critical t-value |
| ----------- | ----------- |
|1     | 12.7       |
| 5 | 2.57       |
| 10 | 2.22     |
| 20 | 2.08     |
| 28 | 2.048
| 30 | 2.04    |

:::

::::

## Exercise - introduction to statistics

```{r}
#| label: ex-intro-stats
countdown::countdown(
  minutes = 30,
  color_border = "#00AEEF",
  color_text = "#00AEEF",
  color_running_text = "white",
  color_running_background = "#00AEEF",
  color_finished_text = "#00AEEF",
  color_finished_background = "white",
  top = 0,
  margin = "0.8em",
  font_size = "2em"
)
```

# Introduction to Linear Models {background-color="#D9DBDB"}

## Two-sample t-tests

**Q. When testing the difference between two population means, what is the null hypothesis for the difference in their means?**


We know that even when samples **are** drawn from the same population, the samples means won't be exactly the same

```{r, echo = FALSE, out.width="50%", fig.alt = ""}
knitr::include_graphics("images/sample_means.png")
```


## Different enough?

When can we determine that two sample means are different **enough**? To have come from *different* populations?

```{r, echo = FALSE, out.width="40%", fig.alt = ""}
knitr::include_graphics("images/sample_means.png")
knitr::include_graphics("images/sample_means_diff.png")
```



## Two-sample t-test

* Compare the means of two samples

* Null hypothesis: there is no difference between the population means

* t-statistic: based on difference in sample **means, sd & n**

* For a given sample size and t-value, how unlikely is to have two random samples *at least* this different IF both samples are drawn from identical/same populations. 



## Variance matters

```{r, echo = FALSE, out.width="60%", fig.alt = "Equal means, but different variance"}
knitr::include_graphics("images/variance_matters.png")

```



## T-test Example

Example: A botanist is studying the mass of pollen transported by individual bees from two different hives (Hive A and Hive B). 

She collects pollen samples from 62 bees in Hive A (mean pollen mass = 31.4 mg) and 67 bees in Hive B (mean pollen mass = 36.7 mg). Variances for each hive are 225.0 mg^2 and 186.0 mg^2, respectively. 


**Is there a significant difference in pollen mass transported per bee for the two hives studied?**


Variance $s^2$ = Sum of squared residuals/ n

Standard deviation (s) = $\sqrt Variance$


## Standard error of the difference

 **Calculate the difference in means, and the standard error of the difference in means**

::::{.columns}

:::{.column}

Mean Difference = 36.7 - 31.4

Mean Difference = 5.3

:::

:::{.column}



$$
SED = \sqrt{s^2_1\over n_1} + {s^2_2\over n_2}
$$



$$
SED = \sqrt{225\over 62} + {186\over 67}
$$




$$
SED = \sqrt{3.63} + {2.78}
$$




$$
SED = 2.53
$$


:::

::::



## Standard error of the difference

::::{.columns}

:::{.column}

Mean difference = 5.3


**Calculate 95% confidence intervals**

Assuming a normal distribution this would be 1.96 * SED = 4.96



Assuming a *t* distribution = ( $\alpha$ = 0.975, *df* = 129-2, *SED* = 2.53 ) = 5.008



95% CI range = 5.3 [± 5.008] = 0.292 - 10.308 

:::

:::{.column}

$$
SED = 2.53
$$

```{r, echo = FALSE, out.width="80%", fig.alt = "T distributions"}
knitr::include_graphics("images/t_distribution_comparisons.png")
```

:::

::::



##

**Calculate 95% confidence intervals**

95% CI range = 5.3 [± 5.008] = 0.292 - 10.308 

* **Describe the estimated mean difference**

**The mass of pollen transported per bee in Hive B is on average 5.3mg more than Hive A [0.29 - 10.3] (mean [± 95% CI])**

##

**The mass of pollen transported per bee in Hive B is on average 5.3mg more than Hive A [0.29 - 10.3] (mean [± 95% CI])**

**Q. Will this be a statistically significant difference?**

$$
\alpha = 1 - C
$$

:::{.fragment}

As the 95% CI calculated from the *t* distribution *do not* cross 0, we can say that their is a > 5% probability of observing at least this difference in means under the assumption that the null hypothesis is true

:::

:::{.fragment}

**"At P ≤ 0.05 bees from Hive B transport at least 0.29mg of pollen more per bee than Hive A"**

:::

## Calculate precise p-values

FIND THE CRITICAL VALUE OF t

**You are not expected to be able to do this by hand. This requires finding the degrees of freedom and use a critical t value table (R will calculate this for you)**

Critical value for t at 127 df and 𝛼 = 0.05 is **1.98**

FIND THE t-STATISTIC FOR YOUR SAMPLES (here, equal variances)

$$
t_{sample}={difference \over SED}={5.3 \over 2.53}=2.09
$$

For a *t*-value of 2.09 at *df* 127, *p* = 0.0115

## P-value {.smaller}

::::{.columns}

:::{.column}

IF the null hypothesis is true (samples are taken from populations with the same mean), the probability that we would have taken two samples that are at least this different by random chance (means, taking into account data spread, etc.) is 1.15%.


**“Pollen mass transported by individual bees in Hive A (32 ± 15 mg [mean ± sd],  n = 62) and Hive B (38 ± 13.6 mg [mean ± sd], n = 67) differed significantly (t(127) = 2.09, p = 0.0115).”**

:::

:::{.column}

```{r, echo = T, eval = FALSE}

hive_data %>% 
  t_test(pollen_mass ~ hive,
         var.equal = T)

```




```

	Two Sample t-test

data:  hive_a and hive_b

t = 2.09, df = 127, p-value = 0.01152

alternative hypothesis: true difference in means is not equal to 0

95 percent confidence interval:
0.294166 10.30808


```

:::

::::


## Linear models

- A linear approach to modeling the relationship between a dependent variable and one or more independent variables.


### Simple Linear Regression
- Models the relationship between two variables by fitting a linear equation.
- Equation: $Y = \beta_0 + \beta_iX + \epsilon$
  - $Y$: Dependent variable
  - $X$: Independent variable
  - $\beta_0$: Intercept
  - $\beta_i$: Slope
  - $\epsilon$: Error term

## Testing with linear models {.smaller}

- Tests if the coefficients ($\beta$) of the model are significantly different from zero.
- Null hypothesis (H0): $\beta_i$ = 0  (no effect).
- Alternative hypothesis (H1): $\beta_i \neq 0$ (significant effect).

### Steps
1. **Fit the model**
   - Use methods like Ordinary Least Squares (OLS).
2. **Calculate the test statistic**
   - Typically a t-statistic for each coefficient.
3. **Determine the p-value**
   - Indicates the probability of observing the data if H0 is true.
4. **Make a decision**
   - If p-value < α, reject H0.

## Linear models


::::{.columns}

:::{.column}

* Difference tests: t-test, ANOVA, ANCOVA

* Association tests: Regressions

:::

:::{.column}

```{r, echo = FALSE, out.width="60%", fig.alt = "Introduction to linear models"}
knitr::include_graphics("images/linear_model_difference.png")
knitr::include_graphics("images/linear_model_regression.png")
```
:::

::::



## R does most of the work for you

```{r, echo = T, eval = FALSE}

hive_lsmodel <- lm(pollen_mass ~ hive, data = hive_data)

```

```
Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept)    29.160      1.792  16.274   <2e-16 ***
hiveb		  -5.33       2.53    2.09   0.0115 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

```

## Exercise - Linear models

```{r}
#| label: ex-linear models
countdown::countdown(
  minutes = 25,
  color_border = "#00AEEF",
  color_text = "#00AEEF",
  color_running_text = "white",
  color_running_background = "#00AEEF",
  color_finished_text = "#00AEEF",
  color_finished_background = "white",
  top = 0,
  margin = "1.2em",
  font_size = "2em"
)
```

## Linear model assumptions

::::{.columns}

:::{.column}

Are the same as those that apply to a Student's T-test

1) Normality of the residual variance

2) Equality of the residual variance

:::

:::{.column}

```{r, echo = FALSE, out.width="100%", fig.alt = "Introduction to linear models"}
knitr::include_graphics("images/lm_t_test.png")

```

:::

::::


## Common statistical tests are linear models

```{r, echo = FALSE, out.width="60%", fig.alt = "Linear model tests"}
knitr::include_graphics("images/commmon_statistical_tests_linear_models.png")
```


## Assumption checking

```{r}
#| label: ex-assumptions
countdown::countdown(
  minutes = 40,
  color_border = "#00AEEF",
  color_text = "#00AEEF",
  color_running_text = "white",
  color_running_background = "#00AEEF",
  color_finished_text = "#00AEEF",
  color_finished_background = "white",
  top = 0,
  margin = "1.2em",
  font_size = "2em"
)
```

# P-values

## What is a P-value

:::{.fragment}

### The probability of getting results at least as extreme as the ones we observed. Assuming the Null Hypothesis is true

:::

## Hypothesis formation

:::{.incremental}

- **Null hypothesis:** there is **no** difference between groups. Or no relationship between dependent and independent variables


- **Alternative hypothesis:** there *is* a difference between groups. Or there *is* a relationship between dependent and independent variables

:::

## Null hypothesis probability distribution

```{r, echo = FALSE, out.width="50%"}

knitr::include_graphics("images/null_hypothesis.png")

```

These areas represent 2.5% of the values in the left tail of the distribution, and 2.5% of the values in the right tail of the distribution. 

Together, they make up 5% of the most extreme mean differences we would expect to observe, given our number of observations, 

when the true mean difference is exactly 0 – this represents the use of an $\alpha$ level of 5%



## Sample size can affect distributions

```{r, echo = FALSE, out.width="60%"}

knitr::include_graphics("images/null_5000.png")

```

A probability distribution can be affected by variance and sample size. 



## Hypothesis testing

The **null hypothesis** is that there is no relationship between your variables of interest or that there is no difference among groups

e.g you want to know whether there is a difference in longevity between two groups of mice fed on different diets, diet A and diet B. 

:::{.incremental}

- **Null hypothesis:** there is **no** difference in longevity between the two groups.



- **Alternative hypothesis:** there *is* a difference in longevity between the two groups.




- We can use a linear model to perform a t-test on the data

:::

```
lm(longevity ~ diet, data = mice)
```


```{r, echo = F}
data_sim <- function(mean1, mean2, sd){
set.seed(123)
mice_a <- rnorm(n = 12, mean = mean1, sd = sd)
mice_b <- rnorm(n = 12, mean = mean2, sd = sd)
mice <- data.frame(cbind(mice_a,mice_b)) %>% 
  pivot_longer(cols = everything(),
               names_to = "diet",
               values_to = "longevity")

model <- lm(longevity ~ diet, data = mice)

tidy_model <- model %>% 
  broom::tidy(., conf.int =T)

tidy_model
}

tidy_model <- data_sim(mean1 = 4, mean2 = 3, sd =1)

```



## Visualising the t distribution of the difference

```{r, fig.show="hold", out.width="50%", echo = F}

tidy_model

x <- seq(-5, 5, by = 0.1)
y1 <- dt(x, df = 22)

estimate <- tidy_model[[2,2]]
std.error <- tidy_model[[2,3]]

conf.low <- tidy_model[[2,6]]
conf.high <- tidy_model[[2,7]]

x1 <- (x*std.error)+estimate


plot(x1, y1, type = "l", col = "darkgrey", lty=1,
     xlab = "Mean difference", 
     ylab = "Density", 
     main = "T Distribution",
     ylim = c(0,0.4),
     xlim = c(min(x1), max(x1)))
polygon(c(x1[x1>=conf.high], max(x1), conf.high), c(y1[x1>=conf.high], 0, 0), col="red")


legend("topright", legend = "95% CI", lty = 1, col = "red")

#GGally::ggcoef_model(model)
```


## Compare these write-ups

“Diets can change the longevity of mice (*p* = 0.0016).”

:::{.incremental}

- “Mice on diet B lived significantly shorter lives than mice on diet A (*t*<sub>22</sub> = -3.6, *p* = 0.006).”


- "Mice on diet B had a reduced mean lifespan of 1.41 years[95% CI; -0.595:-2.22] from the mice on diet A (mean 4.19 years (95% CI, 3.62-4.77). While statistically significant (*t*<sub>22</sub> = -3.6, *p* = 0.006), this is a relatively small sample size, and further testing is recommended to confirm this effect."



- Which has the greatest level of useful detail?

:::

## Exercise - Testing

- Testing

- Paired designs

```{r}
#| label: ex-t-test
countdown::countdown(
  minutes = 40,
  color_border = "#00AEEF",
  color_text = "#00AEEF",
  color_running_text = "white",
  color_running_background = "#00AEEF",
  color_finished_text = "#00AEEF",
  color_finished_background = "white",
  top = 0,
  margin = "1.2em",
  font_size = "2em"
)
```

## Common misundertandings\n about P values

[Common misconceptions about P-values](https://daniellakens.blogspot.com/2017/12/understanding-common-misconceptions.html?m=1)

[Evidence of P-hacking](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4359000/#:~:text=Evidence%20for%20p%2Dhacking%20from,test%20function%20in%20R)




## Comparing hypothetical distributions

In the real world we will never know whether there is a true mean difference, but let's assume that we could. 

The figure below shows the expected data pattern when the null hypothesis is true (grey line) and the expected data pattern when an alternative hypothesis is true (black line). 

```{r, echo = FALSE, out.width="60%"}

knitr::include_graphics("images/null-and-alternate.png")

```


## A non-significant p-value DOES NOT mean the null hypothesis is true

::::{.columns}

:::{.column}


Here we can illustrate why a non-significant result does not always mean that the null hypothesis is true.

We *know* that the true mean difference is 0.5, but we only *observe* a mean difference of 0.35.  *p* > $\alpha$. 

BUT - we can see that the observed mean difference is much more likely under the alternative hypothesis than the null. All the *p*-value tells us is that seeing an observed difference of 0.35 is not that surprising under the null hypothesis.

:::

:::{.column}


```{r, echo = FALSE, out.width="90%"}

knitr::include_graphics("images/type-2.png")

```

:::

::::


## Why a significant p-value does not mean the null hypothesis is false


What we can conclude, based on our data, is that we have observed an extreme outcome, that should be considered surprising. But such an outcome is not *impossible* when the null-hypothesis is true.

```{r, echo = FALSE, out.width="60%"}

knitr::include_graphics("images/type-1.png")

```



## Why a significant p-value is not the same as an important effect

::::{.columns}

:::{.column}

If we plot the null model for a very large sample size, we can see that even very small mean differences will be considered 'surprising'. 

However, just because data is surprising, does not mean we need to care about it. It is mainly the verbal label ‘significant’ that causes confusion here – it is perhaps less confusing to think of a ‘significant’ effect as a ‘surprising’ effect.

:::

:::{.column}

```{r, echo = FALSE, out.width="90%"}

knitr::include_graphics("images/sample-size.png")

```

:::

::::



## Type 1 and Type 2 Errors:

We have now seen that it is possible to make incorrect decisions about rejecting or keeping the null hypothesis.


|             | H0 True   | H0 False     
| ----------- | ----------- |----------- |
| Reject H0 | Type 1 Error $$\alpha$$ | Correct rejection $$1-\beta$$
| Fail to reject H0    | Correct decision $$1-\alpha$$ | Type 2 Error  $$\beta$$   

## Type 1

```{r, echo = FALSE, out.width="60%", fig.alt = "P > 0.05."}

knitr::include_graphics("images/type_1_errors.png")

```

Type 1 error = Rejecting the null hypothesis (because *p* < $\alpha$), but actually this was a random sampling effect, not a *true difference*

## Type 2

```{r, echo = FALSE, out.width="60%", fig.alt = "P < 0.05."}

knitr::include_graphics("images/type_2_errors.png")

```

Type 2 error = Keeping the null hypothesis (because *p* > $\alpha$) the random sampling effect made it look like they come from the *same* parent distribution, but in reality the populations are distinct. 



## Type 2 error

:::{.incremental}

* Probability of a Type 2 error is known as $\beta$ 



* Power is the inverse of a Type 2 error $\beta=1-Power$ 


* A Type 2 error is the scenario where you fail to detect a *true* difference/effect


* Power is the probability you **will** detect a *true* difference/effect 
    *if the alternative hypothesis is true*

:::

## Power

There are three primary factors affecting power:



* Effect size: The magnitude of a result present in a population

* Sample size: The number of observations per sample

* Alpha: the threshold at which you would accept statistical significance (often 0.05)




Raising the value of any of effect size, sample size or $\alpha$ all increase Power $1-\beta$




## Are the statistics correct?

Reporting effect sizes, levels of uncertainty and understanding the statistical power of your experiment are all important. 


But a single experiment is **never** enough to know which hypothesis is correct. 


Only multiple experiments will allow true statistical trends to emerge

::::{.columns}

:::{.column}

```{r, figures-side, fig.show="hold", echo = F, out.width = "40%"}

#### write function 
simT <- function(n, mean2 = 0){
  x1 <- rnorm(n,0,1)
  x2 <- rnorm(n,mean2,1)
  t.test(x1, x2)$p.value 
}


#### repeat function for n = 10 and for different nrep and plot

simTRep <- replicate(1000, simT(20))
hist(simTRep, breaks = 21, col = c('red',rep('grey',20)), 
     main = "Null hypothesis true", sub = "nrep = 1000, n = 20", xlab = "pvalue")


```

:::

:::{.column}

```{r, figures-sidea, fig.show="hold", echo = F, out.width = "40%"}

simTRep <- replicate(1000, simT(20, 0.5))
hist(simTRep, breaks = 21, col = c('red',rep('grey',20)), 
     main = "Alternate hypothesis true", sub = "nrep = 1000, n = 20", xlab = "pvalue")
```

:::

::::


## Are most published results wrong?

```{r, echo = FALSE, out.width="80%", fig.alt = "."}

knitr::include_graphics("images/effects_wrong.png")

```

```{r, eval = FALSE, warning = FALSE, out.width = "100%", fig.cap = "9/(16+9) = 36% of significant p values would be false positives"}


grViz("
digraph boxes_and_circles {
  rankdir = LR

  # a 'graph' statement
  graph [overlap = true, fontsize = 8]




  # several 'node' statements
  node [shape = box,
        fontname = Helvetica]

  
# label names

A[label = '200\n experiments']
B[label = '20 \n real effect ']
C[label = '180 \n no real effect']

F[label = '171 \n true null \n rejection']
G[label = '9 \n false null \n rejection',
color = blue]

E[label = '4 \n real effect \nnot found',

color = red]
D[label = '16 \n real effect \n found']

  # several 'edge' statements
  A->B 
  A->C
  C->F[label = 0.95]
  C->G[label = 0.05]
  B->D[label = 0.8]
  B->E[label = 0.2]
}
")


```



[Smaldino & McElreath 2016](https://royalsocietypublishing.org/doi/full/10.1098/rsos.160384?wm=3049_a111)
[Ioannidis 2005](https://doi.org/10.1371%2Fjournal.pmed.0020124)



## Irreproducible science

* Publication bias

* Low statistical power

* P-hacking

* P-HARKing (*H*ypothesis *A*fter *R*esults *K*nown)

[Bishop 2019](https://www.nature.com/articles/d41586-019-01307-2)




## What can be done?

- Open, reproducible analyses can disclose analysis choices and sample sizes

- Preconsidered statistical models

- Pre-registered studies can detect P-hacking and HARKing


# Regression {background-color="#D9DBDB"}

## Linear models for regression analysis


::::{.columns}

:::{.column}

Difference tests: t-test, ANOVA, ANCOVA

```{r, echo = FALSE, out.width="100%", fig.alt = "Difference model"}
knitr::include_graphics("images/linear_model_difference.png")

```



:::

:::{.column}

Association tests: Regressions

```{r, echo = FALSE, out.width="100%", fig.alt = "Regression model"}
knitr::include_graphics("images/linear_model_regression.png")
```

:::

::::



## Basic linear models

```{r, echo = FALSE, out.width="60%", fig.alt = "Basic linear models aim to describe a linear relationship between a response (outcome) variable and a predictor (input) variable, usually by the method of ordinary least squares"}

knitr::include_graphics("images/basic_linear.png")

```

Basic linear models aim to describe a linear relationship between a:

:::{.incremental}

- response (dependent) variable and a predictor (independent) variable. 

- usually by the method of ordinary least squares.

:::

---

## Straight line equation

$$
\LARGE{y = a + bx}
$$

::::{.columns}

:::{.column}

### Where:

$y$ is the predicted value of the response variable



$a$ is the intercept (value of y when x = 0)



$b$ is the slope of the regression line



$x$ is the value of the explanatory variable

:::

:::{.column}


```{r, echo = FALSE, out.width="100%", fig.alt = "regression"}

knitr::include_graphics("images/reg.png")

```

:::

::::


## Line of best fit

```{r, echo = FALSE, out.width="70%", fig.alt = "Line fitting"}

knitr::include_graphics("images/fit-linear.png")

```


## Ordinary Least Squares

The line of best fit minimises the sum of the **squared distance** that *each* sample point is from the value predicted by the model

This is called the method of 



### Ordinary Least Squares



## Residuals


The difference between the ACTUAL value of the observation $y_i$ and the value that the model predicts $\hat{y_i}$ at that $x$ value are the residuals (residual error).


```{r, echo = FALSE, out.width="50%", fig.alt = "residuals"}

knitr::include_graphics("images/ols.png")

```

The regression model fitted by **O**rdinary **L**east **S**quares (OLS) will produce the equation for the line that **MINIMIZES** the sum of squares of the residuals


## Sum of Squares Errors

::::{.columns}

:::{.column}

```{r, echo = FALSE, out.width="40%", fig.alt = "sum of squares error"}

knitr::include_graphics("images/ols-2.png")

```

:::

:::{.column}

This produces the line with the *smallest* total area size for the squares. 

$$
SSE = \underset{i=1}{n \atop{\sum}}(y_i - \hat{y_i})^2
$$


SUM OF RESIDUAL ERROR = $(2)+(-1)+(4)+(-3)+(-2)=0$



SUM OF SQUARES OF RESIDUAL ERROR = $(2^2)+(-1^2)+(4^2)+(-3^2)+(-2^2)=34$

:::

::::


## Sums of Squares

::::{.columns}

:::{.column}


```{r, echo = FALSE, out.width="100%", fig.alt = "OLS fits a line to produce the smallest amount of SSE"}

knitr::include_graphics("images/Sum of squares.png")

```

:::

:::{.column}

**SST** The squared differences between the observed dependent variable $y_i$ and its overall mean $\overline{y}$.

**SSR** The sum of the differences between the predicted value $\hat{y_i}$ of the dependent variable and its overall mean $\overline{y}$.

**SSE** The error is the difference between the observed dependent value $y_i$  and the predicted value $\hat{y_i}$.

:::

::::


## Linear model equation

$$
\LARGE{y_i = a + bx+\epsilon}
$$

::::{.columns}

:::{.column}

$y_i$ is the predicted value of the response variable

$a$ is the intercept (value of y when x = 0)

$b$ is the slope of the regression line

$x$ is the value of the explanatory variable

$\epsilon$ is the value of the residual error

:::

:::{.column}


```{r, echo = F}
janka <- read_csv(here::here("data", "janka.csv"))

```

```{r, echo = T}
janka_ls1 <- lm(hardness ~ dens, data = janka) 
summary(janka_ls1)
```

:::

::::





## Coefficient of determination


$\LARGE{R^2}$ : The proportion of variation in the dependent variable that can be predicted from the independent variable


$$
\LARGE{R^2=1-{Sum~of~Squared~Distances~between~y_i~and~\hat{y_i}\over{Sum~of~Squared~Distances~between~y_i~and~\overline{y}}} }
$$



$$
\LARGE{R^2=1-{SSE\over{SST}}}
$$



## Adjusted $\LARGE{R^2}$

Adjusted $R^2$ is a corrected goodness-of-fit measure for linear models.



$R^2$ always increases as the number of effects are included in the model. Good for overall prediction, but does not check efficiency. 



Adjusted $R^2$ can fall if a model term does not *improve* the fit of the model



```{r, echo = FALSE, out.width="30%"}

knitr::include_graphics("images/adj_r.png")

```



$N$ = numerator degrees of freedom = Total number of observations across all groups



$k$ = Total number of groups


## Exercise - Regression

```{r}
#| label: ex-regression
countdown::countdown(
  minutes = 40,
  color_border = "#00AEEF",
  color_text = "#00AEEF",
  color_running_text = "white",
  color_running_background = "#00AEEF",
  color_finished_text = "#00AEEF",
  color_finished_background = "white",
  top = 0,
  margin = "1.2em",
  font_size = "2em"
)
```


## Summary

```{r, echo = T}
summary(janka_ls1)
```



## A write-up


 **I** fitted a linear model (estimated using OLS) to predict **timber hardness from wood density**. The model explains a statistically significant and substantial proportion of variance (F<sub>1,34</sub>) = 636.98, p < .001, adj. R<sup>2</sup> = 0.95). The model shows that for each unit increase in wood density (kg/m^3) there is an **increase** of 57.51 (lbf) on the Janka wood hardness scale (Beta = 57.51, 95% CI [52.88, 62.14], t<sub>34</sub> = 25.24, p < .001). Model residuals were checked against the assumptions of a standard linear model.




## Assumptions of the Linear Model

:::{.incremental}

-  *Errors* should be normally distributed

- Homoscedasticity of the errors

- Independent observations

- A Linear relationship

:::

## Model fit checks

```{r, echo = T, out.width="100%"}
performance::check_model(janka_ls1, 
                         detrend = F) 
```


## Linearity

```{r, echo = T, out.width="100%"}
performance::check_model(janka_ls1,
                         check = "linearity") 
```

## Normality

```{r}
#| eval: true
#| echo: true
#| layout-ncol: 2
#| fig-height: 7
#| message: false

performance::check_model(janka_ls1,
                         check = "normality")

performance::check_normality(janka_ls1)
```

## Heteroscedasticity


```{r}
#| eval: true
#| echo: true
#| layout-ncol: 2
#| fig-height: 7
#| message: false

performance::check_model(janka_ls1,
                         check = "homogeneity")

performance::check_heteroscedasticity(janka_ls1)
```

## Outliers


```{r}
#| eval: true
#| echo: true
#| layout-ncol: 2
#| fig-height: 7
#| message: false

performance::check_model(janka_ls1,
                         check = "outliers")

performance::check_outliers(janka_ls1)
```

# Questions?

# ANOVA {background-color="#D9DBDB"}

## z and t distributions

```{r, echo = F, out.width = "70%"}
x <- seq(-5, 5, by = 0.1)
y1 <- dt(x, df = 1)
y2 <- dt(x, df = 3)
y3 <- dt(x, df = 8)
y4 <- dt(x, df = 30)
y5 <- dnorm(x)
plot(x, y1, type = "l", col = "red", 
     xlab = "x", 
     ylab = "Density", 
     main = "T Distributions and Normal Distribution",
     ylim = c(0,0.4),
     xlim = c(-5, 5))
lines(x, y2, col = "blue")
lines(x, y3, col = "green")
lines(x, y4, col = "purple")
lines(x, y5, col = "black", lty = 2)
legend("topright", legend = c("df = 1", "df = 3", "df = 8", "df = 30", "Normal"), col = c("red", "blue", "green", "purple", "black"), lty = c(1, 1, 1, 1, 2))
```



## Model summary

In this example of a simple linear model, we run the equivalent to a Student's t-test.

```{r, echo = FALSE, out.width="60%", fig.alt = "R model summary provides, the formula of the regression, the estimate of the intercept and standard error, estimated differences and uncertainity for each slope, the degrees of freedom for the whole model, F value and R squared"}
knitr::include_graphics("images/model_summary.png")
```

**Q. What happens when we have more than two groups in our predictor variable? Why can't we just do more t-tests?**





## ANalysis Of VAriance (ANOVA)

ANOVAs use information about variances, but the main goal of analysis is comparison of MEANS (don’t let the name mix you up - more on this later).


:::{.fragment}

**ANOVA is an omnibus test** – it tests for significant differences between any means in the study

:::

:::{.fragment}


**ANOVA is just a special case of the linear model**

:::



## ANOVA Hypotheses:

**Null Hypothesis (H0):** All means are equal (in other words, all groups are from populations with the same mean)

:::{.fragment}

**Alternative Hypothesis (HA):** At least two group means are NOT equal (that means that just two could be different, or they could ALL be different)

:::



## ANOVA Example 


::::{.columns}

:::{.column}

We have collected data for soil uranium concentrations at three locations on Los Alamos National Lab property: Site A, Site B, and Site C. The data structure is shown here: 

A one-way ANOVA can be used to assess whether there is a statistically significant difference in uranium concentration in soil at three locations

:::

:::{.column}

```{r, echo = FALSE, out.width="120%", fig.alt = "A tidy dataframe illustrating one continuous dependent variable and and one factor predictor variable (with three levels)"}
knitr::include_graphics("images/three_level.png")
```

:::

::::




## One-way ANOVA (single factor)

What does this one-way/single-factor refer to? 

There is a **single factor** (*variable*), with at least 3 **levels**, where we are trying to compare means across the different levels of that factor.

ANOVA does this *indirectly* by looking at total *between* and *within* group variances as a ratio (F).

```{r, echo = FALSE, out.width="70%", fig.alt = ""}
knitr::include_graphics("images/understand-ANOVA.png")
```

##

::::{.columns}

:::{.column width="30%"}

$$
SSE = \underset{i=1}{n \atop{\sum}}(y_i - \hat{y_i})^2
$$



$$
SSR = \underset{i=1}{n \atop{\sum}}(\hat{y_i} - \overline{y})^2
$$


$$
SST = \underset{i=1}{n \atop{\sum}}(y_i - \overline{y})^2
$$

where:

$y_i$ = Observed value

$\hat{y_i}$ = Value estimated by model

$\overline{y}$ = The Grand Mean



:::

:::{.column width="70%"}

```{r, echo = FALSE, out.width="90%", fig.alt = "A tidy dataframe illustrating one continuous dependent variable and and one factor predictor variable (with three levels)"}
knitr::include_graphics("images/SSR-SST.png")
```




$SSE + SSR = SST$

:::

::::

---

## What does an ANOVA actually do?

::::{.columns}

:::{.column width="60%"}

$$
\large F = {SSR / (k-1)\over SSE / (N-k)} = {MSR\over MSE}
$$



$k$ = Total number of groups

$N$ = **numerator** degrees of freedom = Total number of observations across all groups

$N-k$ = **denominator** degrees of freedom

$MSR$ = Mean Squares Regression

$MSE$ = Mean Squares Error

This is a **ratio** of the between group variance and the the within group variance. 

:::

:::{.column width="40%"}


```{r, echo = FALSE, out.width="120%", fig.alt = ""}
knitr::include_graphics("images/one-way-ANOVA.png")
```

:::

::::



## F distribution

::::{.columns}

:::{.column}

The F-value or ratio of variances, over their respective degrees of freedom will have an F-distribution. 

This F distribution is used when we want to compare within and between group variances.

The curve of the distribution depends on the degrees of freedom, and it is always positively skewed

:::

:::{.column}

```{r, echo = F, fig.height = 10}
x <- seq(0.001, 5, by = 0.001)
y1 <- df(x, df1 = 1, df2 = 1)
y2 <- df(x, df1 = 2, df2 = 1)
y3 <- df(x, df1 = 5, df2 = 2)
y4 <- df(x, df1 = 10, df2 = 1)
y5 <- df(x, df1 = 100, df2 = 100)

plot(x, y1, type = "l", col = "red", lwd = 2,
     xlab = "x", 
     ylab = "Density", 
     main = "F Distributions",
     ylim = c(0,3),
     xlim = c(0.001, 4))
lines(x, y2, col = "blue", lwd = 2)
lines(x, y3, col = "green", lwd = 2)
lines(x, y4, col = "purple", lwd = 2)
lines(x, y5, col = "black", lwd = 2)
legend("topright", legend = c("df1 = 1, df2 = 1", "df1 = 2, df2 = 1", "df1 = 5, df2 = 2", "df1 = 10, df2 = 1", "df1 = 100, df2 = 100"), col = c("red", "blue", "green", "purple", "black"), lty = c(1, 1, 1, 1, 1))
```

:::

::::

## Significance testing

:::{.incremental}

- The **higher** the *F*-value the greater the *signal-to-noise* ratio. 



- For a given value of **numerator** and **denominator** degrees of freedom we can look up the probability of observing this ratio under a null hypothesis of identical variances.


- If F value is high enough then we might have enough evidence to conclude that samples are likely drawn from populations with *different* means.

:::

```{r, echo = FALSE, out.width="45%", fig.alt = ""}
knitr::include_graphics("images/F-test-sig.jpg")
```



# Ask a question about: ANOVA



## ANOVA Example

::::{.columns}

:::{.column}

```{r, echo = FALSE, message = FALSE}

bulbs <- read_csv(here::here("data", "bulbs.csv"))
bulbs %>% 
  head() %>% 
  gt::gt()

```

:::

:::{.column}

```{r, echo = FALSE}
bulb_lsmodel0 <- lm(lifetime_hours ~ bulb_type, data = bulbs)

summary(bulb_lsmodel0)

```

:::

::::

## Summary table

```{r, echo = T}

anova(bulb_lsmodel0)

```



# Post-hoc vs. Planned contrasts




## Correcting for multiple comparisons

:::{.incremental}

- The *F*-ratio tells us only whether the model fitted to the data (SSR) accounts for more variance than other factors (SSE). 

- So if the *F*-ratio is large enough to be statistically significant, then we only know that *one or more* differences between means are statistically significant.

- Further testing is needed! 

:::

## Planned contrasts

:::{.incremental}

- You focused on a *few* scientifically sensible comparisons, rather than every possible comparison

- You chose these *as part of the experimental design* before collecting data

- Could structure linear model to reflect this?

:::



## Post hoc

:::{.incremental}

- Typically unplanned comparisons, conducted only after a significant ANOVA result

- All combinations checked

- Needs correcting for inflated Type 1 error

:::

## Post hoc {.smaller}

| Method     | Equation | Notes|
| ----------- | ----------- |----------- |
| Bonferroni/Dunn-Sidak    | $p = {\alpha \over k}$      | Correct critical p for the number of independent tests
| Holm's    | $p_{1} < \alpha/(k–1+1) = \alpha/k$      | we start with the smallest p-value (i = 1) and determine whether there is a significant result (i.e. p1 < α/(k–1+1) = α/k. If so we move on to the second test. We continue in this manner until we get a non-significant result
| Tukey HSD  | $t_{crit} = q * \sqrt{MSE \over N}$  | Essential a t-test, correcting for multiple comparison, q-values can be looked up for test df and number of treatments



## Estimated means


```{r, echo = F}
library(emmeans)
```

```{r, echo = T}

means <- emmeans::emmeans(bulb_lsmodel0, 
                 specs =  ~ bulb_type)

means

```


## Estimated mean differences


```{r, echo = T}

means <- emmeans::emmeans(bulb_lsmodel0, 
                 specs = pairwise ~ bulb_type)

means

```


## Estimated CI of the difference

```{r, echo = T}

means <- emmeans::emmeans(bulb_lsmodel0, 
                 specs = pairwise ~ bulb_type)

confint(means)

```

## Exercise 

```{r}
#| label: ex-anova
countdown::countdown(
  minutes = 50,
  color_border = "#00AEEF",
  color_text = "#00AEEF",
  color_running_text = "white",
  color_running_background = "#00AEEF",
  color_finished_text = "#00AEEF",
  color_finished_background = "white",
  top = 0,
  margin = "1.2em",
  font_size = "2em"
)
```

# Complex models  {background-color="#D9DBDB"}

## Basic linear models

```{r, echo = FALSE, out.width="60%", fig.cap = "Basic linear models aim to describe a linear relationship between a response (outcome) variable and a predictor (input) variable, usually by the method of ordinary least squares"}

knitr::include_graphics("images/basic_linear.png")

```



## Straight line equation

$$
\LARGE{y_i = a + bx+\epsilon}
$$

### Where:

$y_i$ is the predicted value of the response variable



$a$ is the intercept (value of y when x = 0)



$b$ is the slope of the regression line



$x$ is the value of the explanatory variable



$\epsilon$ is the value of the residual error



##


::::{.columns}

:::{.column}

```{r, echo = FALSE, out.width="80%", fig.alt = "Culmen: the ridge along the top part of a bird's bill"}

knitr::include_graphics("images/culmen.jpg")

```


:::

:::{.column}


```{r, echo = F, out.width = "60%"}
library(ggpubr)
penguins %>% 
  filter(species=="Adelie") %>% 
ggplot(aes(x= bill_length_mm, 
                     y= bill_depth_mm)) +
    geom_point()+
    geom_smooth(method = "lm",
                se = FALSE)+
  theme_classic()+
  stat_cor(method = "pearson", #<<
           aes(label=..r.label..))+#<<
  stat_regline_equation(label.y = 21.7)
```

:::

::::


## what about an extra variable?

Now we have *two* reasonable predictors of bill depth:

Bill length & Body mass

```{r}
penguins %>% 
  select(bill_length_mm, bill_depth_mm, body_mass_g) %>% 
  as_tibble() %>% 
  head()

```


---

## ANCOVA

```{r}
penguins %>% 
lm(bill_length_mm ~ bill_depth_mm + body_mass_g, data = .)

```

Written as an equation this is:


$\large{bill~length=23.31+0.16_{(bill~depth)}+0.004_{(body~mass)}}$



## Two-way ANOVA

* Bill depth - a continuous quantitative variable

* Body mass - a continuous quantitative variable

* Penguin Species - a categorical variable with three levels


```{r, echo = FALSE, out.width="60%", fig.alt = "Adelie, Chinstrap, Gentoo"}

knitr::include_graphics("images/three_penguins.png")

```


## Dummy variables

In order to represent a categorical variable in a model - we need to convert these cases to ones that are compatible with the maths. 

Dummy variables, are coded with 0 and 1's. With three species we would have the following:

:::{.incremental}

* Adelie[0,0] - the reference or *intercept* species

* Chinstrap[1,0]

* Gentoo[0,1]

:::

```{r, echo = FALSE, out.width="30%", fig.alt = "Adelie, Chinstrap, Gentoo"}

knitr::include_graphics("images/three_penguins.png")

```


## Practice

```{r, echo =T}
lm(bill_length_mm ~ 
              bill_depth_mm +
              body_mass_g + 
              species,#<<
   data = penguins) %>% 
  broom::tidy(.)
```



## Practice

$$
\large{bill~length=bill~depth+body~mass+species}
$$

$\large{bill~length=15.9+0.71_{bill~depth}+0.003_{body~mass}+9.9_{speciesChinstrap}+7.39_{speciesGentoo}}$

If everything else about two penguins is the same (bill depth and body mass), we would expect a **Chinstrap** penguin to have a bill length 9.9mm longer than an Adelie pengun (on average).

:::{.fragment}

If everything else about two penguins is the same (bill depth and body mass), we would expect a **Gentoo** penguin to have a bill length 7.39mm longer than an Adelie pengun (on average).

:::

:::{.fragment}

**Q. What would be the bill length for a Gentoo penguin with a bill depth of 13.2mm and a body mass of 4500g?**

:::

:::{.fragment}

**46.162mm**

:::



## Interactions

### Why?

* What if you think that one of the predictor variables *changes* the *WAY* that another predictor variable influences the outcome?

* Increases our understanding of predictor variables

### Why not?

* Makes coefficient interpretation more difficult

* Increases model complexity




## Example

The species of penguin *changes* the relationship between bill length and bill depth (e.g. the shape of their beaks are different).

::::{.columns}

:::{.column}

```{r, echo = T, eval = F}
lsmodel1 <- lm(bill_length_mm ~ 
              bill_depth_mm +
              body_mass_g + 
              species + 
              species:bill_depth_mm, #<<
            data = penguins)

summary(lsmodel1)

```

:::

:::{.column}

```{r, echo = F}
lsmodel1 <- lm(bill_length_mm ~ 
              bill_depth_mm +
              body_mass_g + 
              species + 
              species:bill_depth_mm, #<<
            data = penguins)

summary(lsmodel1)

```

:::

::::


## Additive vs Interaction


::::{.columns}

:::{.column}

### Additive model

```{r, echo = FALSE, out.width="90%", fig.alt = "No Interaction effect"}

knitr::include_graphics("images/no_interaction.png")

```

:::

:::{.column}

### Interaction model

```{r, echo = FALSE, out.width="90%", fig.alt = "Line fitting"}

knitr::include_graphics("images/interaction.png")

```

:::

::::

## Model summary

```{r, echo = T}
lsmodel1 %>% 
  broom::tidy()
```



## F-test between nested models

$$F = \frac{{(SSE_1 - SSE_2) / (df_1 - df_2)}}{{SSE_2 / df_2}}$$
Where $SSE_1$ is the simpler/nested model; $SSE_2$ is the full/original model

$df_1$is the degrees of freedom for the simpler model (number of observations - number of model parameters for the simpler model).

$df_2$is the degrees of freedom for the more complex model (number of observations - number of model parameters for the more complex model).


## F-test between nested models

$$F = \frac{{(SSE_1 - SSE_2) / (df_1 - df_2)}}{{SSE_2 / df_2}}$$

```{r}
lsmodel2 <- lm(bill_length_mm ~ 
              bill_depth_mm +
              body_mass_g + 
              species,
            data = penguins)
```

```{r, echo = T}
anova(lsmodel2, lsmodel1)

```



## Interpret an interaction term

Once we add an interaction term we can no longer interpret that "on average bill length increases by 0.29mm for every 1mm increase in bill depth. Because bill depth **also shows up as interaction term with species**

:::{.fragment}

We now have to interpret this as :

For a specific species of penguin e.g. Chinstrap

$Bill~length=23.7+0.29_{bill depth}+0.002_{body mass}+-10.27_{Chinstrap}+1.09_{bill~depth*species}$

:::

:::{.fragment}

"For Chinstrap penguin we expect a penguin with a bill depth of 13.2 mm to increase bill length by:"

$(0.002*body~mass)+(1*-10.2)+(0.002*1.09*1)$

:::


## When considering interaction terms

:::{.incremental}

* Have a clear basis for *why* you expect an interaction (and visualise the data)

* Know that your coefficients WILL change when you add an interaction

* You can add the interaction term as a way to TEST the hypothesis for a significant interaction, then drop it from your model if not required. 

:::


## Estimates and CI

- Estimates and CI **must come from your full model**


- It is ok to run F tests on simpler models (interaction term removed) - in order to get F statistics of main effects

```{r, echo =T}

drop1(lsmodel2, test = "F")

```

## Emmeans in interaction models

Generalisations are no longer valid in interaction models, the effect of a predictor variable on the dependent variable is now conditional on the value of the other predictor variable

::::{.columns}

:::{.column}

```{r}
#|echo: TRUE
#|message: TRUE
#|info: TRUE
#|warning: TRUE


emmeans::emmeans(lsmodel1,
                 specs = ~ bill_depth_mm,
            data = penguins)
```

>NOTE: Results may be misleading due to involvement in interactions

:::

:::{.column}

```{r}
#|echo: TRUE
#|message: TRUE

emmeans::emmeans(lsmodel1,
                 specs = ~ bill_depth_mm + species,
            data = penguins)
```

:::

::::

## Exercise multiple regression

```{r}
#| label: ex-mult-regression
countdown::countdown(
  minutes = 40,
  color_border = "#00AEEF",
  color_text = "#00AEEF",
  color_running_text = "white",
  color_running_background = "#00AEEF",
  color_finished_text = "#00AEEF",
  color_finished_background = "white",
  top = 0,
  margin = "1.2em",
  font_size = "2em"
)
```

# Turning a hypothesis into a model {background-color="#D9DBDB"}

## Turning a question into a model

- Hypotheses in research predict relationships between variables.

- Linear models help test these hypotheses by quantifying these relationships.

- Converting hypotheses into linear models involves identifying dependent and independent variables.

- Considering and including important covariates

- Determining whether interaction terms need to be included


## Simple linear model

:::{.incremental}

- **Question**: Does the amount of sunlight affect plant growth?

- **Hypothesis**: More sunlight hours increase plant growth

- **Linear Model**: `height ~ sunlight_hours`

:::


## Control variables

:::{.incremental}

- **Question**: Does the amount of sunlight affect plant growth?

- **Hypothesis**: More sunlight hours increase plant growth

- **Control variables**: Soil quality

- **Linear Model**: `height ~ sunlight_hours + soil quality`

:::

## Multiple predictor model

:::{.incremental}

- **Question**: How do water and nutrient levels affect plant growth?

- **Hypothesis**: Both increased water and nutrient levels lead to increased plant growth.

- **Control Variables**: Temperature

- **Linear Model**: `growth ~ water + nutrient + temp_c`

:::


## Multiple predictor model

:::{.incremental}

- **Question**: Do water and nutrient levels work together to affect plant growth?

- **Hypothesis**: Increasing water and nutrient levels has a combined effect that leads to increased plant growth, greater than the effect of either on their own.

- **Control Variables**: Temperature

- **Linear Model**: `growth ~ water + nutrient + temp_c + water:nutrient`

:::

## Exercise 1

:::{.incremental}

- **Question**: Does temperature affect the metabolic rate of lizards?

- **Hypothesis**: Temperature increases the metabolic rate of lizards

- **Control Variables**: Age of lizards

- **Linear Model**: `metabolic_rate ~ temp + age`

:::

## Exercise 2:

:::{.incremental}

- **Question**: How does diet and exercise affect cholesterol in mice?

- **Hypothesis**: low fat diets and regular exercise decrease cholesterol levels in mice

- **Control Variables**: Genetic strain of mice

- **Linear Model**: `cholesterol ~ diet_fat + daily_exercise_hours + strain`

- **Linear Model**: `cholesterol ~ diet_fat + daily_exercise_hours + strain + diet_fat:daily_exercise`

:::

## Exercise 3:

:::{.incremental}

- **Question**: Do immune system responses depend on stress and sleep in humans?

- **Hypothesis**: Negative effects of stress on immune responses are lessened if sleep duration remains high

- **Control Variables**: Age

- **Linear Model**: `immune_response ~ sleep_hours + stress + age + sleep_hours:stress`

:::

# Questions?

# Fitting models  {background-color="#D9DBDB"}

## How do I know my model is a good fit?


### 1. Statistics are no substitute for judgment

Have a clear hypothesis for why variables are being included (and whether they might interact)

### 2. Check assumptions & diagnostics

A model with poor diagnostics is a bad fit for the data – confidence intervals and p values will not be robust. 


## Model checks

- Start by fitting a model that includes your dependent variable(s), covariates and specifies any key interactions

- Check the model is a good fit for the observed data

:::{.incremental}

* Diagnostic plots of residuals


* Multicollinearity



* Omitted Variable Bias



* Irrelevant variables



* Hypothesis testing for model simplification


:::



## Model checks

::::{.columns}

:::{.column width="40%"}

```{r, echo = T}

lsmodel1 <- lm(bill_length_mm ~ 
              bill_depth_mm +
              body_mass_g + 
              species + 
              species:bill_depth_mm, #<<
            data = penguins)

```

:::

:::{.column width="60%"}

```{r, echo = T}
library(performance)

check_model(lsmodel1, detrend = FALSE)

```

:::

::::

## Linearity and heteroscedasticity

```{r, echo = F, out.width = "90%"}
library(performance)

check_model(lsmodel1, check = c("linearity", "homogeneity"))

```

## Collinearity and High Leverage {.smaller}

::::{.columns}

:::{.column width="40%"}

The next two plots analyze for collinearity and high leverage points.


**High Leverage Points** are observations that deviate far from the average. These can skew the predictions for linear models.

**Collinearity** is when features are highly correlated, which can throw off simple regression models. However, when we are using interaction terms - we *expect* these to be highly correlated with main effects. 

:::

:::{.column width="60%"}


```{r, echo = F}


check_model(lsmodel1, check = c("vif", "outliers"))

```

:::

::::

## Multicollinearity

Correlation between predictor variables in a linear model = High VIF


One pair = collinearity, 

two or more = multicollinearity



Can be a result of an overspecified model (chucked everything in without thinking) 

also common in observation datasets (rather than experimental datasets) 

mean-centering continuous variables can reduce this

e.g. ecological data where variables may be dependent on each other



$R^2$ may be high


BUT individual predictors may have high uncertainties and appear non-significant


Variance Inflation Factor

$VIF_j={1\over{1-R^2_i}}$


Each predictor is regressed (in turn) against the full model *without* that predictor present $R^2_i$


## Normality of Residuals


::::{.columns}

:::{.column width="40%"}


If the distributions are skewed, this can indicate problems with the model.

**Quantile-Quantile Plot**: We can see that several points towards the end of the quantile plot do not fall along the straight-line. 

**Normal density Plot**: The residuals fit a very nice normal distribution

:::

:::{.column width="60%"}

```{r, echo = F, out.width = "90%"}


check_model(lsmodel1, check = c("qq", "normality"), detrend = FALSE)

```

:::

::::




## Assumptions not met?

### What if our data does not satisfy one or more of these assumptions?

---

## Data transformations

If our assumptions are violated, then depending on the issue, estimates of the mean or uncertainty intervals may be biased, affecting our ability to determine statistical significance. 


Transformations can help with:

:::{.incremental}

1. Heteroscedasticity (the opposite of Homogeneity) of variance



2. Non-linearity



3. Non-normal residual variance



4. Outliers (sometimes) - might be possible to remove these

:::

```{}
lm(sqrt(y) ~ x)

lm(log(y) ~ x)
```

---

## Choosing a transformation

::::{.columns}

:::{.column}

```{r, echo = T, out.width = "90%"}
MASS::boxcox(lsmodel1)

```

:::

:::{.column}


|Lambda value $\lambda$ | Transformed data (Y)|
|-----------------------|-----------------------|
|-2|Y^-2|
|-1|Y^-1|
|-0.5|Y^-0.5|
|0|log(Y)|
|0.5|sqrt(Y)|
|1|Y^1|
|2|Y^2|

:::

::::





## Omitted variable bias

Bias created when one or more predictor variables are incorrectly left out of a model

e.g. this predictor variable should have been included because you could reasonably expect it to influence the outcome. 


* Model *may* be a poor fit

* Other terms may have their influence over – or underestimated ( it is not always clear which way round this will occur).



* Standard errors and measures of uncertainty are wrong



* Significance tests are biased



* Predictions will be wrong



## Irrelevant variables

**The other side of the coin – Including irrelevant variables**



* Estimates will be unbiased but perhaps inefficient (greater variances, SE, CI)

* Variances will be unbiased (**but maybe not optimal for hypothesis testing**)

* Greater sample size can help reduce inconsistency and selection bias issues

* Prediction will be unchanged



**So: it’s better to INCLUDE an irrelevant predictor variable that to OMIT a relevant one if you aren't sure.**



## Model fit checklist

Think **HARD** about what terms should be included in a model to test a hypothesis

::::{.columns}

:::{.column}

1) Which terms is it reasonable to test might interact with each other to affect y? 

2) Which terms might be showing signs of collinearity? 

3) Visualise your data

4) Fit your most complex model (main terms and interactions)

:::

:::{.column}

5) Check the model fit/diagnostics

    - Homogeneity of variance,
    
    - normal distribution of residuals,
    
    - collinearity

6) Refit model (change terms, data transformation if necessary)

7) Test removal of interaction terms 

8) Leave all main predictors in the model/refine model further.

:::

::::

## Model checks by simulation

DHARMa works by simulating residuals from the fitted model, comparing them with observed residuals, and providing diagnostic plots to assess model adequacy and identify potential issues like heteroscedasticity or influential data points.

It can be useful for complex model types (GLM(M)) & when sample sizes are very low

```{r, echo = T}

plot(DHARMa::simulateResiduals(lsmodel1))

```

## Exercise - complex linear models

```{r}
#| label: ex-complex-models
countdown::countdown(
  minutes = 45,
  color_border = "#00AEEF",
  color_text = "#00AEEF",
  color_running_text = "white",
  color_running_background = "#00AEEF",
  color_finished_text = "#00AEEF",
  color_finished_background = "white",
  top = 0,
  margin = "1.2em",
  font_size = "2em"
)
```

## Stepwise-removal

- Stepwise regression is a popular tool for simplifying models and removing non-significant predictors

- However standard statistical tests do not account for sequential testing

- models can have inflated p-valyes and narrow confidence intervals

- I recommend restricting this to testing whether interaction terms are required

[Step away from stepwise](https://doi.org/10.1186/s40537-018-0143-6)


## Testing whether interactions can be removed

$R^2$ almost always increases as you add more terms and interactions. This does not increase your ability to test predictors. 

The adjusted $R^2$ may be more a more reliable measure.

`anova()` or `drop1()` both produce **likelihood ratio F-tests** when comparing **nested models**.

$F = {({SSE_{full} - SSE_{reduced}})\over{df_{full} - df_{reduced}}}$


$F = {SSE\Delta\over df\Delta}$


## Types of sums of squares

There are three types of sums of squares I, II & III

By default `anova()` implements type I


When data are balanced these will all be **the same**. For unbalanced designs these may not



## drop1()

The `drop1()` function compares all possible models that can be constructed by dropping a single model term. As such it produces the most robust sum of squares for F-test with unbalanced model design.

```{r, echo = T}
drop1(lsmodel1, test = "F")

```

Note it drops all terms that *can* be dropped e.g. species cannot be dropped here, because it is in the interaction term.

Equivalent to `anova(reduced model, full model)`

---

## drop1()

```{r, echo = T}

lsmodel1a <- lm(bill_length_mm ~ bill_depth_mm + body_mass_g + species,
            data = penguins)

drop1(lsmodel1a, test = "F")

```

If an interaction is dropped from a full model, then `drop1()` could be re-run. This can be done to simplify the model, or just accurately acquire F values **only for the main effects also involved in an interaction**.

## Reporting

**Any estimates or confidence intervals should come from full model.**

```{r, echo = T}
gtsummary::tbl_regression(lsmodel1)
```

## AIC

:::{.incremental}

- The Akaike Information Criterion (AIC)  balances the trade-off between model fit and complexity by penalizing models with more parameters.

- It aims to find the model that best explains the data while avoiding overfitting.

- AIC is calculated as follows: $\text{AIC} = 2k - 2\ln(\hat{L})$, 

- where: log-likelihood is the maximized value of the likelihood function for the fitted model. $k$ is the number of parameters in the model.

- In general a difference in AIC of <2 suggests equivalent goodness-of-fit

:::

## AIC

::::{.columns}

:::{.column}

**AIC can:**

- Compare non-nested models fitted to the same dataset and response variable

- Compare across different GLM families and link functions

:::

:::{.column}

**AIC cannot:**

- Compare models where the response variable is transformed

- Compare models where there are differences in the dataset

:::

::::

```{r, echo = T}

AIC(lsmodel1, lsmodel1a)

```

## AIC


```{r, echo = T}
drop1(lsmodel1, test = "F")

```

## Model dredging

```{r}


penguins1 <- penguins %>% drop_na(bill_length_mm) %>% 
  mutate(bill_depth_mm = mean(bill_depth_mm) - bill_depth_mm,
         body_mass_g = mean(body_mass_g) - body_mass_g)
```

```{r, echo = T}

library(MuMIn)

model <- lm(bill_length_mm ~ bill_depth_mm * body_mass_g * species,
            data = penguins1, na.action = "na.fail")

model_dredge <- dredge(model)

head(model_dredge, n = 3)

```

## Model averaging {.smaller}

```{r, eval = F, echo = T}
model.avg(model_dredge)
```

```{r}

ma_df <- model.avg(model_dredge)
ma_coefs <- coefTable(ma_df, full=TRUE, adjust.se = TRUE)
coefnames <- row.names(ma_coefs)
ma_coefs <- as.data.frame(ma_coefs)
ma_coefs <- mutate(ma_coefs,
                   coefficient = coefnames,
                   t = Estimate / `Std. Error`,
                   p = pt(abs(t), df = 195, lower.tail = FALSE),
                   lower95 = Estimate - 1.96 * `Std. Error`,
                   upper95 = Estimate + 1.96 * `Std. Error`) %>% select(Estimate, `Std. Error`, t, p, lower95, upper95)
knitr::kable(ma_coefs, digits = 2)

```

## Issues with Model averaging

- Multi-collinearity: When predictors are highly correlated, the AIC weights can become unreliable. Multi-collinearity can lead to inflated standard errors and unstable coefficient estimates, which affects the calculation of AIC weights.

- The AIC model weights apply to an entire model and not any individual predictor variables within that model and, thus, have minimal information content about contributions of individual predictor variables to predicted responses

- [Does model averaging make sense](https://drewtyre.rbind.io/post/rebutting_cade/)

- [Model averaging and muddled multimodel inferences](https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/14-1639.1?saml_referrer)


# Issues and pitfalls with models {background-color="#D9DBDB"}


## Univoltine butterflies

- Univoltine species of insects are those that have a single generation per year

- In [this paper](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/1365-2656.12492) the authors investigated the effects of avg temperature in June on adult body size

- Looked at historical temperature data and museum specimens of *Hesperia comma*


## The data

```{r}
#| eval: true
#| echo: false
#| layout-ncol: 2
#| fig-height: 7
#| message: false


butterfly <- readr::read_csv("../data_2/univoltine_butterfly.csv")


butterfly <- butterfly %>% 
  janitor::clean_names()

```

- Year specimen collected

- Forewing length (mm)

- Sex of butterfly

- Average June temp (celsius)

- Average June rainfall (mm)

## Check for errors in continuous data

```{r}
#| eval: true
#| echo: true
#| fig-height: 7
#| message: false

summary(butterfly)

```


## Check for errors in categorical data

```{r}
#| eval: true
#| echo: true
#| fig-height: 7
#| message: false

butterfly %>% 
  distinct(sex)

```

```{r}
#| eval: true
#| echo: true
#| fig-height: 7
#| message: false

butterfly %>% 
  is.na() %>% 
  sum()

```

## Fix the dataset

::::{.columns}

:::{.column}

```{r}
#| eval: false
#| echo: true
#| fig-height: 7
#| message: false

butterfly_correct <- butterfly %>% 
  mutate(rain_jun = if_else(rain_jun >100, mean(rain_jun), rain_jun)) %>% 
  mutate(sex = case_when(sex == "Maes" ~ "Males",
                         sex == "Female" ~ "Females",
                          .default = as.character(sex)))

butterfly_correct %>% 
  distinct(sex)

```

:::

:::{.column}

```{r}
#| eval: true
#| echo: false
#| fig-height: 7
#| message: false

butterfly_correct <- butterfly %>% 
  mutate(rain_jun = if_else(rain_jun >100, mean(rain_jun), rain_jun)) %>% 
  mutate(sex = case_when(sex == "Maes" ~ "Males",
                         sex == "Female" ~ "Females",
                          .default = as.character(sex)))

butterfly_correct %>% 
  distinct(sex)

```

:::

::::

## Pairwise comparisons


```{r}
#| eval: true
#| echo: true
#| fig-height: 7
#| layout-ncol: 2
#| message: false


butterfly_correct %>% 
  GGally::ggpairs(columns = c("forewing_length",
                              "jun_mean",
                              "rain_jun"),
                              ggplot2::aes(colour = sex))

```


## Multiple models {.smaller}


```{r}
#| eval: true
#| echo: true
#| fig-height: 7
#| message: false

butterfly_correct %>% 
  group_split(sex) %>% 
  map(~lm(forewing_length ~ jun_mean + rain_jun, data = .) %>% 
        summary())

```

## Issues

- Fitting multiple models is not appropriate

- Each model has reduced power

- Risks overfitting

- No hypothesis testing for a differential response between the sexes has been performed

## Analysis

```{r}
#| eval: true
#| echo: true
#| fig-height: 7
#| message: false

model <- lm(forewing_length ~ jun_mean + rain_jun + sex + jun_mean:sex, data = butterfly_correct)

summary(model)


```

## Check model fit

```{r}
#| eval: true
#| echo: true
#| fig-height: 7
#| message: false

performance::check_model(model, detrend = F)

```



## Test interaction

```{r}
#| eval: true
#| echo: true
#| fig-height: 7
#| message: false

model_2 <- lm(forewing_length ~ jun_mean + rain_jun + sex, data = butterfly_correct)

anova(model_2, model)

summary(model_2)

```

## Figures

::::{.columns}

:::{.column width="30%"}

```{r}
#| eval: false
#| echo: true
#| fig-height: 7
#| message: false

butterfly_correct %>% 
  ggplot(aes(x = jun_mean,
             y = forewing_length,
             colour = sex))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_classic(base_size = 18)

```

:::

:::{.column width="70%"}

```{r}

#| fig-height: 7
#| message: false

butterfly_correct %>% 
  ggplot(aes(x = jun_mean,
             y = forewing_length,
             colour = sex))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_classic(base_size = 18)

```

:::

::::

## A better figure

::::{.columns}

:::{.column width="30%"}

```{r}
#| eval: false
#| echo: true
#| fig-height: 7
#| message: false

emmeans::emmeans(model_2, specs = ~ sex + jun_mean,
                 at = list(jun_mean = seq(12,17,1))) %>% as_tibble() %>% 
  ggplot(aes(x = jun_mean,
               y = emmean,
               colour = sex,
               fill = sex)) +
  geom_ribbon(aes(ymin = lower.CL,
                  ymax = upper.CL),
              alpha = .2)+
  geom_line()+
  geom_point(data = butterfly_correct,
             aes(x = jun_mean,
                 y = forewing_length))+
  theme_classic(base_size = 18)
  

```

:::

:::{.column width="70%"}

```{r}

#| fig-height: 7
#| message: false

emmeans::emmeans(model_2, specs = ~ sex + jun_mean,
                 at = list(jun_mean = seq(12,17,1))) %>% as_tibble() %>% 
  ggplot(aes(x = jun_mean,
               y = emmean,
               colour = sex,
               fill = sex)) +
  geom_ribbon(aes(ymin = lower.CL,
                  ymax = upper.CL),
              alpha = .2)+
  geom_line()+
  geom_point(data = butterfly_correct,
             aes(x = jun_mean,
                 y = forewing_length))+
  theme_classic(base_size = 18)

```

:::

::::

# Generalized Linear Models {background-color="#D9DBDB"}

## Recapping general linear models

- Also known at the Ordinary Least Squares (OLS) model

- It aims to fit a regression line which minimises the squared differences between observed and predicted values

:::{.fragment}

![](images/ols.png){fig-align="center" fig-alt="ordinary least squares" width=70%}

:::

## Equation of the line

The equation of a linear model (lm) is given by:

$$
y_i = \beta_0 + \beta_1 x_i + \epsilon_i
$$

where:

:::{.incremental}

- $y_i$ is the predicted value of the response variable.

- $\beta_0$ is the intercept.

- $\beta_1$ is the slope coefficient, representing the change in the response variable for a one-unit change in the explanatory variable.

- $x_i$ is the value of the explanatory variable.

- $\epsilon_i$ represents the residuals of the model
:::



## Limitations of general linear models

**Q**. What are the assumptions of a general linear model?

::: {.incremental}

* Assumes a linear relationship

* Assumes normal distribution of the residuals

* Assumes homogeneity of the residuals

* Independence - assumes observations are independent of each other

:::



## Normal distribution of the residuals

The linear regression line is the most likely line given your data if we assume each data point comes from a hypothetical bell curve centered on the regression line

![](images/prob-reg.jpeg){fig-align="center" fig-alt="probability" width=60%}

## Normal distribution

```{r}
#| eval: true
#| echo: false
#| fig-height: 8
#| layout-ncol: 2
#| message: false

# Define a range of mean and standard deviations (average rate of success)
mean <- rep(c(10,20,30), 3)
sd <- rep(c(5, 7, 10), each = 3)

# Generate the data
norm_data <- map2_df(mean, sd, ~tibble(
  mean = factor(.x),
  sd = factor(.y),
  x = seq(0,40, length.out = 100),
  density = dnorm(x, .x, .y)
))  # For ordered plotting

# Plot
norm_data |> 
  filter(mean == 20) |> 
ggplot(aes(x = x, y = density, color = sd)) +
  geom_line(linewidth = 1.5) +
  scale_color_brewer(palette = "Dark2") +
  labs(title = "Change in Normal Distribution \nwith different Standard Deviations, Mean = 20",
       x = "X",
       y = "Probability",
       color = "SD") +
  theme_minimal(base_size = 16)

norm_data |> 
  filter(sd == 7) |> 
ggplot(aes(x = x, y = density, color = mean)) +
  geom_line(linewidth = 1.5) +
  scale_color_brewer(palette = "Accent") +
  labs(title = "Change in Normal Distribution \nwith different Means, SD = 7",
       x = "X",
       y = "Probability",
       color = "Mean") +
  theme_minimal(base_size = 16)

```


## Normal distribution of the residuals

When using our residuals to calculate standard error, confidence intervals and statistical significance these are assumed to be drawn from:

- a normal distribution with mean zero 

- with a constant variance. 

:::{.fragment}
<br>
This implies that the residuals, or the distances between the observed values and the values predicted by the linear model, can be modeled by drawing random values from a normal distribution.

:::

## The linear model equation

Another way to write the lm equation is:

$$
y_i \sim N(\mu = \beta_0 + \beta_1 X_i, \sigma^2)
$$

:::{.fragment}

Which literally means that $y_i$ is drawn from a normal distribution with parameters:

- $\mu$ (which depends on $x_i$)  

- $\sigma$ (which has the same value for all measures of $Y$).

:::


## Real data

How often do these assumptions really hold true? 

A good fit: 

```{r}
#| eval: true
#| echo: false
#| layout-ncol: 2
#| fig-height: 7
#| message: false


janka <- readr::read_csv("../data_2/janka.csv")

model <- lm(sqrt(hardness) ~ dens, weights = 1/sqrt(hardness), data = janka)

plot(model, which=2)

plot(model, which=3)

```


## Real data

How often do these assumptions really hold true? 

An ok fit: 

```{r}
#| eval: true
#| echo: false
#| layout-ncol: 2
#| fig-height: 7
#| message: false

cuckoo <- read_csv("../data_2/cuckoo.csv")

cuckoo_lm <- lm(Beg ~ Mass + Species + Mass:Species, data = cuckoo)

plot(cuckoo_lm, which=2)

plot(cuckoo_lm, which=3)
```

## Real data

How often do these assumptions really hold true? 

A poor fit: 

```{r}
#| eval: true
#| echo: false
#| layout-ncol: 2
#| fig-height: 7
#| message: false

load(file = "../data_2/Mayflies.rda")

Mayflies_lm <- lm(Occupancy ~ CCU, data = Mayflies)

plot(Mayflies_lm, which=2)

plot(Mayflies_lm, which=3)
```


## Assumption testing


```{r}
#| fig-height: 7
par(mfrow = c(2, 2), mar = c(4, 4, 2, 1))
plot(model)

```




## Residuals vs Fitted

::::{.columns}

:::{.column}

```{r}

plot(model, which=1)

```

:::

:::{.column}

- **Purpose:** To check for linearity and homoscedasticity.

- **Interpretation:** Look for a random scatter of points around the horizontal line at y = 0. A funnel-shaped pattern suggests heteroscedasticity.

:::

::::


## QQ-plot

::::{.columns}

:::{.column}

```{r}

plot(model, which=2)

```

:::

:::{.column}

- **Purpose:** To assess the normality of the residuals

- **Interpretation:** Points should fall along the diagonal line. Deviation from the line indicates non-normality of residuals.

:::

::::

## Scale-location

::::{.columns}

:::{.column}

```{r}

plot(model, which=3)

```

:::

:::{.column}

- **Purpose:** To check homoscedasticity and identify outliers

- **Interpretation:** Uses **standardised** residuals. Constant spread indicates homoscedasticity

:::

::::

## Residuals vs. Leverage

::::{.columns}

:::{.column}

```{r}

plot(model, which=4)

```

:::

:::{.column}

- **Purpose:** To identify influential data points(outliers)

- **Interpretation:** Loking for points with high leverage that might affect the regression line. Investigate values > 0.5

:::

::::


## Performance

::::{.columns}

:::{.column}

The `performance` package from [easystats](https://easystats.github.io/easystats/) can produce (among other things) similar plots.

:::

:::{.column}

```{r}
#| fig-height: 7

library(performance)
check_model(model)

```

:::

::::

## Formal tests

::::{.columns}

:::{.column}

- For linear models we can also run some formal tests on the residuals

```{r}
#| eval: true
#| echo: true
#| message: false

# lmtest::bptest(model)

performance::check_normality(model)

# shapiro.test(residuals(model))

performance::check_heteroscedasticity(model)

```
:::

:::{.column}

- This becomes more difficult with generalised models

- Being able to interpret residual plots is important

:::

::::

# Generalised Linear Models {background-color="#D9DBDB"}

## What are Generalised linear models?

:::{.incremental}

- The Generalised Linear Model (GLM) is an extension of the ordinary linear regression model that accommodates a broader range of response variable types and error distributions.

- Key components: 

- **Linear Predictor:** Combines predictor variables linearly.

- **Link Function:** Links the mean of the response variable to the linear predictor.

- **Error family:** Drawn from the **exponential family** it determines the shape of the response variable's distribution.

:::


## Linear Predictor

Linear models:

::: {.center-text}


$y_i = \beta0 + \beta_1x1 + \beta_2x2 + ... +\beta_nxn +\epsilon_i$

:::



::: {.fragment}

<br>

Then generalised linear models...

::: {.center-text}

$\eta_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots + \beta_n x_{ni}$


:::

- $\eta_i$ the linear prediction for observation $i$

:::


## The link function


Let's start with linear models...

::: {.center-text}


$y_i = \beta0 + \beta_1x1 + \beta_2x2 + ... +\beta_nxn +\epsilon_i$

:::

::: {.fragment}

<br>

Then generalised linear models...

::: {.center-text}

$g(\mu_i) = \eta_i$


:::

:::

:::{.fragment}

- $\eta_i$ linear prediction for observation $i$

- $g$ the link function relating the linear predictor to the expected value (mean) of the response variable

- $\mu_i$ is the expected value of the response variable for observation $i$

Common link functions: identity, sqrt, log, logit

:::


## Error family

Let's start with linear models...

::: {.center-text}


$y_i = \beta0 + \beta_1x1 + \beta_2x2 + ... +\beta_nxn +\epsilon_i$


$\epsilon_i = \mathcal{N}(0, \sigma^2)$

:::



::: {.fragment}

Then generalised linear models...

::: {.center-text}

$\mu_i = f(\eta_i)$

$\epsilon_i \sim \mathcal{N}(0, \sigma^2)$

:::

:::

:::{.fragment}

 - $\epsilon_i$ is the error term for observation $i$

**Examples:** Gaussian (normal), binomial, Poisson, gamma, etc.

:::

## Generalised Linear Model

::::{.columns}

:::{.column}

**Linear Predictor** ($\eta$):

$\eta_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots$

**Link Function** ($g$):

$g(\mu_i) = \eta_i$

**Probability Distribution**:

$\mu_i = f(\eta_i)$

$\epsilon_i \sim \mathcal{N}(0, \sigma^2)$

:::

:::{.column}

- $\eta_i$ linear prediction for observation $i$

- $g$ the link function relating the linear predictor to the expected value (mean) of the response variable

- $\mu_i$ is the expected value of the response variable for observation $i$

- $f$ the inverse of the link function, transforming the linear predictor back to the response variable's expected value

- $\epsilon_i$ is the error term for observation $i$

:::

::::

## Changing model structures

There are a range of model structures available. 

The choice of error family and link influence how well the model fits

| Exponential Error Family      | Link Function       |
|-------------------|---------------------|
| Gaussian          | Identity, sqrt, log, inverse            |
| Binomial          | Logit, probit, cloglog               |
| Poisson           | Log, identity, sqrt                 |
| Gamma             | Inverse, identity, log, sqrt             |
| Negative Binomial | Log, identity, sqrt|


## Choosing an error family

::::{.columns}

:::{.column width="40%"}

- What type of variable is the outcome?

- Fit models: check residuals and AICs

:::

:::{.column width="60%"}

![](images/flow.png){fig-align="center" fig-alt="physalia logo" width=150%}

:::

::::


# Questions? {background-color="#D9DBDB"}

# A Linear Model Example {background-color="#D9DBDB"}

## Janka timber hardness

This regression analysis uses data from the Australian forestry industry recording wood density and timber hardness from 36 different samples

:::{.incremental}

- Timber hardness is quantified on the "Janka" scale

- The 'amount of force required to embed a 0.444" steel ball into the wood to half of its diameter'.

:::

## Fitting the general linear model

```{r}
#| eval: true
#| echo: false
#| fig-height: 7
#| message: false

janka <- readr::read_csv("../data_2/janka.csv")

```


```{r}
#| eval: true
#| echo: true
#| layout-ncol: 2
#| fig-height: 8
#| message: false

janka_ls <- lm(hardness ~ dens, data = janka)

summary(janka_ls)

janka |> 
  ggplot(aes( x = dens, y = hardness))+
  geom_point()+
  geom_smooth(method = "lm")

```


## Model diagnostics

```{r}
#| eval: true
#| echo: true
#| layout-ncol: 2
#| fig-height: 8
#| message: false

plot(janka_ls, which=2)

plot(janka_ls, which=3)
```


## Violations of assumptions

```{r}
#| eval: true
#| echo: true
#| fig-height: 8
#| message: false

library(performance)

# Breusch-Pagan Test of Homoscedasticity
check_heteroscedasticity(janka_ls)

# Shapiro-Wilk test for normality of residuals
check_normality(residuals(janka_ls))



```


## BoxCox

The R output for the `MASS::boxcox()` function plots a maximum likelihood curve (with a 95% confidence interval - drops down as dotted lines) for the best transformation for fitting the dependent variable to the model.

::::{.columns}

:::{.column}

| lambda value | transformation |
|--------------|----------------|
| 0            | log(Y)         |
| 0.5          | sqrt(Y)        |
| 1            | Y              |
| 2            | Y^1            |

:::

:::{.column}

```{r}
#| eval: true
#| echo: true
#| fig-height: 7

MASS::boxcox(janka_ls)

```

:::

::::

## Square root transformation

```{r}
#| eval: true
#| echo: true
#| layout-ncol: 2
#| fig-height: 8
#| message: false

janka_sqrt <- lm(sqrt(hardness) ~ dens, data = janka)

plot(janka_sqrt, which=2)

plot(janka_sqrt, which=3)

```

## Model fit

```{r}
#| eval: true
#| echo: true
#| layout-ncol: 2
#| fig-height: 8
#| message: false

ggplot(janka, aes(x = hardness, y = dens)) +
  geom_point() +  # scatter plot of original data points
  geom_smooth(method = "lm", formula = y ~ sqrt(x)) +  # regression line
  labs(title = "Sqrt Linear Regression with ggplot2",
       x = "X", y = "Y")  # axis labels and title

```


## Log transformation

```{r}
#| eval: true
#| echo: true
#| layout-ncol: 2
#| fig-height: 8
#| message: false

janka_log <- lm(log(hardness) ~ dens, data = janka)

plot(janka_log, which=2)

plot(janka_log, which=3)

```

## Model fit

```{r}
#| eval: true
#| echo: true
#| fig-height: 8
#| message: false
ggplot(janka, aes(x = hardness, y = dens)) +
  geom_point() +  # scatter plot of original data points
  geom_smooth(method = "lm", formula = (y ~ log(x))) +  # regression line
  labs(title = "Log Linear Regression",
       x = "X", y = "Y")  # axis labels and title
```

## Polynomials

```{r}
#| eval: true
#| echo: true
#| layout-ncol: 2
#| fig-height: 8
#| message: false

janka_poly <- lm(log(hardness) ~ poly(dens, 2), data = janka)

plot(janka_poly, which=2)

plot(janka_poly, which=3)

```

## Polynomial fit

```{r}
#| eval: true
#| echo: true
#| layout-ncol: 2
#| fig-height: 8
#| message: false

summary(janka_poly)



ggplot(janka, aes(x = hardness, y = dens)) +
  geom_point() +  # scatter plot of original data points
  geom_smooth(method = "lm", formula = (y ~ poly(log(x), 2))) +  # regression line
  labs(title = "Quadratic Log Linear Regression",
       x = "X", y = "Y")  # axis labels and title



```


## Weighted least squares

```{r}
#| eval: true
#| echo: true
#| message: false

janka_wls <- lm(sqrt(hardness) ~ dens, weights = 1/sqrt(hardness), data = janka)

```

- Weights are specified as $\frac{1}{\sqrt{\text{hardness}}}$, indicating that observations with higher hardness values will have lower weights, and vice versa.

- This weighting scheme can assign more importance to certain observations in the model fitting process.

- This approach is known as weighted least squares (WLS) regression, where observations are weighted differently based on certain criteria, such as the square root of hardness.

## Weighted least squares

```{r}
#| eval: true
#| echo: true
#| layout-ncol: 2
#| fig-height: 8
#| message: false

janka_wls <- lm(sqrt(hardness) ~ dens, weights = 1/sqrt(hardness), data = janka)

plot(janka_wls, which=2)

plot(janka_wls, which=3)

```

## Model fit

```{r}
#| eval: true
#| echo: false
#| fig-height: 8
#| layout-ncol: 2
#| message: false

prediction_data <- data.frame(dens = sort(unique(janka$dens)))
predictions <- predict(janka_wls, newdata = prediction_data, interval = "confidence", level = 0.95)

# Adding predictions and confidence intervals to the dataframe
prediction_data$wls_pred = predictions[, "fit"]
prediction_data$wls_pred.lwr = predictions[, "lwr"]
prediction_data$wls_pred.upr = predictions[, "upr"]

ggplot(janka) +
     geom_ribbon(data = prediction_data, aes(x = dens, ymin = wls_pred.lwr, ymax = wls_pred.upr), alpha = 0.8, fill = "lightgray")+
    geom_line(data = prediction_data, aes(x = dens, y = wls_pred), color = "blue")+
  geom_point(aes(x = dens, y = sqrt(hardness)))

summary(janka_wls)

```

## Troublesome transformations

:::{.incremental}

- Changes interpretability

- Can introduce NEW violations of assumptions

- Error and Mean change together

- We don't understand the true structure of our data

- [Implications of log-transformation](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4120293/)

:::


# A Generalised Linear Model Example {background-color="#D9DBDB"}

## A Generalised linear model approach


* Fit a `glm(gaussian(link = "identity"))` to the data

* Check that the model is identical to the `lm()`

```{r}
#| eval: true
#| echo: true
#| fig-height: 8
#| message: false


janka_glm <- glm(hardness ~ dens, data = janka, family = gaussian(link = "identity"))

summary(janka_glm)

```

## A Generalised linear model approach

We previously identified that the **square root** of the dependent variable might have been a better fit with our linear model:

```{r}
#| eval: true
#| echo: true
#| fig-height: 8
#| message: false


janka_glm <- glm(hardness ~ dens, data = janka, family = gaussian(link = "sqrt"))

summary(janka_glm)

```


## Plot model

::::{.columns}

:::{.column}

```{r}
#| eval: false
#| echo: true
#| fig-height: 8
#| message: false


ggplot(janka, aes(x = dens, y = hardness)) +
  geom_point() +  # scatter plot of original data points
  geom_smooth(method = "glm", method.args = list(gaussian(link = "sqrt"))) +  # regression line
  labs(title = "Linear Regression with ggplot2",
       x = "X", y = "Y")  # axis labels and title


```

:::

:::{.column}

```{r}
#| eval: true
#| echo: false
#| fig-height: 8
#| message: false


ggplot(janka, aes(x = dens, y = hardness)) +
  geom_point() +  # scatter plot of original data points
  geom_smooth(method = "glm", method.args = list(gaussian(link = "sqrt"))) +  # regression line
  labs(title = "Linear Regression with ggplot2",
       x = "X", y = "Y")  # axis labels and title


```

:::

::::

## Residuals

```{r}
#| eval: true
#| echo: true
#| layout-ncol: 2
#| fig-height: 8
#| message: false

janka_glm <- glm(hardness ~ dens, data = janka, family = gaussian(link = "sqrt"))

plot(janka_glm, which=2)

plot(janka_glm, which=3)

```



## Choosing an Error family


### Gamma

:::: columns

::: {.column}

```{r}
#| eval: true
#| echo: false
#| fig-height: 7
#| message: false

# Define a range of shape values
shape_values <- c(1, 2, 5, 10)
scale_value <- 2 # Keep scale fixed for simplicity

# Generate the Gamma distribution data
gamma_data <- map_df(shape_values, ~tibble(
  shape = .x,
  x = seq(0, 20, length.out = 100),
  density = dgamma(seq(0, 20, length.out = 100), shape = .x, scale = scale_value)
)) %>%
  mutate(shape = factor(shape, levels = shape_values)) # For ordered plotting

# Plot
ggplot(gamma_data, aes(x = x, y = density, color = shape)) +
  geom_line() +
  scale_color_brewer(palette = "Dark2") +
  labs(title = "Change in Gamma Distribution with Different Shape Parameters",
       x = "Value",
       y = "Density",
       color = "Shape Parameter") +
  theme_minimal(base_size = 16)

```

$f(x;\alpha,\beta) = \frac{\beta^\alpha x^{\alpha - 1} e^{-\beta x}}{\Gamma(\alpha)}$

::: 

::: {.column}

- Shape (α): Determines the shape or curve of the distribution. Higher values of α result in distributions that are more peaked and skewed to the left.

- Rate (β): Influences the spread of the distribution. Smaller values of β result in distributions that are more spread out, larger values of β lead to distributions that are less spread out.

- Useful for modelling **positively skewed continuous  non-negative data**

:::


::::


## Gamma GLM

```{r}
#| eval: true
#| echo: true
#| fig-height: 8
#| message: false


janka_gamma <- glm(hardness ~ dens, data = janka, family = Gamma(link = "sqrt"))

summary(janka_gamma)

```

## Plot model

::::{.columns}

:::{.column}

```{r}
#| eval: false
#| echo: true
#| fig-height: 8
#| message: false


check_model(janka_gamma, detrend =F) 


```

:::

:::{.column}

```{r}
#| eval: true
#| echo: false
#| fig-height: 7
#| message: false


check_model(janka_gamma, detrend =F) 


```

:::

::::


# Questions? {background-color="#D9DBDB"}


# Likelihood {background-color="#D9DBDB"}


## Log-Likelihood

::::{.columns}

:::{.column}

- Likelihood measures the probability of observing the given data under a specific statistical model, as a function of the model's parameters.

- It represents how well the model explains the observed data.

- The log likelihood function in maximum likelihood estimations is usually computationally simpler as it is additive.

:::

:::{.column}

![](images/log-likelihood.png){fig-align="center" fig-alt="The log-likelihood (l) maximum is the same as the likelihood (L) maximum." width=100%}

:::

::::

## Log-Likelihood

Likelihood Function:

$L(\theta | y) = f(y_1 | \theta) \times f(y_2 | \theta) \times \ldots \times f(y_n | \theta)$

:::{.fragment}
<br>
Log-Likelihood Function:

$\ell(\theta | y) = \log(f(y_1 | \theta)) + \log(f(y_2 | \theta)) + \ldots + \log(f(y_n | \theta))$

:::

:::{.fragment}
<br>
Although log-likelihood functions are mathematically easier than their multiplicative counterparts, they can be challenging to calculate by hand. They are usually calculated with software.

:::

## Maximum Likelihood Estimation

For a specified error family distribution and link function, the glm finds parameter values that have the highest likelihood score.

:::{.incremental}

- Which estimates are most probable for producing the observed data

- This is an iterative process, without a single defined equation

- For gaussian and identity link it will produce the same outcome as OLS.

:::

Log-Likelihood Function:
$$\ell(\theta | \mathbf{y}) = \sum_{i=1}^{n} \log(f(y_i | \theta))$$


## Maximum Likelihood


::::{.columns}

:::{.column}

```{r}
#| eval: true
#| echo: false
#| fig-height: 8
#| message: false
#| warning: false

# Simulated data
set.seed(42)

log_likelihood_visual <- function(mean = 6, sd = 1){

data <- rnorm(100, mean = mean, sd = sd)

# Define a grid of mu and sigma values
mu_range <- seq(mean-(sd*2), mean+(sd*2), length.out = 100)
sigma_range <- seq(sd-sd, sd+sd, length.out = 100)
sigma_range[sigma_range < 1] <- 1
grid <- expand.grid(mu = mu_range, sigma = sigma_range)

# Function to calculate log-likelihood for normal distribution
log_likelihood <- function(mu, sigma, data) {
  n <- length(data)
  -n/2 * log(2 * pi) - n * log(sigma) - 1/(2 * sigma^2) * sum((data - mu)^2)
}

# Calculate log-likelihood for each combination of mu and sigma
grid$log_likelihood <- mapply(log_likelihood, mu = grid$mu, sigma = grid$sigma, MoreArgs = list(data = data))

# Plot
ggplot(grid, aes(x = mu, y = sigma, z = log_likelihood)) +
  geom_contour_filled(aes(fill = after_stat(level)), bins = 20) + # Use geom_contour_filled for filled contour plots
  labs(title = "Log-Likelihood Contour Plot",
       x = expression(mu),
       y = expression(sigma),
       fill = "Log-Likelihood") +
  theme_minimal()
}

log_likelihood_visual()
```

:::

:::{.column}

- A contour plot visualizing the log-likelihood surface for a normal distribution fitted to simulated data. 

- The contour lines on the plot represent regions of equal log-likelihood values. Darker regions indicate lower log-likelihood values, while lighter regions indicate higher log-likelihood values

:::

::::


## Deviance

- The deviance is a key concept in Generalised linear models. 

- It measures the deviance of the fitted Generalised linear model with respect to a perfect/**saturated** model for the sample.

```{r}
#| eval: true
#| echo: false
#| fig-height: 6
#| message: false



# Simulate some data
set.seed(123)
n <- 100  # Sample size
x <- rnorm(n)  # Predictor variable
y <- 2 + 3*x + rnorm(n)  # Continuous response variable (linear relationship)

# Fit the null model (intercept only)
null_model <- lm(y ~ 1)

# Fit the saturated model (fully saturated model)
saturated_model <- lm(y ~ x)

# Fit the fitted model (linear predictor with x)
fitted_model <- lm(y ~ x)

# Create a dataframe to store observed points
observed_data <- data.frame(x = x, y = y)

# Generate fitted lines
fitted_lines <- data.frame(x = sort(x))
fitted_lines$Null <- predict(null_model, newdata = fitted_lines)
fitted_lines$Fitted <- predict(fitted_model, newdata = fitted_lines)

# Plot observed points and fitted lines
ggplot() +
    geom_point(data = observed_data, aes(x = x, y = y), color = "black") +
    geom_line(data = fitted_lines, aes(x = x, y = Null, color = "Null")) +
    geom_line(data = observed_data, aes(x = x, y = y, color = "Saturated")) +
    geom_line(data = fitted_lines, aes(x = x, y = Fitted, color = "Fitted")) +
    scale_color_manual(values = c("Null" = "red", "Saturated" = "blue", "Fitted" = "green"),
                       name = "Model") +
    labs(
        title = "Fitted Lines vs Observed Points",
        x = "x",
        y = "y"
    ) +
    theme_minimal(base_size = 14)


```




## Pseudo R-squared

::::{.columns}

:::{.column}

![](images/deviance.png){fig-align="center" fig-alt="" width=100%}

:::

:::{.column}

Formula: 

$GLM~R^2 = 1 - \frac{D}{D_0}$

$linear\_model~R^2= 1 - \frac{SSE}{SST}$


- $D$ is the deviance of the fitted model.

- $D_0$ is the deviance of the null model (linear model with only an intercept).

The GLM $R^2$ **is not** the percentage of variance explained by the model, but rather a ratio indicating how close the fit is to being perfect.

:::

::::

## Pseudo R-squared in R

- We can fit the deviance-based pseudo $R^2$ with the `MuMIn` package

- `r.squaredLR()` is a function used to compute the likelihood ratio (LR) based R-squared for a given model

```{r}
#| eval: true
#| echo: true
#| message: false



library(MuMIn)

r.squaredLR(janka_gamma)


```

## AIC

:::{.incremental}

- The Akaike Information Criterion (AIC)  balances the trade-off between model fit and complexity by penalizing models with more parameters.

- It aims to find the model that best explains the data while avoiding overfitting.

- AIC is calculated as follows: $\text{AIC} = 2k - 2\ln(\hat{L})$, 

- where: log-likelihood is the maximized value of the likelihood function for the fitted model. $k$ is the number of parameters in the model.

- In general a difference in AIC of <2 suggests equivalent goodness-of-fit

:::

## AIC

::::{.columns}

:::{.column}

**AIC can:**

- Compare non-nested models fitted to the same dataset and response variable

- Compare across different GLM families and link functions

:::

:::{.column}

**AIC cannot:**

- Compare models where the response variable is transformed

- Compare models where there are differences in the dataset

:::

::::

## Likelihood ratio test

The likelihood ratio test (LRT) “unifies” frequentist statistical tests. Brand-name tests like t-test, F-test, chi-squared-test, are specific cases (or even approximations) of the LRT.

- The likelihood ratio test (LRT) begins with a comparison of the likelihood scores of the two models:

$\text{LR} = -2(\ln L_1 - \ln L_2)$

:::{.fragment}

Where:

- $\ln L_1$ and $\ln L_2$ are the log-likelihoods of the two models being compared.

:::

## Likelihood ratio test

- This LRT statistic approximately follows a chi-square distribution. 

- To determine if the difference in likelihood scores among the two models is statistically significant, we next must consider the degrees of freedom. 

- In the LRT, degrees of freedom is equal to the number of additional parameters in the more complex model.

```{r}
#| echo: false
#| eval: true

fitted_model <- glm(hardness ~ dens, data = janka, family = Gamma(link = "sqrt"))
null_model <- glm(hardness ~ 1, data = janka, family = Gamma(link = "sqrt"))
fitted_likelihood <- logLik(glm(hardness ~ dens, data = janka, family = Gamma(link = "sqrt")))
null_likelihood <- logLik(glm(hardness ~ 1, data = janka, family = Gamma(link = "sqrt")))
```

```{r}
#| echo: true
#| eval: true


LR <- -2*(null_likelihood[1]-fitted_likelihood[1])

LR

```

## Likelihood ratio test

:::{.incremental}

- The likelihood ratio test `lrtest()` is typically calculated as twice the difference in deviance between the two models. (Can also be carried out with the `anova()` function)

- Scaling by -2 ensures the test statistic follows a chi-square distribution under certain conditions

- We can calculate the likelihood ratio test statistic, compare it to the chi-square distribution with the appropriate degrees of freedom, and determine whether the improvement in fit between the two models is statistically significant.

:::

```{r}

lrtest(null_model, fitted_model)

```

## F distribution

What if the variance is unknown e.g. Gaussian and Gamma distributions?

:::{.incremental}

- Then the null model estimates one parameter while the alternative model estimates two, so the difference in df is still 1. 

- In this case, we know this more familiarly as the ANOVA or F-test, which in this example is equivalent to the t-test on the intercept.

:::

```{r}
summary(fitted_model)

```

## F distribution

What if the variance is unknown e.g. Gaussian and Gamma distributions?


```{r}
#| echo: true
#| eval: true

anova(null_model, fitted_model, test = "F")

drop1(fitted_model, test = "F")

```



# GLMs for binary data {background-color="#D9DBDB"}

## GLMS for binary data 

Common response variable in ecological datasets is the binary variable: we observe a phenomenon X or its “absence”

:::{.incremental}

* Presence/Absence of a species

* Presence/Absence of a disease

* Success/Failure to observe behaviour

* Survival/Death of organisms

:::

Wish to determine if $P/A∼ Variable$

Called a logistic regression or logit model

## Binary variables

:::::{.columns}

::::{.column}

```{r}
#| eval: true
#| echo: false
#| fig-height: 8
#| message: false
#| warning: false

load(file = "../data_2/Mayflies.rda")

```



:::{.incremental}

- Investigating mayfly abundance in relation to pollution gradient measured in Cumulative Criterion Units (CCU)

- Mayflies serve as indicators of stream health due to sensitivity to metal pollution

- Higher CCU values indicate increased metal pollution, potentially impacting mayfly presence or absence in the stream

:::

::::

::::{.column}

![](images/Ephemera.png){fig-align="center" fig-alt="Ephemera vulgata" width=60%}

::::

:::::

## Example: Mayflies

Fitting a linear regression vs a logit-link regression:

```{r}
#| eval: true
#| echo: false
#| fig-height: 7
#| layout-ncol: 2
#| message: false
#| warning: false

ggplot(Mayflies, aes(x=CCU, y=Occupancy)) + geom_point()+
  geom_smooth(method = "lm")+
    labs(title = "Linear Regression",
       x = "CCU", y = "Occupancy") +
  theme_classic(base_size = 14)

ggplot(Mayflies, aes(x=CCU, y=Occupancy)) + geom_point()+
  geom_smooth(method = "glm", method.args = list(binomial(link = "logit"))) +
  labs(title = "Logit-link Binomial Regression",
       x = "CCU", y = "Occupancy") +
  theme_classic(base_size = 14)

```



## Bernoulli Distribution

::::{.columns}

:::{.column}

The Bernoulli distribution models the probability of success or failure in a single trial of a binary experiment:

* where success occurs with probability $p$ 

* and failure with probability ${1-p}$

:::

:::{.column}

```{r}
#| eval: true
#| echo: false
#| fig-height: 8
#| message: false
#| warning: false

# Define probabilities
p_success <- 0.7
p_failure <- 1 - p_success

# Create data frame
df <- data.frame(
  Outcome = c("Success", "Failure"),
  Probability = c(p_success, p_failure)
)

# Plot
ggplot(df, aes(x = Outcome, y = Probability, group = Outcome)) +
  geom_bar(stat = "identity") +
  labs(title = "Probability Distribution of a Bernoulli Random Variable",
       x = "Outcome",
       y = "Probability") +
  theme_minimal(base_size = 14)

```

:::

::::

## Probability distribution

:::: columns

::: {.column}
$logit(p) = \log \frac{p}{1 - p}$

$y_i = Bernoulli(p) = \frac{p}{1 - p}$
:::

::: {.column}
**Mean of distribution** Probability (p) of observing an outcome

**Variance of observed responses** As observed responses approach 0 or 1, the variance of the distribution decreases
:::

::::

## The link function

If $μ = xβ$ is only true for normally distributed data, 
then, if this is not the case, we must use a transformation on the expected values:

$$g(μ) = xβ$$

where $g(μ)$ is the link function.

This allows us to relax the normality assumption.

## The logit link

For binary data, the link function is called the logit:

$$ logit(p) = \log \frac{p}{1 - p} $$



The log of the odds $(p / (1 - p))$


## The logit link

$$ logit(p) = \log \frac{p}{1 - p} $$

:::{.incremental}

- The odds put our expected values on a 0 to +Inf scale.

- The log transformation puts our expected values on a -Inf to +Inf scale.

- Now, the expected values can be linearly related to the linear predictor.

:::

## Probability, odds, logit-odds

::::{.columns}

:::{.column width="60%"}

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false

# Generate a sequence of independent variable values
independent_variable <- seq(-10, 10, by = 0.5)

# Define a function to calculate probabilities
calculate_probability <- function(x) {
  probability <- 1 / (1 + exp(-x))
  return(probability)
}

# Define a function to calculate odds
calculate_odds <- function(probability) {
  odds <- probability / (1 - probability)
  return(odds)
}

# Define a function to calculate log odds
calculate_log_odds <- function(odds) {
  log_odds <- log(odds)
  return(log_odds)
}

# Calculate probabilities, odds, and log odds
probabilities <- sapply(independent_variable, calculate_probability)
odds <- sapply(probabilities, calculate_odds)
log_odds <- sapply(odds, calculate_log_odds)

# Plot the relationships
par(mfrow = c(1, 3), mar = c(5, 5, 2, 2))
plot(independent_variable, probabilities, type = "l", col = "blue", xlab = "Independent Variable", ylab = "Probability", main = "Change in Probability", ylim = c(0, 1))
plot(independent_variable, odds, type = "l", col = "red", xlab = "Independent Variable", ylab = "Odds", main = "Change in Odds")
plot(independent_variable, log_odds, type = "l", col = "green", xlab = "Independent Variable", ylab = "Log Odds", main = "Change in Log Odds")


```

:::

:::{.column width="40%"}

- The odds put our expected values on a 0 to +Inf scale.

- The log transformation puts our expected values on a -Inf to +Inf scale.

- Now, the expected values can be linearly related to the linear predictor.

:::

::::


## Example



```{r}
#| eval: true
#| echo: true
#| message: false
#| warning: false

mayfly_glm <- glm(Occupancy ~ CCU, family = binomial(link = "logit"), data = Mayflies)

summary(mayfly_glm)

```



## Interpret the model

:::{.incremental}

Each coefficient corresponds to a predictor variable, indicating the change in the **log odds** of the response variable associated with a one-unit change in that predictor, holding other predictors constant.

<br>

- Interpretation of coefficients involves exponentiating them to obtain odds ratios.

- An odds ratio greater than 1 implies higher odds of the event occurring with an increase in the predictor.

- An odds ratio less than 1 implies lower odds of the event occurring with an increase in the predictor.

:::

## Intepret the model

| Probability | Odds                              | Log Odds | Verbiage               |
|-------------|-----------------------------------|-----------------|------------------------|
| $p=.95$     | $\frac{95}{5} = \frac{19}{1} = 19$ |      2.94           | 19 to 1 odds for      |
| $p=.75$     | $\frac{75}{25} = \frac{3}{1} = 3$  |       1.09          | 3 to 1 odds for       |
| $p=.50$     | $\frac{50}{50} = \frac{1}{1} = 1$  |        0         | 1 to 1 odds           |
| $p=.25$     | $\frac{25}{75} = \frac{1}{3} = 0.33$ |    -1.11            | 3 to 1 odds against   |
| $p=.05$     | $\frac{95}{5}  = \frac{1}{19} = 0.0526$ |   -2.94          | 19 to 1 odds against  |

## Logit odds

When we use a binomial model, we produce the 'log-odds', this produces a fully unconstrained linear regression as anything less than 1, can now occupy an infinite negative value -∞ to ∞.


$$\log\left(\frac{p}{1-p}\right)	=	\beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}$$

:::{.fragment}

$$\frac{p}{1-p}	=	e^{\beta_{0}}e^{\beta_{1}x_{1}}e^{\beta_{2}x_{2}}$$

:::

:::{.fragment}

- We can interpret $\beta_{1}$ and $\beta_{2}$ as the increase in the log odds for every unit increase in $x_{1}$ and $x_{2}$. 

- We could alternatively interpret $\beta_{1}$ and $\beta_{2}$ using the notion that a one unit change in $x_{1}$ as a percent change of $e^{\beta_{1}}$ in the odds. 

:::

##

:::::{.columns}

::::{.column}

For the intercept: 

:::{.incremental}

- The estimate as log odds is 5.102.

- Therefore the odds are 164

- Over 99% probability of observing mayfly when CCU = 0

:::

::::

::::{.column}

```{r}
summary(mayfly_glm)
```

::::

:::::


##

:::::{.columns}

::::{.column}


For the predictor variable `CCU`:

:::{.incremental}

- The estimate is -3.051.

- This means that for every one unit increase in `CCU`, the log odds of the response variable **decreases by 3.051**, holding all other predictors constant.

:::

::::

::::{.column}

```{r}
summary(mayfly_glm)
```

::::

:::::

##

:::::{.columns}

::::{.column}

Now, let's interpret the coefficient for `CCU` using the odds ratio interpretation:

:::{.incremental}

- The odds ratio associated with `CCU` is calculated as $e^{\beta_{\text{CCU}}} = e^{-3.051}$.

- Therefore, $e^{\beta_{\text{CCU}}} \approx 0.048$.

- This means that for every one unit increase in `CCU`, the odds of the response variable decrease by a multiple of 0.048

:::

::::

::::{.column}

```{r}
#| eval: true
#| echo: true

broom::tidy(mayfly_glm, exponentiate = T)
```

::::

:::::




## Model fit

For a simple Bernoulli/Binary GLM there are only a few checks that apply:

```{r}
#| eval: true
#| echo: true
#| fig-height: 6
#| layout-ncol: 3
#| message: false

# Calculate and plot "deviance" residuals
dresid <- resid(mayfly_glm, type = "deviance")
hist(dresid)

# Plot leverage
plot(mayfly_glm, which = 5)

# Plot Cook's distance
plot(mayfly_glm, which = 4)

```

## Model fit

Residuals in binary glms will never be normally distributed - so a "residuals vs fitted plot" provides little insight. We can try "binned residuals": 

```{r}
#| eval: true
#| echo: false
#| fig-height: 6
#| message: false
#| layout-ncol: 2

plot(mayfly_glm, which = 1)

pred <- predict(mayfly_glm)

arm::binnedplot(pred, dresid)

```


## DHARMa fit

- [DHARMa](https://theoreticalecology.wordpress.com/2016/08/28/dharma-an-r-package-for-residual-diagnostics-of-glmms/) works by **simulating residuals** from the fitted model, comparing them with observed residuals, and providing diagnostic plots to assess model adequacy and identify potential issues like heteroscedasticity or influential data points.

:::{.fragment}

```{r}
#| echo: true
#| eval: true
library(DHARMa)
plot(simulateResiduals(mayfly_glm))

```

:::

## Prediction


- `predict()` function for GLMs computes predicted values based on the fitted model.

- For existing data, it predicts values for each observation in the original dataset.

- For new data, it predicts values for a specified new dataset, allowing for predictions on unseen data.


```{r}
#| eval: false
#| echo: true
#| message: false

# Predictions for existing data
predict(mayfly_glm, type = "response")

```


```{r}
#| eval: false
#| echo: true
#| message: false

# Predictions for new data
new_CCU<- data.frame(CCU = c(0,1,2,3,4,5))
predict(mayfly_glm, newdata = new_CCU, type = "response")

```

## Emmeans

The `emmeans` package in R computes estimated marginal means (EMMs) it can also provides post-hoc comparisons and contrasts for fitted models.


- This specific function call below computes EMMs for the predictor variable CCU at specific values (0 to 5) and provides them on the response scale.

```{r}

emmeans::emmeans(mayfly_glm, 
                 specs = ~ CCU, 
                 at=list(CCU=c(0:5)), 
                 type='response') |> 
  as_tibble()|> 
  gt::gt() |> 
  gt::fmt_number(columns = everything(), n_sigfig = 2)


```

## Prediction plots with emmeans

We can use `emmeans` package to compute estimated marginal means (EMMs) from a fitted GLM, convert them into a tibble format for visualization with ggplot2, overlay the means with uncertainty ribbons and add them on a scatter plot of the original data.

::::{.columns}

:::{.column width="60%"}

```{r}
#| eval: true
#| echo: false
#| fig-height: 7
#| message: false
means <- emmeans::emmeans(mayfly_glm, 
                 specs = ~ CCU, 
                 at=list(CCU=c(0:5)), 
                 type='response') |> 
  as_tibble()

ggplot(Mayflies, aes(x=CCU, y=Occupancy)) + geom_point()+
    geom_ribbon(data = means,
              aes(x = CCU,
                  y = prob,
                  ymin = asymp.LCL,
                  ymax = asymp.UCL),
              alpha = .2)+
  geom_line(data = means,
            aes(x = CCU,
                y = prob)) +  # regression line
  labs(title = "Logit-link Binomial Regression",
       x = "CCU", y = "Occupancy")+
  theme_classic(base_size = 14)

```

:::

:::{.column width="40%"}


```{r}
#| eval: false
#| echo: true
#| fig-height: 7
#| message: false
means <- emmeans::emmeans(mayfly_glm, 
                 specs = ~ CCU, 
                 at=list(CCU=c(0:5)), 
                 type='response') |> 
  as_tibble()

ggplot(Mayflies, aes(x=CCU, y=Occupancy)) + geom_point()+
    geom_ribbon(data = means,
              aes(x = CCU,
                  y = prob,
                  ymin = asymp.LCL,
                  ymax = asymp.UCL),
              alpha = .2)+
  geom_line(data = means,
            aes(x = CCU,
                y = prob)) +  # regression line
  labs(title = "Logit-link Binomial Regression",
       x = "CCU", y = "Occupancy")+
  theme_classic(base_size = 14)

```

:::

::::


# GLMs for Binomial data {background-color="#D9DBDB"}

## Proportion data and GLM

Sometimes, count data aligns more closely with logistic regression methodologies than it initially appears.

We're not looking at typical count data when measuring the number of occurrences with a known total sample size.

Imagine, for example, we're studying the prevalence of a native underbrush species across various forest plots. We assess 15 different plots, each meticulously surveyed for the presence of this underbrush, counting the number of square meters where the underbrush is present versus absent within a standard area:

$$\frac{M^2~\text{with native underbrush (successes)}}{\text{Total surveyed area in}~M^2~(\text{trials})}$$

Bound between zero and one


## Binomial distribution

:::: columns

::: {.column}

```{r}
#| eval: true
#| echo: false
#| fig-height: 8
#| message: false

# Define a range of trials
trial_sizes <- c(5, 10, 20, 50, 100)

# Define the probability of success
p_success <- 0.7

# Generate the binomial distribution data
binom_data <- map_df(trial_sizes, ~tibble(
  trials = .x,
  success = 0:.x,
  probability = dbinom(0:.x, .x, p_success)
)) %>%
  mutate(trials = factor(trials, levels = trial_sizes)) # This ensures the plots are ordered correctly

# Plot
ggplot(binom_data, aes(x = success, y = probability, color = trials)) +
  geom_line() + # Use geom_point() if you prefer dots
  scale_color_brewer(palette = "Dark2") +
  labs(title = "Change in Binomial Distribution with Number of Trials",
       x = "Number of Successes",
       y = "Probability",
       color = "Number of Trials") +
  theme_minimal()

```

::: 


:::{.column}


$logit(p) = \log \frac{p}{1 - p}$

$y_i = Binomial(n,p)$

* It is the collection of Bernoulli trials for the same event

* It is represented by the number of Bernoulli trials $n$

* It is also the probability of an event in each trial $p$

:::

::::

## Binomial: Example

:::: columns

::: {.column}

![](images/Tribolium castaneum.jpg){fig-align="center" fig-alt="Tribolium" width=50%}
:::

:::{.column}

This small dataset is from an experiment looking at mortality in batches of flour exposed to different doses of pesticides.

The question of interest is: 

> How does pesticide dose affect mortality in the flour beetle *Tribolium castaneum*

:::

::::

## The data

```{r}
#|echo: true
#|message: false

beetles <- read_csv("../data_2/beetles.csv")
beetles
```

## Preparing the data

As well as the numbers killed, we need the numbers that remain alive

```{r}
#| echo: true
#| eval: true

beetles <- beetles |> 
  rename("dead" = Number_killed,
         "trials" = Number_tested) |> 
  mutate("alive" = trials-dead)

beetles

```


## Binomial VS Bernoulli Keypoints!

Bernoulli deals with the outcome of the single trial of the event, whereas Binomial deals with the outcome of the multiple trials of the single event.

<br>

Bernoulli is used when the outcome of an event is required for only one time, 

<br>

whereas the Binomial is used when the outcome of an event is required multiple times.

## Binomial glm

The GLM of the binomial counts will analyse the number of *each* batch of beetles killed, while taking into account the size of each group

```{r}
#| echo: true
#| eval: true

#cbind() creates a matrix of successes and failures for each batch

beetle_glm <- glm(cbind(dead, alive) ~ Dose, family = binomial(link = "logit"), data = beetles)

summary(beetle_glm)

```

## Weights

An alternative method is to analyse the proportion of beetles killed and including the number of trials with the `weight` argument

```{r}
#| echo: true
#| eval: true


beetle_glm_weights <- glm(Mortality_rate ~ Dose, weights = trials, family = binomial(link = "logit"), data = beetles)

summary(beetle_glm_weights)

```


## Checking Binomial model fit

- For a Binomial model standard residual checks do not apply

::::{.columns}

:::{.column}

```{r}
#| echo: true
#| eval: false

# Calculate and plot "deviance" residuals

par(mfrow = c(2, 2), mar = c(4, 4, 2, 1))

pred <- predict(beetle_glm_weights) 
dresid <- resid(beetle_glm_weights, type = "deviance")

# Check for overdispersion
hist(dresid)

# Binned residuals
arm::binnedplot(dresid, pred)

# Plot leverage
plot(beetle_glm_weights, which = 5)

plot(beetle_glm_weights, which = 2)


```

:::

:::{.column}

```{r}
#| echo: false
#| eval: true

# Calculate and plot "deviance" residuals

par(mfrow = c(2, 2), mar = c(4, 4, 2, 1))

pred <- predict(beetle_glm_weights) 
dresid <- resid(beetle_glm_weights, type = "deviance")

# Check for overdispersion
hist(dresid)

# Binned residuals
arm::binnedplot(dresid, pred)

# Plot leverage
plot(beetle_glm_weights, which = 5)

plot(beetle_glm_weights, which = 2)


```

:::

::::


## Performance residual checks

::::{.columns}

:::{.column}

```{r}
#| echo: true
#| eval: true

performance::check_model(beetle_glm_weights)

```

:::

:::{.column}

```{r}
#| echo: true
#| eval: true

performance::binned_residuals(beetle_glm_weights)

```

:::

::::

## Checking with DHARMa


- [DHARMa](https://theoreticalecology.wordpress.com/2016/08/28/dharma-an-r-package-for-residual-diagnostics-of-glmms/) works by **simulating residuals** from the fitted model, comparing them with observed residuals, and providing diagnostic plots to assess model adequacy and identify potential issues like heteroscedasticity or influential data points.

:::{.fragment}

```{r}
#| echo: true
#| eval: true
#| message: false
#| warning: false

library(DHARMa)
plot(simulateResiduals(beetle_glm_weights))
```

:::

## Estimates of significance

Confidence intervals

```{r}
#| echo: true
#| eval: true
#| message: false

library(broom)
tidy(beetle_glm, conf.int = T)

```

```{r}
#| echo: true
#| eval: true
#| message: false

drop1(beetle_glm, test = "Chi")

```

## Table

This function has automatically applied the exponentiate to produce the odds and odds ratio:

```{r}
#| echo: true
#| eval: true
#| message: false

library(sjPlot)

tab_model(beetle_glm)

```

## Predictions


```{r}
#| echo: true
#| eval: true
#| message: false
emmeans::emmeans(beetle_glm, 
                 specs = ~ Dose, 
                 at=list(Dose=c(40, 50, 60, 70, 80)), 
                 type='response') 
```

## Predictions plot

```{r}
#| eval: true
#| echo: false
#| fig-height: 7
#| message: false

means <- emmeans::emmeans(beetle_glm, 
                 specs = ~ Dose, 
                 at=list(Dose=c(40:80)), 
                 type='response')  |> 
  as_tibble()

ggplot(beetles, aes(x=Dose, y=Mortality_rate)) + geom_point()+
    geom_ribbon(data = means,
              aes(x = Dose,
                  y = prob,
                  ymin = asymp.LCL,
                  ymax = asymp.UCL),
              alpha = .2)+
  geom_line(data = means,
            aes(x = Dose,
                y = prob)) +  # regression line
  labs(title = "Logit-link Binomial Regression",
       x = "Dose", y = "Mortality")+
  theme_classic(base_size = 14)

```



## Overdispersion

If the **residual deviance of the model is > the residual degrees of freedom** - we consider our binomial models to have **overdispersion**. 

This means the variance is greater than predicted by the binomial distribution

Overdispersion > 1.5 can be accounted for with the *quasi-binomial* glm

```{r}
summary(beetle_glm_weights)
```

## Overdispersion

:::: columns

::: {.column}

**Binomial**
$P(X = s) = C(n, s) \cdot p^s \cdot (1 - p)^{n - s}$

:::

:::{.column}

**Quasibinomial**
$P(X = s) = C(n, s) \cdot p(p+k\theta)^{s-1} \cdot (1 - pk\theta)^{n - s}$

:::

::::

Where:

- $n$ is the total number of trials of an event.
- $s$ corresponds to the number of times an event should occur.
- $p$ is the probability that the event will occur.
- $(1 - p)$ is the probability that the event will not occur.
- $C$ term represents combinations, calculated as $C(n, s) = \frac{n!}{s!(n - s)!}$, representing the number of ways to choose $s$ successes out of $n$ trials.

- $\theta$ term describes additional variance outside of the Binomial distribution

## Fitting the quasibinomial model

```{r}
#|echo: true
#|message: false

summary(beetle_glm)

```

```{r}
#|echo: true
#|message: false

beetle_quasiglm <- glm(cbind(dead, alive) ~ Dose, family = quasibinomial(link = "logit"), data = beetles)

summary(beetle_quasiglm)

```


## Fitting the quasibinomial model

::::{.columns}

:::{.column}

Standard Error, Confidence intervals and p-values WILL change.

Estimates remain the same


```{r}
#| eval: true
#| echo: false
#| fig-height: 6
#| message: false

means <- emmeans::emmeans(beetle_quasiglm, 
                 specs = ~ Dose, 
                 at=list(Dose=c(40:80)), 
                 type='response')  |> 
  as_tibble()

ggplot(beetles, aes(x=Dose, y=Mortality_rate)) + geom_point()+
    geom_ribbon(data = means,
              aes(x = Dose,
                  y = prob,
                  ymin = asymp.LCL,
                  ymax = asymp.UCL),
              alpha = .2)+
  geom_line(data = means,
            aes(x = Dose,
                y = prob)) +  # regression line
  labs(title = "Logit-link Binomial Regression",
       x = "Dose", y = "Mortality")+
  theme_classic(base_size = 14)

```

:::

:::{.column}

Likelihood ratio tests should now be applied with an F-statistics


```{r}
#| eval: true
#| echo: true
#| message: false

drop1(beetle_quasiglm, test = "F")

```

:::

::::

## Challenge: Binomial model


:::: columns


::: {.column width="60%"}

On the afternoon of January 28th, 1986 the space shuttle Challenger experienced a critical failure and broke apart in mid air, resulting in the deaths of all seven crewmembers.

An investigation discovered critical failures in all six of the O-rings in the solid rocket booster.

> How did temperature affect the probability of o-ring failure?

> What was the probability of all o-rings failing when the temperature was 36 degrees F

:::

::: {.column width="40%"}

```{r}
#| label: ex-challenger-timer
countdown::countdown(
  minutes = 40,
  color_border = "#00AEEF",
  color_text = "#00AEEF",
  color_running_text = "white",
  color_running_background = "#00AEEF",
  color_finished_text = "#00AEEF",
  color_finished_background = "white",
  top = 0,
  margin = "1.2em",
  font_size = "2em"
)
```

<br><br>

![](images/space-shuttle.jpg){fig-align="center" fig-alt="Challenger" width=60%}

:::

::::


# GLMs for count data {background-color="#D9DBDB"}

## Poisson

:::: columns

::: {.column}

```{r}
#| eval: true
#| echo: false
#| fig-height: 8
#| message: false

# Define a range of lambda values (average rate of success)
lambda_values <- c(1, 4, 10, 20, 50)

# Generate the Poisson distribution data
poisson_data <- map_df(lambda_values, ~tibble(
  lambda = .x,
  events = 0:75, # Assuming a reasonable range for visualization
  probability = dpois(0:75, .x)
)) |> 
  mutate(lambda = factor(lambda, levels = lambda_values)) # For ordered plotting

# Plot
ggplot(poisson_data, aes(x = events, y = probability, color = lambda)) +
  geom_line(linewidth = 1.5) +
  scale_color_brewer(palette = "Dark2") +
  labs(title = "Change in Poisson Distribution with Different Lambda",
       x = "Number of Events",
       y = "Probability",
       color = "Lambda") +
  theme_minimal(base_size = 14)

```

::: 

::: {.column}

Count or rate data are ubiquitous in the life sciences (e.g number of parasites per microlitre of blood, number of species counted in a particular area). These type of data are **discrete** and **non-negative**.

A useful distribution to model abundance data is the **Poisson** distribution: 

a discrete distribution with a single parameter, λ (lambda), which defines both the mean and the variance of the distribution.

:::


::::

## GLM

::: {.incremental}

Recall the simple linear regression case (i.e a GLM with a Gaussian error structure and identity link). For the sake of clarity let's consider a single explanatory variable where $\mu$ is the mean for *Y*:

$\mu_i = \beta0 + \beta_1x1 + \beta_2x2 + ... +\beta_nxn$

$y_i \sim \mathcal{N}(\mu_i, \sigma^2)$

* The mean function is **unconstrained**, i.e the value of $\beta_0 + \beta_1X$ can range from $-\infty$ to $+\infty$. 

:::

## Poisson


* If we want to model count data we therefore want to **constrain** this mean to be positive only. 

:::{.incremental}

* Mathematically we can do this by taking the **logarithm** of the mean (the log is the default link for the Poisson distribution). 

* We then assume our count data variance to be Poisson distributed (a discrete, non-negative distribution), to obtain our Poisson regression model (to be consistent with the statistics literature we will rename $\mu$ to $\lambda$):

:::

## GLM Poisson

![](images/poisson_regression.webp){fig-align="center" fig-alt="Poisson equation" width=80%}

## Poisson limitations

The **Poisson** distribution has the following characteristics:

::: {.incremental}

* **Discrete** variable (integer), defined on the range $0, 1, \dots, \infty$.

* A single ***rate*** parameter $\lambda$, where $\lambda > 0$.

* **Mean** = $\lambda$  

* **Variance** = $\lambda$

:::


## Poisson: Case study

:::: columns

::: {.column}

![](images/3 Spined Stickleback.jpg){fig-align="center" fig-alt="Stickleback" width=50%}
:::

:::{.column}

In this study the authors investigated the effect of the parasitic tapeworm *Schistocephalus solidus* infection on the susceptibility of infection from a second parasite, the trematode *Diplostomum pseudospathaceum*

> How does Treatment/Infection status affect trematode counts?

:::

::::

##

This model looks ok

```{r}
#| eval: false
#| echo: true
#| fig-height: 8
#| message: false

stick_lm <- lm(Diplo_intensity ~ Treatment, data = parasite)
```


```{r}
#| include: FALSE

parasite <- read_csv("../data_2/parasite_exp.csv")

```

```{r}
#| eval: true
#| echo: false
#| fig-height: 7
#| message: false

stick_lm <- lm(Diplo_intensity ~ Treatment, data = parasite)

emmeans::emmeans(stick_lm, specs = ~Treatment) %>% 
  as_tibble() %>% 
ggplot(aes(x=Treatment, y=emmean)) + 
  geom_pointrange(aes(ymin = lower.CL, ymax = upper.CL)) +
  geom_jitter(data = parasite, aes( x= Treatment, y = Diplo_intensity),
              alpha = .2, width = .2)+
  theme_minimal(base_size = 18)



```


## Diagnostics

Let us display the model diagnostics plots for this linear model.

```{r}
#| echo: false
#| layout-ncol: 2
#| fig-height: 8

plot(stick_lm, which=2)

plot(stick_lm, which=3)
```


* Curvature

* Funnelling effect



## Poisson model

We should therefore try a different model structure.

The response variable in this case is a classic **count data**: **discrete** and bounded below by zero (i.e we cannot have negative counts). We will therefore try a **Poisson model** using the canonical **log** link function for the mean:


* λ varies with x (mass) which means residual variance will also vary with 
x, which means that we just relaxed the homogeneity of variance assumption!

* Predicted values will now be integers instead of fractions

* The model will never predict negative values (Poisson is strictly positive)

$$
    \log{\lambda} = \beta_0 + \beta_1 T_i + \beta_1 T_j + \beta_1 T_k 
$$


## Fit the Poisson model

Fit the poisson model

```{r}
#| echo: true

stick_poisson <- glm(Diplo_intensity ~ Treatment, family = "poisson", data = parasite)

summary(stick_poisson)
```


## Poisson model fit 

::::{.columns}

:::{.column}

Linear Model

```{r}
#| echo: false
#| fig-height: 6

par(mfrow = c(1, 2), mar = c(4, 4, 2, 1))

plot(stick_lm, which=2)

plot(stick_lm, which=3)


```

:::

:::{.column}

Poisson Model

```{r}
#| echo: false
#| fig-height: 6

par(mfrow = c(1, 2), mar = c(4, 4, 2, 1))

plot(stick_poisson, which=2)

plot(stick_poisson, which=3)


```

:::

::::

## Effect of treatment

To perform a global test on the effect of treatment.

The likelihood ratio test allows us to determine the overall deviance explained by treatment

```{r}
#| eval: true
#| echo: true

# For a fixed  mean-variance model we use a Chisquare distribution
drop1(stick_poisson, test = "Chisq")

```


## Model summary

::::{.columns}

:::{.column}

```{r}
#| echo: true

summary(stick_poisson)

```

:::

:::{.column}

```{r}
#| eval: true
#| echo: false
#| fig-height: 5

emmeans::emmeans(stick_poisson, specs = ~Treatment,
                 type = "response") %>% 
  as_tibble() %>% 
ggplot(aes(x=Treatment, y=rate)) + 
  geom_pointrange(aes(ymin = asymp.LCL, ymax = asymp.UCL)) +
  geom_jitter(data = parasite, aes( x= Treatment, y = Diplo_intensity),
              alpha = .2, width = .2)+
  theme_minimal(base_size = 18)
```

:::

::::


## Poisson limitations

So for the Poisson regression case we assume that the mean and variance are the same.
Hence, as the mean *increases*, the variance *increases* also (**heteroscedascity**).
This may or may not be a sensible assumption so watch out! Just because a Poisson distribution *usually* fits well for count data, doesn't mean that a Gaussian distribution *can't* always work.

Recall the link function between the predictors and the mean and the rules of logarithms (if $\log{\lambda} = k$(value of predictors), then $\lambda = e^k$):


## Overdispersion

When the residual deviance is higher than the residual degrees of freedom, we say that the model is overdispersed. This situation is mathematically represented as:

$$
\phi = \frac{\text{Residual deviance}}{\text{Residual degrees of freedom}}
$$

Overdispersion occurs when the variance in the data is even higher than the mean, indicating that the Poisson distribution might not be the best choice. This can be due to many reasons, such as the presence of many zeros, many very high values, or missing covariates in the model.

## Overdispersion and what to do about it

| Causes of over-dispersion | What to do about it | 
|---------|:-----|
| Model mis-specification (missing covariates or interactions)    | Add more covariates or interaction terms   |
| Too many zeros ("zero inflation")    | Use a zero-inflated model  |
| Non-independence of observations       | Use a generalised mixed model with random effects to take non-independence into account    |
| Variance is larger than the mean      | Use a quasipoisson GLM if overdispersion = 2-15. Use a negative binomial GLM if > 15-20  |

: Overdispersion statistic values > 1


## Choosing a model

![](images/dispParam.png){fig-align="center" fig-alt="Poisson/NegBin" width=50%}


## Overdispersion and what to do about it

It may be true that you are initially unsure whether overdispersion is coming from zero-inflation, larger variance than the mean or both. 

You can fit models with the same dependent and independent variables and different error structures and use AIC to help determine the best model for your data

## Overdispersion in the cuckoo model


$\phi = \frac{\text{Residual deviance}}{\text{Residual degrees of freedom}}$ = $\frac{697.25}{217} = 3.21$

```{r}
#| eval: true
#| echo: true

summary(stick_poisson)

performance::check_overdispersion(stick_poisson)

```

## Quasi-Poisson GLM 

The systematic part and the link function remain the same

$$
    \log{\lambda} = \beta_0 + \beta_1 x_i
$$

*phi*$\phi$ is a dispersion parameter, it will not affect estimates but will affect *significance*. Standard errors are multiplied by $\sqrt\phi$ 

$$
Y_i = Poisson(\phi \lambda_i)
$$


Where:

- $Yi$ is the response variable.
- $\phi$ is the dispersion parameter, which adjusts the variance of the distribution

Confidence intervals and p-values WILL change.


## Fit a quasipoisson model to the data

```{r}
#| eval: true
#| echo: true

stick_quasipoisson <- glm(Diplo_intensity ~ Treatment, family = quasipoisson, data = parasite)
```

* Look at the residual plots - how have they changed? 

* Look at the SE and p-values - how have they changed

* Calculate new 95% confidence intervals

## Compare models

```{r}
#| eval: true
#| echo: true
#| layout-ncol: 2

summary(stick_poisson)

summary(stick_quasipoisson)

```

## F distributions

The presence of overdispersion suggested the use of the F-test for nested models. We will test if the interaction term can be dropped from the model.

Though here for a term with only one degree of freedom $t^2$ = the F distribution with denominator degree of freedom

```{r}
#| eval: true
#| echo: true

drop1(stick_quasipoisson, test = "F")

```



# Negative Binomial {background-color="#D9DBDB"}

## Negative Binomial

```{r}
#| eval: true
#| echo: false
#| fig-height: 8
#| fig-width: 10
#| message: false

##Negative Binomial Distribution (Varying Shape Parameter r)
#In the negative binomial distribution:
  
#  Shape Parameter (r): Represents the number of successes required before the experiment is stopped.
#Probability of Success (p): Represents the probability of success in each Bernoulli trial.
#As r increases:
  
#  The distribution becomes more skewed to the right.
#The average number of failures before success increases.
#The variance of the distribution also increases, indicating greater variability.

# Function to generate negative binomial distribution data

generate_nbinom_data <- function(r, p) {
  tibble(failures = 0:(10*r), 
         probability = dnbinom(0:(10*r), size = r, prob = p))
}

# Define range of shape parameter values (r)
r_values <- rep(c(2, 5, 10), times = 3)  # Number of successes

# Fixed probability of success
p_fixed <- rep(c(0.2, 0.4, 0.6), each = 3)  

# Generate negative binomial distribution data for different r values
nbinom_data <- map2_df(r_values, p_fixed, ~generate_nbinom_data(r = .x, p = .y) 
                      %>% mutate(r = as.factor(.x)) %>% mutate(p = as.factor(.y))) 

# Plot for negative binomial distribution
ggplot(nbinom_data, aes(x = failures, y = probability, color = r, group = interaction(r,p))) +
  geom_line() +
  scale_color_brewer(palette = "Dark2")+
  labs(title = "Negative Binomial Distribution with Varying Shape Parameter (r)",
       x = "Number of Failures",
       y = "Probability",
       color = "Number of Successes (r)") +
  theme_minimal(base_size = 14)+
  facet_wrap(~p)+
  gghighlight::gghighlight()

```

## Negative Binomial

Negative binomial GLMs are favored when overdispersion is high.

It has two parameters, $μ$ and $\theta$. $\theta$ controls for the dispersion parameter (smaller $\theta$ indicates higher dispersion). It corresponds to a combination of two distributions (Poisson and gamma).

It assumes that the $Y_i$ are Poisson distributed with the mean $μ_i$ assumed to follow a gamma distribution:

$$
E(Y_i) = μ_i \\
\text{Var}(Y_i) = μ_i + μ_i^2/k
$$


## Fitting a negative binomial in R

Negative binomial is not in the `glm()` function. We need the `MASS` package:

Suitable for strongly over-dispersed zero-bounded integer data.

```{r}
#| eval: false
#| echo: true
#| message: false

library(MASS)

model <- glm.nb(y ~ x1 + x2, link = "log", data = dataframe)

```


## Check zero-inflation

The model is underfitting zeros (but not by much). 

```{r}
#| echo: true
#| fig-height: 7
#| warning: false

check_zeroinflation(stick_quasipoisson)

100*sum(parasite$Diplo_intensity == 0)/nrow(parasite)
# Only 2% of our data has zeros

```

## Compare models

```{r}
#| echo: true
#| fig-height: 7
#| warning: false
# Neg bin
stick_nb <- glm.nb(Diplo_intensity ~ Treatment, link = "log", data = parasite)

```


## Compare models

```{r}
#| echo: true
#| fig-height: 7
#| warning: false


AIC(stick_poisson)
AIC(stick_quasipoisson)
AIC(stick_nb)


```

## Validating Negative Binomial models

```{r}
#| echo: true
#| fig-height: 7
#| layout-ncol: 2
#| warning: false

performance::check_model(stick_nb)

performance::check_zeroinflation(stick_nb)

```

## Validating a model by simulation

```{r}
#| echo: true
#| fig-height: 7
#| layout-ncol: 2
#| warning: false
plot(DHARMa::simulateResiduals(stick_nb))
```


## Comparison of model predictions

- Luckily in this instance we can be assured that each of these models makes very similar predictions:

```{r}

colors <- c("Quasi" = "darkgreen", "NegBin" = "darkorange", "Poisson" = "purple")


means_poisson <- emmeans::emmeans(stick_poisson, 
                 specs = ~ Treatment, 
                 type='response') |> 
  as_tibble()

means_quasi <- emmeans::emmeans(stick_quasipoisson, 
                 specs = ~ Treatment, 
                 type='response') |> 
  as_tibble()

means_nb <- emmeans::emmeans(stick_nb, 
                 specs = ~ Treatment, 
                 type='response') |> 
  as_tibble()


ggplot(parasite, aes(x=Treatment, y=Diplo_intensity)) + 
  geom_jitter(width = .2,
              alpha = .2)+
 geom_pointrange(data = means_quasi,
                 aes(x = Treatment,
                     y = rate,
                     ymin = asymp.LCL, ymax = asymp.UCL,
                     colour = "Quasi"))+
geom_pointrange(data = means_nb,
                 aes(x = Treatment,
                     y = response,
                     ymin = asymp.LCL, ymax = asymp.UCL,
                     color = "NegBin"),
                position = position_nudge(x= .2))+
geom_pointrange(data = means_poisson,
                 aes(x = Treatment,
                     y = rate,
                     ymin = asymp.LCL, ymax = asymp.UCL,
                     color = "Poisson"),
                position = position_nudge(x= -.2))+  
  theme_classic(base_size = 18)+
  scale_color_manual(values = colors)+
  scale_y_continuous(limits = c(0,15))

```


# Linear Mixed Models {background-color="#D9DBDB"}

## Why mixed model?

The key feature of a linear mixed-effects model is the inclusion of random effects - variables where our observations are grouped into subcategories that systematically affect our outcome - to account for important structure in our data. 

Mixed-effects model can be used in many situations instead of one of our more straightforward tests when this structure may be important:

i) mixed-effects models incorporate group and even individual-level differences

ii) mixed-effects models cope well with missing data, unequal group sizes and repeated measurements

## Structure {.smaller}

:::{.incremental}

- Biological datasets are often highly structured, containing clusters of non-independent observational units that are hierarchical in nature, and LMMs allow us to explicitly model the non-independence in such data. 

- Example: 

> We measure several chicks from the same clutch, and several clutches from different females, or we might take repeated measurements of the same chick’s growth rate over time. 

- In both cases, we might expect that measurements within a statistical unit (here, an individual, or a female’s clutch) might be more similar than measurements from different units. 

- Explicit modelling of the random effects structure will aid correct inference about fixed effects, depending on which level of the system’s hierarchy is being manipulated. 

:::

## Error rates

:::{.incremental}

- If the fixed effect varies or is manipulated at the level of the clutch, then treating multiple chicks from a single clutch as independent would represent pseudoreplication

- If fixed effects vary at the level of the chick, then non-independence among clutches or mothers could also be accounted for. 

- Random effects represent grouping and allow the estimation of variance in the response variable within and among these groups. 

- This reduces the probability of false positives and false negatives

:::

## Examples of structured data

*Hierarchy*

- Estimating scores on a standardised maths test - students from the same maths class should be grouped

```
lmer(test_score ~ study_time + (1|class))
```

*Repeated measures*

- Medical interventions on blood sugar levels - each person is measured multiple times over a year

```
lmer(blood_sugar ~ treatment + time + (1|individual))
```

## Fixed and Random Effects

::::{.columns}

:::{.column}

### Fixed Effect

Fixed effects are variables that we expect will affect the dependent/response variable: they’re what you call explanatory variables in a standard linear regression.

${y_i = \beta0 + \beta1x+\epsilon_i}$


```
y ~ x, data = data)
```

:::

:::{.column}

### Random Effect

A random effect is a parameter that is allowed to vary across groups or individuals. Random effects do not take a single fixed value, rather they follow a distribution (usually the normal distribution) and allow a model to account for variation around an intercept or slope.

${y_{ij} = \beta0_{j} + \beta1x+\epsilon_i}$


```
y ~ x + (1|group), data = data)
```

:::

::::

## A regression on simulated data

```{r, include = F}

library(lmerTest)
library(tidyverse)
library(sjPlot)

theme_set(theme_classic(base_size = 18))

```


```{r, echo = F}
# Generating a fake dataset with different means for each group
set.seed(123)  # Setting seed for reproducibility


rand_eff <- data.frame(group = as.factor(seq(1:5)),
            b0 = rnorm(5, mean = 0, sd = 20),
            b1 = rnorm(5, 0, 0.5))

data <- expand.grid(group = as.factor(seq(1:10)), 
                    obs = as.factor(seq(1:100))) %>%
  left_join(rand_eff,
            by = "group") %>%
  mutate(x = runif(n = nrow(.), 0, 10),
         B0 = 20,
         B1 = 2,
         E = rnorm(n = nrow(.), 0, 10)) %>%
  mutate(y = B0 + b0 + x * (B1 + b1) + E)

data <- expand.grid(group = as.factor(seq(1:4)), 
                    obs = as.factor(seq(1:100)))

data.1 <- expand.grid(group = as.factor(5),
          obs = as.factor(seq(1:30)))

data <- bind_rows(data, data.1) %>% 
  left_join(rand_eff,
            by = "group") %>%
  mutate(x = runif(n = nrow(.), 0, 10),
         B0 = 20,
         B1 = 2,
         E = rnorm(n = nrow(.), 0, 10)) %>%
  mutate(y = B0 + b0 + x * (B1 + b1) + E)

```


```{r, echo = F, fig.width = 12}

ggplot(data, aes(x = x, 
                 y = y)) +
  geom_point() +
  labs(x = "Independent Variable", 
       y = "Dependent Variable")+
  geom_smooth(method = "lm")

```

- In this example variable x has been modelled against variable y, but the data actually comes from five separate groups

## Mean between groups

::::{.columns}

:::{.column}

```{r, echo = F, fig.width = 8}

ggplot(data, aes(x = group, 
                 y = y)) +
  geom_boxplot() +
  labs(x = "Groups", 
       y = "Dependent Variable")

```

:::

:::{.column}

```{r, echo = F, fig.width = 8}

# Color tagged by group
plot_group <- ggplot(data, aes(x = x, 
                               y = y)) +
  geom_point(alpha = 0.6, size = 2,
             aes(color = group,
                               group = group)) +
  labs(title = "Data Coloured by Group", 
       x = "Independent Variable", 
       y = "Dependent Variable")+
    geom_smooth(method = "lm")+
  theme(legend.position="none")

plot_group

```

:::

::::

The mean value is slightly different between each group

## Stratified analysis

One way to analyse this data would be to conduct independent regressions for each group: 

```{r, echo = F, fig.width = 12}

# Plotting the relationship between x and y with group-level smoothing
ggplot(data, aes(x = x, y = y, color = group, group = group)) +
  geom_point(alpha = 0.6) +  # Scatter plot of x and y with transparency
  labs(title = "Data Colored by Group", x = "Independent Variable", y = "Dependent Variable") +
  theme(legend.position = "none") +
  geom_smooth(method = "lm") +  # Group-level linear regression smoothing
  facet_wrap(~group)  # Faceting the plot by group

```

Each analysis will be restricted by its sample size, and the reduction in power will inflate sampling bias - leading to inconclusive results


## Partial pooling

- Complete pooling models all the information together and ignores structure

- Mixed models employ partial pooling:

- Fixed effects calculated on pooled data

- For each group the random effect estimates the intercept

```{r, echo = F, fig.width = 10}

plot_function2 <- function(model, title = "Data Coloured by Group"){
  
data <- data %>% 
  mutate(fit.m = predict(model, re.form = NA),
         fit.c = predict(model, re.form = NULL))

data %>%
  ggplot(aes(x = x, y = y, col = group)) +
  geom_point(pch = 16, alpha = 0.6) +
  geom_line(aes(y = fit.c, col = group), size = 2)  +
  coord_cartesian(ylim = c(-40, 100))+
  labs(title = title, 
       x = "Independent Variable", 
       y = "Dependent Variable") 
}

mixed_model <- lmer(y ~ x + (1|group), data = data)

plot_function2(mixed_model, "Random intercept")

```



## Shrinkage


```{r, echo = F, fig.width = 12}
# Nesting the data by group
nested_data <- data %>% 
    group_by(group) %>% 
    nest()

# Fitting linear regression models and obtaining predictions for each group
nested_models <- map(nested_data$data, ~ lm(y ~ x, data = .)) %>% 
    map(predict)

# Creating a new dataframe and adding predictions from different models
data1 <- data %>% 
  mutate(fit.m = predict(mixed_model, re.form = NA),
         fit.c = predict(mixed_model, re.form = NULL)) %>% 
  arrange(group,obs) %>% 
  mutate(fit.l = unlist(nested_models)) 

# Creating a plot to visualize the predictions
data1 %>% 
  ggplot(aes(x = x, y = y, colour = group)) +
    geom_point(pch = 16, size = 2, alpha = 0.4) + 
  geom_line(aes(y = fit.l, linetype = "lm"), colour = "black", size = 1.1)+
  geom_line(aes(y = fit.c, linetype = "lmer"), size = 1.1)+ 
  geom_line(aes(y = fit.m, linetype = "Mean"),size = 1.1, colour = "darkgrey")+
   scale_linetype_manual(name = "Model Type", 
                        labels = c("Stratified mean", "Mixed model", "Pooled mean"),
                        values = c("dotdash", "solid", "dashed"))+
  facet_wrap( ~ group)+
  guides(colour = "none")

```



## Model in R

```{r, echo = T}
library(lmerTest)
lmer1 <- lmer(y ~ x + (1|group), data = data)
summary(lmer1)

```


**Group** the variation associated with the group effect (after fixed effects are fitted)

**Residual** The residual/leftover deviations or variance not due to fixed or random effects



## Model output

Similar in interpretation to fixed effects from models you have constructed before

**However** p-values for mixed models aren’t as straightforward as they are for the linear model. There are multiple approaches, and there’s a discussion surrounding these, with sometimes wildly differing opinions about which approach is the best.

`lmerTest` lmer model fits via Satterthwaite's degrees of freedom method estimation.

```
Fixed effects:
            Estimate Std. Error       df t value Pr(>|t|)    
(Intercept)  23.2692     6.4818   4.1570    3.59   0.0215 *  
x             2.0271     0.1703 424.0815   11.90   <2e-16 ***

```


## Random slopes and intercepts {.smaller}

```{r, include = FALSE}

plot_function <- function(model, title = ""){
  
data <- data %>% 
  mutate(fit.m = predict(model, re.form = NA),
         fit.c = predict(model, re.form = NULL))

data %>%
  ggplot(aes(x = x, y = y, col = group)) +
  geom_point(pch = 16, alpha = 0.4) +
  geom_line(aes(y = fit.c, col = group), size = 1)  +
  coord_cartesian(ylim = c(-40, 100))+
  labs(title = title)+
  theme(legend.position ="none")
}

```

::::{.columns}

:::{.column}

${y_{ij} = \beta0_{j} + \beta1x+\epsilon_i}$

```
y ~ x + (1|group), data = data)
```

```{r, echo = FALSE, fig.width = 12}

# random intercept model
lmer1 <- lmer(y ~ x + (1|group), data = data)
plot_function(lmer1, "Random intercept")
```

 A random-intercepts model where the outcome variable y is a function of predictor x, with a random intercept for group 

:::

:::{.column}

${y_{ij}  = \beta0_{j} + \beta1_{j}x+\epsilon_i}$


```
y ~ x + (x|group), data = data)
```

```{r, echo = FALSE, fig.width = 12}
# Random slope and intercept model

lmer3 <- lmer(y ~ x + (x | group), data = data, control = lmerControl(optimizer = "Nelder_Mead"))
plot_function(lmer3, "Random intercept & slope")
```
A random intercepts and random slopes model, where both intercepts and slopes are permitted to vary by group

:::

::::

Random slope models give the model far more flexibility to fit the data, but require a lot more data to obtain accurate estimates of separate slopes for each group.



## Checking models

::::{.columns}

:::{.column}

Checking models with random effects is more complex

`check_model` will add plots to investigate the distribution of random effects

`DHARMa` when dealing with increasingly complex models - residual simulations may be preferred

:::

:::{.column}

```{r, echo = F, warning = F, message = F, fig.width = 12}

DHARMa::simulateResiduals(lmer1, plot = T)

```

:::

::::

## Comparing models

Comparisons of random effects may be checked with the Likelihood Ratio Test (LRT) and a $\chi^2$ distribution

```{r, eval = F, echo = T}

anova(random_slope_intercept, random_intercept)

```

```{r, echo = F}

anova(lmer3, lmer1)

```

---

## Fixed effects

Comparisons of fixed effects may be checked with the Likelihood Ratio Test (LRT) and an $F$ distribution

```{r, eval = F, echo =T}

anova(model, test = "F")

```


```{r, echo = T}

drop1(lmer1, test = "F")

```

---

## Choosing your model

- Explore your data and understand it

- Think carefully before deciding on the structure of your model

- Often better to 'keep it maximal' with regards to random effects (if you can) - don't be guided solely by LRT.

---

## Issues

### Convergence warning

Model may need simplification or an alternative algorithm

```{r, echo = T, warning = T}
lmer3 <- lmer(y ~ x + (x | group), data = data)

```


### Boundary fit

Your model did fit, but it generated that warning because some of your random effects are very small




## Reporting models

1. Describe and justify your model (summarize the model fit).

  - Specify all fixed and random effects, interactions, intercepts, and slopes
  - Specify sample size: number of observations, and number of levels for each grouping factor

2. Mention that you checked assumptions (and how), and that the assumptions are satisfied.

3. Fixed effects: Report significance (test statistic (t/F), degrees of freedom, p-value) and actual estimates for coefficients (effect size: magnitude and direction, standard errors, and confidence intervals). Report Post-hoc tests (`emmeans()`).

4. Random effects: Report the variances, standard deviations


## Recommended {.smaller}

::::{.columns}

:::{.column}

- Cite the relevant packages for constructing and presenting analyses

- Include plots of data and models

- Report fixed effects as you would for a fixed-effects model

- Make sure to include a summary of random effect specifications and s.d.



:::

:::{.column}
```{r, echo = T}

sjPlot::tab_model(lmer3)

```
:::

::::

# Wrap-up {background-color="#D9DBDB"}

## Where next?


<br><br>

::: {.fragment}


* (Generalised) Linear **Mixed** Models

:::

::: {.fragment}

* Generalised Additive Models

:::


## Additional resources

* Discovering Statistics - Andy Field

* An Introduction to Generalized Linear Models - Dobson & Barnett

* An Introduction to Statistical Learning with Applications in R - James, Witten, Hastie & Tibshirani

* Mixed Effects Models and Extensions in Ecology with R - Zuur, et al.

* Ecological Statistics with contemporary theory and application

* The Big Book of R (https://www.bigbookofr.com/)

* [British Ecological Society Guides to Better Science](https://www.britishecologicalsociety.org/publications/better-science/)

*[(SORTEE)](https://www.sortee.org/reading/)


## Reading list {.smaller}

::::{.columns}

:::{.column}

[Writing statistical methods for ecologists](https://doi.org/10.1002/ecs2.4539)

[Reporting statistical methods and outcome of statistical analyses in research articles](https://link.springer.com/article/10.1007/s43440-020-00110-5)

[Design principles for data analysis](https://doi.org/10.1080/10618600.2022.2104290)

[Log-transformation and its implications for data analysis.](https://doi.org/10.3969%2Fj.issn.1002-0829.2014.02.009)

[Effect size, confidence interval and statistical significance: a practical guide for biologists](https://doi.org/10.1111/j.1469-185X.2007.00027.x)

[Same data, different analysts: variation in effect sizes due to analytical decisions in ecology and evolutionary biology](https://ecoevorxiv.org/repository/view/6000/)

[Misconceptions, Misuses, and Misinterpretations of P Values and Significance Testing](https://doi.org/10.2106/jbjs.16.01314)

:::

:::{.column}

[Ten common statistical mistakes to watch out for when writing or reviewing a manuscript.](https://elifesciences.org/articles/48175)

[Why most published research findings are false](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124)

[Step away from stepwise](https://doi.org/10.1186/s40537-018-0143-6)

[Model averaging and muddled multimodel inference](https://doi.org/10.1890/14-1639.1)

[Make scientific data FAIR](https://www.nature.com/articles/d41586-019-01720-7)

[A brief introduction to mixed effects modelling and multi-model inference in ecology](https://peerj.com/articles/4794/)

[The Practical Alternative to the p Value Is the Correctly Used p Value](https://doi.org/10.1177/1745691620958012)

:::

::::

## 

::: columns
::: {.column}

<br>

{{< fa brands linkedin >}} [philip-leftwich](https://www.linkedin.com/in/philip-leftwich-117052155/)

{{< fa brands mastodon >}} [\@ecoevo.social\@PhilipLeftwich](https://ecoevo.social/@PhilipLeftwich)

{{< fa brands github >}} [PhilipLeftwich](https://github.com/Philip-Leftwich)

{{< fa globe >}} [philip.leftwich.github.io](https://philip.leftwich.github.io/)



:::
::: {.column}


:::
:::
